---------------------------------------
Begin Slurm Prolog: Aug-10-2025 15:35:15
Job ID:    6782330
User ID:   xchen920
Account:   gts-apm7
Job name:  channel_trans
Partition: gpu-v100
QOS:       inferno
---------------------------------------
== Job info ==
Sun Aug 10 03:35:15 PM EDT 2025
atl1-1-02-009-35-0.pace.gatech.edu
== GPU check ==
Sun Aug 10 15:35:21 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-16GB           On  |   00000000:AF:00.0 Off |                    0 |
| N/A   41C    P0             29W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
== Launch ==
/storage/scratch1/4/xchen920/project
0.10.0
device= cuda:0
  0%|          | 0/135842 [00:00<?, ?it/s] 12%|█▏        | 16831/135842 [00:00<00:01, 107730.56it/s] 28%|██▊       | 38498/135842 [00:00<00:00, 159759.57it/s] 41%|████      | 55679/135842 [00:00<00:00, 120942.05it/s] 51%|█████     | 69378/135842 [00:00<00:00, 94359.26it/s]  66%|██████▌   | 89396/135842 [00:00<00:00, 120015.34it/s] 79%|███████▉  | 107136/135842 [00:01<00:00, 90457.47it/s] 92%|█████████▏| 125482/135842 [00:01<00:00, 108857.93it/s]100%|██████████| 135842/135842 [00:01<00:00, 112143.83it/s]
  0%|          | 0/108673 [00:00<?, ?it/s] 16%|█▌        | 17395/108673 [00:00<00:01, 47180.74it/s] 33%|███▎      | 35653/108673 [00:00<00:00, 84991.43it/s] 50%|████▉     | 53828/108673 [00:00<00:00, 112582.71it/s] 66%|██████▋   | 72063/108673 [00:00<00:00, 132775.58it/s] 81%|████████▏ | 88455/108673 [00:01<00:00, 70928.59it/s]  98%|█████████▊| 106539/108673 [00:01<00:00, 89921.92it/s]100%|██████████| 108673/108673 [00:01<00:00, 88885.60it/s]
  0%|          | 0/27169 [00:00<?, ?it/s] 66%|██████▋   | 18011/27169 [00:00<00:00, 180099.01it/s]100%|██████████| 27169/27169 [00:00<00:00, 181602.24it/s]
tensor([   3,   16,  452,    7, 1086,   60, 7436,   26,   22, 2761,    7, 1423,
          67,  635,   12,   60, 2679,   65,  844,    7,  525,    4,    2,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1])
torch.Size([52, 128]) torch.Size([52, 128])
++++++++++++++++ 213
len(train_dataloader): 850
torch.Size([128, 52]) torch.Size([128, 52])
tensor([    3,    14,   480,  4872,    29,   193,     6,    15,     9,   176,
           26, 12858,   984,    62,  3962,   118,  2532,    25,  7889,   157,
          253,  7007,     4,     2,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1]) torch.int64
tensor([    3,   464,    33, 11938,   126,    36,     7,   925,    65,  9847,
           66,    42,  2250,    31,   174,  1745,    40,     8,   411,   189,
         5776,    82,  2036,     4,     2,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1]) torch.int64
*************************** start training...

================================================================================2025-08_10 15:39:15
******** [step = 50] loss: 9.356, acc: 0.009
******** [step = 100] loss: 8.896, acc: 0.091
******** [step = 150] loss: 8.524, acc: 0.136
******** [step = 200] loss: 8.189, acc: 0.163
******** [step = 250] loss: 7.877, acc: 0.180
******** [step = 300] loss: 7.575, acc: 0.192
******** [step = 350] loss: 7.283, acc: 0.202
******** [step = 400] loss: 7.012, acc: 0.212
******** [step = 450] loss: 6.772, acc: 0.222
******** [step = 500] loss: 6.557, acc: 0.232
******** [step = 550] loss: 6.368, acc: 0.241
******** [step = 600] loss: 6.200, acc: 0.250
******** [step = 650] loss: 6.047, acc: 0.258
******** [step = 700] loss: 5.906, acc: 0.266
******** [step = 750] loss: 5.780, acc: 0.273
******** [step = 800] loss: 5.664, acc: 0.280
******** [step = 850] loss: 5.558, acc: 0.286
EPOCH = 1 loss: 5.558, acc: 0.286, val_loss: 3.721, val_acc: 0.401

================================================================================2025-08_10 15:40:49
******** [step = 50] loss: 3.823, acc: 0.382
******** [step = 100] loss: 3.795, acc: 0.383
******** [step = 150] loss: 3.773, acc: 0.384
******** [step = 200] loss: 3.745, acc: 0.386
******** [step = 250] loss: 3.721, acc: 0.388
******** [step = 300] loss: 3.698, acc: 0.391
******** [step = 350] loss: 3.679, acc: 0.393
******** [step = 400] loss: 3.661, acc: 0.395
******** [step = 450] loss: 3.642, acc: 0.397
******** [step = 500] loss: 3.627, acc: 0.398
******** [step = 550] loss: 3.611, acc: 0.400
******** [step = 600] loss: 3.595, acc: 0.402
******** [step = 650] loss: 3.580, acc: 0.403
******** [step = 700] loss: 3.566, acc: 0.405
******** [step = 750] loss: 3.550, acc: 0.406
******** [step = 800] loss: 3.536, acc: 0.408
******** [step = 850] loss: 3.521, acc: 0.409
EPOCH = 2 loss: 3.521, acc: 0.409, val_loss: 3.331, val_acc: 0.417

================================================================================2025-08_10 15:42:11
******** [step = 50] loss: 3.265, acc: 0.428
******** [step = 100] loss: 3.241, acc: 0.432
******** [step = 150] loss: 3.238, acc: 0.434
******** [step = 200] loss: 3.229, acc: 0.436
******** [step = 250] loss: 3.226, acc: 0.436
******** [step = 300] loss: 3.222, acc: 0.436
******** [step = 350] loss: 3.217, acc: 0.437
******** [step = 400] loss: 3.209, acc: 0.437
******** [step = 450] loss: 3.205, acc: 0.438
******** [step = 500] loss: 3.200, acc: 0.439
******** [step = 550] loss: 3.191, acc: 0.440
******** [step = 600] loss: 3.184, acc: 0.440
******** [step = 650] loss: 3.180, acc: 0.441
******** [step = 700] loss: 3.173, acc: 0.442
******** [step = 750] loss: 3.169, acc: 0.442
******** [step = 800] loss: 3.161, acc: 0.443
******** [step = 850] loss: 3.155, acc: 0.444
EPOCH = 3 loss: 3.155, acc: 0.444, val_loss: 3.017, val_acc: 0.465

================================================================================2025-08_10 15:43:32
******** [step = 50] loss: 3.020, acc: 0.453
******** [step = 100] loss: 2.999, acc: 0.455
******** [step = 150] loss: 2.992, acc: 0.456
******** [step = 200] loss: 2.983, acc: 0.458
******** [step = 250] loss: 2.977, acc: 0.460
******** [step = 300] loss: 2.977, acc: 0.460
******** [step = 350] loss: 2.973, acc: 0.460
******** [step = 400] loss: 2.970, acc: 0.461
******** [step = 450] loss: 2.969, acc: 0.461
******** [step = 500] loss: 2.967, acc: 0.462
******** [step = 550] loss: 2.963, acc: 0.462
******** [step = 600] loss: 2.962, acc: 0.463
******** [step = 650] loss: 2.961, acc: 0.463
******** [step = 700] loss: 2.957, acc: 0.463
******** [step = 750] loss: 2.955, acc: 0.464
******** [step = 800] loss: 2.951, acc: 0.464
******** [step = 850] loss: 2.948, acc: 0.464
EPOCH = 4 loss: 2.948, acc: 0.464, val_loss: 2.883, val_acc: 0.477

================================================================================2025-08_10 15:44:57
******** [step = 50] loss: 2.851, acc: 0.466
******** [step = 100] loss: 2.832, acc: 0.471
******** [step = 150] loss: 2.827, acc: 0.472
******** [step = 200] loss: 2.824, acc: 0.473
******** [step = 250] loss: 2.823, acc: 0.474
******** [step = 300] loss: 2.819, acc: 0.475
******** [step = 350] loss: 2.820, acc: 0.475
******** [step = 400] loss: 2.820, acc: 0.476
******** [step = 450] loss: 2.816, acc: 0.476
******** [step = 500] loss: 2.813, acc: 0.477
******** [step = 550] loss: 2.812, acc: 0.477
******** [step = 600] loss: 2.811, acc: 0.478
******** [step = 650] loss: 2.812, acc: 0.478
******** [step = 700] loss: 2.810, acc: 0.478
******** [step = 750] loss: 2.809, acc: 0.479
******** [step = 800] loss: 2.807, acc: 0.479
******** [step = 850] loss: 2.803, acc: 0.480
EPOCH = 5 loss: 2.803, acc: 0.480, val_loss: 2.723, val_acc: 0.500

================================================================================2025-08_10 15:46:19
******** [step = 50] loss: 2.685, acc: 0.488
******** [step = 100] loss: 2.669, acc: 0.490
******** [step = 150] loss: 2.663, acc: 0.492
******** [step = 200] loss: 2.661, acc: 0.493
******** [step = 250] loss: 2.662, acc: 0.493
******** [step = 300] loss: 2.661, acc: 0.494
******** [step = 350] loss: 2.659, acc: 0.495
******** [step = 400] loss: 2.661, acc: 0.495
******** [step = 450] loss: 2.659, acc: 0.496
******** [step = 500] loss: 2.657, acc: 0.496
******** [step = 550] loss: 2.656, acc: 0.497
******** [step = 600] loss: 2.653, acc: 0.497
******** [step = 650] loss: 2.653, acc: 0.498
******** [step = 700] loss: 2.651, acc: 0.498
******** [step = 750] loss: 2.649, acc: 0.499
******** [step = 800] loss: 2.650, acc: 0.499
******** [step = 850] loss: 2.644, acc: 0.500
EPOCH = 6 loss: 2.644, acc: 0.500, val_loss: 2.596, val_acc: 0.517

================================================================================2025-08_10 15:47:41
******** [step = 50] loss: 2.510, acc: 0.512
******** [step = 100] loss: 2.496, acc: 0.516
******** [step = 150] loss: 2.498, acc: 0.516
******** [step = 200] loss: 2.500, acc: 0.516
******** [step = 250] loss: 2.498, acc: 0.516
******** [step = 300] loss: 2.500, acc: 0.516
******** [step = 350] loss: 2.503, acc: 0.516
******** [step = 400] loss: 2.505, acc: 0.516
******** [step = 450] loss: 2.505, acc: 0.517
******** [step = 500] loss: 2.509, acc: 0.516
******** [step = 550] loss: 2.509, acc: 0.516
******** [step = 600] loss: 2.508, acc: 0.517
******** [step = 650] loss: 2.507, acc: 0.517
******** [step = 700] loss: 2.508, acc: 0.517
******** [step = 750] loss: 2.509, acc: 0.517
******** [step = 800] loss: 2.509, acc: 0.517
******** [step = 850] loss: 2.510, acc: 0.517
EPOCH = 7 loss: 2.510, acc: 0.517, val_loss: 2.487, val_acc: 0.535

================================================================================2025-08_10 15:49:04
******** [step = 50] loss: 2.413, acc: 0.525
******** [step = 100] loss: 2.391, acc: 0.528
******** [step = 150] loss: 2.383, acc: 0.529
******** [step = 200] loss: 2.387, acc: 0.530
******** [step = 250] loss: 2.391, acc: 0.530
******** [step = 300] loss: 2.393, acc: 0.530
******** [step = 350] loss: 2.398, acc: 0.529
******** [step = 400] loss: 2.399, acc: 0.529
******** [step = 450] loss: 2.397, acc: 0.530
******** [step = 500] loss: 2.397, acc: 0.531
******** [step = 550] loss: 2.394, acc: 0.531
******** [step = 600] loss: 2.394, acc: 0.531
******** [step = 650] loss: 2.395, acc: 0.531
******** [step = 700] loss: 2.397, acc: 0.532
******** [step = 750] loss: 2.398, acc: 0.532
******** [step = 800] loss: 2.399, acc: 0.532
******** [step = 850] loss: 2.400, acc: 0.532
EPOCH = 8 loss: 2.400, acc: 0.532, val_loss: 2.396, val_acc: 0.547

================================================================================2025-08_10 15:50:25
******** [step = 50] loss: 2.319, acc: 0.538
******** [step = 100] loss: 2.296, acc: 0.542
******** [step = 150] loss: 2.299, acc: 0.542
******** [step = 200] loss: 2.295, acc: 0.543
******** [step = 250] loss: 2.299, acc: 0.542
******** [step = 300] loss: 2.300, acc: 0.543
******** [step = 350] loss: 2.302, acc: 0.543
******** [step = 400] loss: 2.306, acc: 0.543
******** [step = 450] loss: 2.304, acc: 0.543
******** [step = 500] loss: 2.308, acc: 0.543
******** [step = 550] loss: 2.307, acc: 0.544
******** [step = 600] loss: 2.311, acc: 0.543
******** [step = 650] loss: 2.312, acc: 0.543
******** [step = 700] loss: 2.311, acc: 0.544
******** [step = 750] loss: 2.311, acc: 0.544
******** [step = 800] loss: 2.313, acc: 0.544
******** [step = 850] loss: 2.312, acc: 0.544
EPOCH = 9 loss: 2.312, acc: 0.544, val_loss: 2.334, val_acc: 0.559

================================================================================2025-08_10 15:51:45
******** [step = 50] loss: 2.214, acc: 0.554
******** [step = 100] loss: 2.206, acc: 0.555
******** [step = 150] loss: 2.209, acc: 0.555
******** [step = 200] loss: 2.207, acc: 0.556
******** [step = 250] loss: 2.206, acc: 0.557
******** [step = 300] loss: 2.212, acc: 0.556
******** [step = 350] loss: 2.219, acc: 0.556
******** [step = 400] loss: 2.221, acc: 0.556
******** [step = 450] loss: 2.221, acc: 0.556
******** [step = 500] loss: 2.224, acc: 0.556
******** [step = 550] loss: 2.227, acc: 0.555
******** [step = 600] loss: 2.229, acc: 0.556
******** [step = 650] loss: 2.230, acc: 0.556
******** [step = 700] loss: 2.232, acc: 0.556
******** [step = 750] loss: 2.234, acc: 0.555
******** [step = 800] loss: 2.236, acc: 0.555
******** [step = 850] loss: 2.237, acc: 0.555
EPOCH = 10 loss: 2.237, acc: 0.555, val_loss: 2.301, val_acc: 0.566

================================================================================2025-08_10 15:53:06
******** [step = 50] loss: 2.145, acc: 0.562
******** [step = 100] loss: 2.130, acc: 0.566
******** [step = 150] loss: 2.135, acc: 0.566
******** [step = 200] loss: 2.139, acc: 0.566
******** [step = 250] loss: 2.144, acc: 0.565
******** [step = 300] loss: 2.149, acc: 0.565
******** [step = 350] loss: 2.150, acc: 0.566
******** [step = 400] loss: 2.154, acc: 0.565
******** [step = 450] loss: 2.158, acc: 0.565
******** [step = 500] loss: 2.163, acc: 0.564
******** [step = 550] loss: 2.164, acc: 0.564
******** [step = 600] loss: 2.165, acc: 0.565
******** [step = 650] loss: 2.167, acc: 0.565
******** [step = 700] loss: 2.170, acc: 0.564
******** [step = 750] loss: 2.173, acc: 0.564
******** [step = 800] loss: 2.175, acc: 0.564
******** [step = 850] loss: 2.175, acc: 0.565
EPOCH = 11 loss: 2.175, acc: 0.565, val_loss: 2.250, val_acc: 0.576

================================================================================2025-08_10 15:54:26
******** [step = 50] loss: 2.081, acc: 0.575
******** [step = 100] loss: 2.078, acc: 0.576
******** [step = 150] loss: 2.068, acc: 0.576
******** [step = 200] loss: 2.076, acc: 0.575
******** [step = 250] loss: 2.084, acc: 0.574
******** [step = 300] loss: 2.087, acc: 0.574
******** [step = 350] loss: 2.092, acc: 0.574
******** [step = 400] loss: 2.098, acc: 0.574
******** [step = 450] loss: 2.102, acc: 0.573
******** [step = 500] loss: 2.102, acc: 0.574
******** [step = 550] loss: 2.107, acc: 0.573
******** [step = 600] loss: 2.111, acc: 0.573
******** [step = 650] loss: 2.114, acc: 0.573
******** [step = 700] loss: 2.116, acc: 0.573
******** [step = 750] loss: 2.119, acc: 0.573
******** [step = 800] loss: 2.122, acc: 0.573
******** [step = 850] loss: 2.123, acc: 0.573
EPOCH = 12 loss: 2.123, acc: 0.573, val_loss: 2.232, val_acc: 0.580

================================================================================2025-08_10 15:55:47
******** [step = 50] loss: 2.044, acc: 0.580
******** [step = 100] loss: 2.041, acc: 0.581
******** [step = 150] loss: 2.041, acc: 0.581
******** [step = 200] loss: 2.043, acc: 0.582
******** [step = 250] loss: 2.044, acc: 0.582
******** [step = 300] loss: 2.049, acc: 0.582
******** [step = 350] loss: 2.051, acc: 0.581
******** [step = 400] loss: 2.058, acc: 0.581
******** [step = 450] loss: 2.059, acc: 0.581
******** [step = 500] loss: 2.063, acc: 0.581
******** [step = 550] loss: 2.064, acc: 0.581
******** [step = 600] loss: 2.067, acc: 0.580
******** [step = 650] loss: 2.068, acc: 0.580
******** [step = 700] loss: 2.071, acc: 0.580
******** [step = 750] loss: 2.074, acc: 0.580
******** [step = 800] loss: 2.075, acc: 0.580
******** [step = 850] loss: 2.078, acc: 0.580
EPOCH = 13 loss: 2.078, acc: 0.580, val_loss: 2.203, val_acc: 0.585

================================================================================2025-08_10 15:57:08
******** [step = 50] loss: 1.980, acc: 0.590
******** [step = 100] loss: 1.977, acc: 0.591
******** [step = 150] loss: 1.984, acc: 0.590
******** [step = 200] loss: 1.983, acc: 0.590
******** [step = 250] loss: 1.991, acc: 0.590
******** [step = 300] loss: 1.995, acc: 0.590
******** [step = 350] loss: 2.001, acc: 0.590
******** [step = 400] loss: 2.001, acc: 0.589
******** [step = 450] loss: 2.008, acc: 0.589
******** [step = 500] loss: 2.016, acc: 0.588
******** [step = 550] loss: 2.020, acc: 0.588
******** [step = 600] loss: 2.024, acc: 0.587
******** [step = 650] loss: 2.028, acc: 0.587
******** [step = 700] loss: 2.031, acc: 0.587
******** [step = 750] loss: 2.033, acc: 0.587
******** [step = 800] loss: 2.035, acc: 0.587
******** [step = 850] loss: 2.036, acc: 0.587
EPOCH = 14 loss: 2.036, acc: 0.587, val_loss: 2.173, val_acc: 0.593

================================================================================2025-08_10 15:58:28
******** [step = 50] loss: 1.935, acc: 0.595
******** [step = 100] loss: 1.937, acc: 0.595
******** [step = 150] loss: 1.939, acc: 0.596
******** [step = 200] loss: 1.944, acc: 0.596
******** [step = 250] loss: 1.955, acc: 0.595
******** [step = 300] loss: 1.959, acc: 0.594
******** [step = 350] loss: 1.968, acc: 0.593
******** [step = 400] loss: 1.972, acc: 0.593
******** [step = 450] loss: 1.976, acc: 0.593
******** [step = 500] loss: 1.980, acc: 0.592
******** [step = 550] loss: 1.986, acc: 0.592
******** [step = 600] loss: 1.989, acc: 0.592
******** [step = 650] loss: 1.992, acc: 0.592
******** [step = 700] loss: 1.993, acc: 0.592
******** [step = 750] loss: 1.996, acc: 0.592
******** [step = 800] loss: 1.998, acc: 0.591
******** [step = 850] loss: 2.001, acc: 0.591
EPOCH = 15 loss: 2.001, acc: 0.591, val_loss: 2.165, val_acc: 0.594

================================================================================2025-08_10 15:59:50
******** [step = 50] loss: 1.916, acc: 0.597
******** [step = 100] loss: 1.907, acc: 0.600
******** [step = 150] loss: 1.907, acc: 0.601
******** [step = 200] loss: 1.914, acc: 0.600
******** [step = 250] loss: 1.922, acc: 0.599
******** [step = 300] loss: 1.925, acc: 0.599
******** [step = 350] loss: 1.930, acc: 0.599
******** [step = 400] loss: 1.940, acc: 0.598
******** [step = 450] loss: 1.945, acc: 0.598
******** [step = 500] loss: 1.945, acc: 0.598
******** [step = 550] loss: 1.949, acc: 0.598
******** [step = 600] loss: 1.951, acc: 0.598
******** [step = 650] loss: 1.954, acc: 0.597
******** [step = 700] loss: 1.959, acc: 0.597
******** [step = 750] loss: 1.965, acc: 0.596
******** [step = 800] loss: 1.968, acc: 0.596
******** [step = 850] loss: 1.970, acc: 0.596
EPOCH = 16 loss: 1.970, acc: 0.596, val_loss: 2.159, val_acc: 0.594

================================================================================2025-08_10 16:01:13
******** [step = 50] loss: 1.870, acc: 0.604
******** [step = 100] loss: 1.873, acc: 0.605
******** [step = 150] loss: 1.878, acc: 0.606
******** [step = 200] loss: 1.885, acc: 0.605
******** [step = 250] loss: 1.885, acc: 0.605
******** [step = 300] loss: 1.885, acc: 0.605
******** [step = 350] loss: 1.889, acc: 0.605
******** [step = 400] loss: 1.894, acc: 0.605
******** [step = 450] loss: 1.898, acc: 0.605
******** [step = 500] loss: 1.903, acc: 0.605
******** [step = 550] loss: 1.908, acc: 0.604
******** [step = 600] loss: 1.914, acc: 0.604
******** [step = 650] loss: 1.917, acc: 0.604
******** [step = 700] loss: 1.923, acc: 0.603
******** [step = 750] loss: 1.926, acc: 0.603
******** [step = 800] loss: 1.930, acc: 0.602
******** [step = 850] loss: 1.939, acc: 0.601
EPOCH = 17 loss: 1.939, acc: 0.601, val_loss: 2.156, val_acc: 0.594

================================================================================2025-08_10 16:02:33
******** [step = 50] loss: 1.854, acc: 0.609
******** [step = 100] loss: 1.857, acc: 0.609
******** [step = 150] loss: 1.865, acc: 0.608
******** [step = 200] loss: 1.867, acc: 0.609
******** [step = 250] loss: 1.870, acc: 0.608
******** [step = 300] loss: 1.871, acc: 0.609
******** [step = 350] loss: 1.875, acc: 0.608
******** [step = 400] loss: 1.875, acc: 0.609
******** [step = 450] loss: 1.877, acc: 0.608
******** [step = 500] loss: 1.880, acc: 0.608
******** [step = 550] loss: 1.886, acc: 0.607
******** [step = 600] loss: 1.890, acc: 0.607
******** [step = 650] loss: 1.892, acc: 0.607
******** [step = 700] loss: 1.895, acc: 0.607
******** [step = 750] loss: 1.897, acc: 0.607
******** [step = 800] loss: 1.900, acc: 0.607
******** [step = 850] loss: 1.905, acc: 0.606
EPOCH = 18 loss: 1.905, acc: 0.606, val_loss: 2.113, val_acc: 0.604

================================================================================2025-08_10 16:03:55
******** [step = 50] loss: 1.798, acc: 0.620
******** [step = 100] loss: 1.807, acc: 0.618
******** [step = 150] loss: 1.807, acc: 0.619
******** [step = 200] loss: 1.818, acc: 0.617
******** [step = 250] loss: 1.824, acc: 0.617
******** [step = 300] loss: 1.827, acc: 0.617
******** [step = 350] loss: 1.833, acc: 0.616
******** [step = 400] loss: 1.841, acc: 0.615
******** [step = 450] loss: 1.847, acc: 0.614
******** [step = 500] loss: 1.851, acc: 0.614
******** [step = 550] loss: 1.855, acc: 0.613
******** [step = 600] loss: 1.857, acc: 0.613
******** [step = 650] loss: 1.861, acc: 0.612
******** [step = 700] loss: 1.866, acc: 0.612
******** [step = 750] loss: 1.869, acc: 0.612
******** [step = 800] loss: 1.872, acc: 0.611
******** [step = 850] loss: 1.878, acc: 0.611
EPOCH = 19 loss: 1.878, acc: 0.611, val_loss: 2.091, val_acc: 0.608

================================================================================2025-08_10 16:05:18
******** [step = 50] loss: 1.810, acc: 0.619
******** [step = 100] loss: 1.789, acc: 0.621
******** [step = 150] loss: 1.789, acc: 0.621
******** [step = 200] loss: 1.788, acc: 0.621
******** [step = 250] loss: 1.791, acc: 0.621
******** [step = 300] loss: 1.800, acc: 0.619
******** [step = 350] loss: 1.805, acc: 0.619
******** [step = 400] loss: 1.810, acc: 0.619
******** [step = 450] loss: 1.815, acc: 0.619
******** [step = 500] loss: 1.821, acc: 0.618
******** [step = 550] loss: 1.826, acc: 0.617
******** [step = 600] loss: 1.832, acc: 0.617
******** [step = 650] loss: 1.836, acc: 0.617
******** [step = 700] loss: 1.840, acc: 0.616
******** [step = 750] loss: 1.843, acc: 0.616
******** [step = 800] loss: 1.847, acc: 0.615
******** [step = 850] loss: 1.850, acc: 0.615
EPOCH = 20 loss: 1.850, acc: 0.615, val_loss: 2.097, val_acc: 0.607

================================================================================2025-08_10 16:06:49
******** [step = 50] loss: 1.755, acc: 0.625
******** [step = 100] loss: 1.763, acc: 0.625
******** [step = 150] loss: 1.768, acc: 0.624
******** [step = 200] loss: 1.769, acc: 0.624
******** [step = 250] loss: 1.777, acc: 0.623
******** [step = 300] loss: 1.780, acc: 0.623
******** [step = 350] loss: 1.785, acc: 0.622
******** [step = 400] loss: 1.792, acc: 0.622
******** [step = 450] loss: 1.798, acc: 0.622
******** [step = 500] loss: 1.802, acc: 0.621
******** [step = 550] loss: 1.807, acc: 0.621
******** [step = 600] loss: 1.810, acc: 0.620
******** [step = 650] loss: 1.815, acc: 0.620
******** [step = 700] loss: 1.817, acc: 0.620
******** [step = 750] loss: 1.820, acc: 0.619
******** [step = 800] loss: 1.823, acc: 0.619
******** [step = 850] loss: 1.825, acc: 0.619
EPOCH = 21 loss: 1.825, acc: 0.619, val_loss: 2.076, val_acc: 0.613

================================================================================2025-08_10 16:08:16
******** [step = 50] loss: 1.751, acc: 0.628
******** [step = 100] loss: 1.749, acc: 0.628
******** [step = 150] loss: 1.753, acc: 0.627
******** [step = 200] loss: 1.758, acc: 0.627
******** [step = 250] loss: 1.761, acc: 0.626
******** [step = 300] loss: 1.764, acc: 0.626
******** [step = 350] loss: 1.770, acc: 0.625
******** [step = 400] loss: 1.773, acc: 0.625
******** [step = 450] loss: 1.776, acc: 0.625
******** [step = 500] loss: 1.780, acc: 0.624
******** [step = 550] loss: 1.784, acc: 0.624
******** [step = 600] loss: 1.787, acc: 0.624
******** [step = 650] loss: 1.791, acc: 0.623
******** [step = 700] loss: 1.794, acc: 0.623
******** [step = 750] loss: 1.797, acc: 0.623
******** [step = 800] loss: 1.800, acc: 0.622
******** [step = 850] loss: 1.803, acc: 0.622
EPOCH = 22 loss: 1.803, acc: 0.622, val_loss: 2.063, val_acc: 0.614

================================================================================2025-08_10 16:09:42
******** [step = 50] loss: 1.729, acc: 0.631
******** [step = 100] loss: 1.726, acc: 0.633
******** [step = 150] loss: 1.725, acc: 0.633
******** [step = 200] loss: 1.730, acc: 0.632
******** [step = 250] loss: 1.733, acc: 0.632
******** [step = 300] loss: 1.739, acc: 0.631
******** [step = 350] loss: 1.741, acc: 0.631
******** [step = 400] loss: 1.750, acc: 0.629
******** [step = 450] loss: 1.751, acc: 0.629
******** [step = 500] loss: 1.758, acc: 0.629
******** [step = 550] loss: 1.762, acc: 0.628
******** [step = 600] loss: 1.767, acc: 0.627
******** [step = 650] loss: 1.771, acc: 0.627
******** [step = 700] loss: 1.774, acc: 0.626
******** [step = 750] loss: 1.777, acc: 0.626
******** [step = 800] loss: 1.781, acc: 0.626
******** [step = 850] loss: 1.785, acc: 0.625
EPOCH = 23 loss: 1.785, acc: 0.625, val_loss: 2.053, val_acc: 0.617

================================================================================2025-08_10 16:11:02
******** [step = 50] loss: 1.718, acc: 0.631
******** [step = 100] loss: 1.715, acc: 0.632
******** [step = 150] loss: 1.718, acc: 0.633
******** [step = 200] loss: 1.728, acc: 0.631
******** [step = 250] loss: 1.731, acc: 0.631
******** [step = 300] loss: 1.733, acc: 0.631
******** [step = 350] loss: 1.737, acc: 0.631
******** [step = 400] loss: 1.738, acc: 0.630
******** [step = 450] loss: 1.738, acc: 0.631
******** [step = 500] loss: 1.741, acc: 0.631
******** [step = 550] loss: 1.743, acc: 0.630
******** [step = 600] loss: 1.746, acc: 0.630
******** [step = 650] loss: 1.750, acc: 0.630
******** [step = 700] loss: 1.753, acc: 0.629
******** [step = 750] loss: 1.757, acc: 0.629
******** [step = 800] loss: 1.759, acc: 0.629
******** [step = 850] loss: 1.760, acc: 0.628
EPOCH = 24 loss: 1.760, acc: 0.628, val_loss: 2.040, val_acc: 0.619

================================================================================2025-08_10 16:12:22
******** [step = 50] loss: 1.689, acc: 0.638
******** [step = 100] loss: 1.694, acc: 0.637
******** [step = 150] loss: 1.695, acc: 0.637
******** [step = 200] loss: 1.700, acc: 0.637
******** [step = 250] loss: 1.703, acc: 0.636
******** [step = 300] loss: 1.708, acc: 0.636
******** [step = 350] loss: 1.710, acc: 0.635
******** [step = 400] loss: 1.717, acc: 0.634
******** [step = 450] loss: 1.720, acc: 0.634
******** [step = 500] loss: 1.724, acc: 0.633
******** [step = 550] loss: 1.728, acc: 0.633
******** [step = 600] loss: 1.733, acc: 0.632
******** [step = 650] loss: 1.736, acc: 0.632
******** [step = 700] loss: 1.738, acc: 0.632
******** [step = 750] loss: 1.741, acc: 0.631
******** [step = 800] loss: 1.744, acc: 0.631
******** [step = 850] loss: 1.748, acc: 0.631
EPOCH = 25 loss: 1.748, acc: 0.631, val_loss: 2.041, val_acc: 0.618

================================================================================2025-08_10 16:13:49
******** [step = 50] loss: 1.681, acc: 0.640
******** [step = 100] loss: 1.666, acc: 0.642
******** [step = 150] loss: 1.674, acc: 0.641
******** [step = 200] loss: 1.676, acc: 0.641
******** [step = 250] loss: 1.680, acc: 0.640
******** [step = 300] loss: 1.683, acc: 0.639
******** [step = 350] loss: 1.689, acc: 0.638
******** [step = 400] loss: 1.694, acc: 0.638
******** [step = 450] loss: 1.700, acc: 0.637
******** [step = 500] loss: 1.701, acc: 0.637
******** [step = 550] loss: 1.704, acc: 0.636
******** [step = 600] loss: 1.709, acc: 0.636
******** [step = 650] loss: 1.712, acc: 0.635
******** [step = 700] loss: 1.715, acc: 0.635
******** [step = 750] loss: 1.719, acc: 0.635
******** [step = 800] loss: 1.722, acc: 0.635
******** [step = 850] loss: 1.727, acc: 0.634
EPOCH = 26 loss: 1.727, acc: 0.634, val_loss: 2.033, val_acc: 0.622

================================================================================2025-08_10 16:15:16
******** [step = 50] loss: 1.656, acc: 0.643
******** [step = 100] loss: 1.647, acc: 0.643
******** [step = 150] loss: 1.655, acc: 0.643
******** [step = 200] loss: 1.655, acc: 0.643
******** [step = 250] loss: 1.663, acc: 0.642
******** [step = 300] loss: 1.668, acc: 0.642
******** [step = 350] loss: 1.675, acc: 0.641
******** [step = 400] loss: 1.678, acc: 0.641
******** [step = 450] loss: 1.682, acc: 0.640
******** [step = 500] loss: 1.687, acc: 0.640
******** [step = 550] loss: 1.691, acc: 0.639
******** [step = 600] loss: 1.694, acc: 0.639
******** [step = 650] loss: 1.698, acc: 0.639
******** [step = 700] loss: 1.701, acc: 0.638
******** [step = 750] loss: 1.705, acc: 0.638
******** [step = 800] loss: 1.708, acc: 0.638
******** [step = 850] loss: 1.711, acc: 0.637
EPOCH = 27 loss: 1.711, acc: 0.637, val_loss: 2.017, val_acc: 0.625

================================================================================2025-08_10 16:16:38
******** [step = 50] loss: 1.640, acc: 0.644
******** [step = 100] loss: 1.635, acc: 0.645
******** [step = 150] loss: 1.637, acc: 0.645
******** [step = 200] loss: 1.646, acc: 0.644
******** [step = 250] loss: 1.647, acc: 0.644
******** [step = 300] loss: 1.651, acc: 0.643
******** [step = 350] loss: 1.652, acc: 0.643
******** [step = 400] loss: 1.654, acc: 0.643
******** [step = 450] loss: 1.662, acc: 0.642
******** [step = 500] loss: 1.666, acc: 0.642
******** [step = 550] loss: 1.669, acc: 0.642
******** [step = 600] loss: 1.676, acc: 0.641
******** [step = 650] loss: 1.680, acc: 0.641
******** [step = 700] loss: 1.685, acc: 0.640
******** [step = 750] loss: 1.688, acc: 0.640
******** [step = 800] loss: 1.691, acc: 0.640
******** [step = 850] loss: 1.694, acc: 0.640
EPOCH = 28 loss: 1.694, acc: 0.640, val_loss: 2.004, val_acc: 0.627

================================================================================2025-08_10 16:18:06
******** [step = 50] loss: 1.612, acc: 0.648
******** [step = 100] loss: 1.611, acc: 0.650
******** [step = 150] loss: 1.620, acc: 0.648
******** [step = 200] loss: 1.627, acc: 0.647
******** [step = 250] loss: 1.632, acc: 0.647
******** [step = 300] loss: 1.637, acc: 0.646
******** [step = 350] loss: 1.643, acc: 0.646
******** [step = 400] loss: 1.647, acc: 0.645
******** [step = 450] loss: 1.650, acc: 0.645
******** [step = 500] loss: 1.653, acc: 0.645
******** [step = 550] loss: 1.659, acc: 0.644
******** [step = 600] loss: 1.663, acc: 0.644
******** [step = 650] loss: 1.667, acc: 0.643
******** [step = 700] loss: 1.670, acc: 0.643
******** [step = 750] loss: 1.673, acc: 0.643
******** [step = 800] loss: 1.676, acc: 0.643
******** [step = 850] loss: 1.678, acc: 0.642
EPOCH = 29 loss: 1.678, acc: 0.642, val_loss: 2.010, val_acc: 0.626

================================================================================2025-08_10 16:19:31
******** [step = 50] loss: 1.625, acc: 0.650
******** [step = 100] loss: 1.600, acc: 0.652
******** [step = 150] loss: 1.605, acc: 0.651
******** [step = 200] loss: 1.609, acc: 0.650
******** [step = 250] loss: 1.616, acc: 0.649
******** [step = 300] loss: 1.620, acc: 0.649
******** [step = 350] loss: 1.627, acc: 0.648
******** [step = 400] loss: 1.633, acc: 0.647
******** [step = 450] loss: 1.637, acc: 0.647
******** [step = 500] loss: 1.639, acc: 0.647
******** [step = 550] loss: 1.644, acc: 0.646
******** [step = 600] loss: 1.648, acc: 0.646
******** [step = 650] loss: 1.652, acc: 0.646
******** [step = 700] loss: 1.656, acc: 0.645
******** [step = 750] loss: 1.660, acc: 0.645
******** [step = 800] loss: 1.662, acc: 0.645
******** [step = 850] loss: 1.667, acc: 0.645
EPOCH = 30 loss: 1.667, acc: 0.645, val_loss: 1.995, val_acc: 0.629

================================================================================2025-08_10 16:20:52
******** [step = 50] loss: 1.586, acc: 0.653
******** [step = 100] loss: 1.578, acc: 0.655
******** [step = 150] loss: 1.581, acc: 0.655
******** [step = 200] loss: 1.586, acc: 0.655
******** [step = 250] loss: 1.595, acc: 0.653
******** [step = 300] loss: 1.600, acc: 0.653
******** [step = 350] loss: 1.602, acc: 0.652
******** [step = 400] loss: 1.608, acc: 0.652
******** [step = 450] loss: 1.613, acc: 0.651
******** [step = 500] loss: 1.622, acc: 0.650
******** [step = 550] loss: 1.627, acc: 0.649
******** [step = 600] loss: 1.630, acc: 0.649
******** [step = 650] loss: 1.635, acc: 0.648
******** [step = 700] loss: 1.639, acc: 0.648
******** [step = 750] loss: 1.645, acc: 0.647
******** [step = 800] loss: 1.649, acc: 0.647
******** [step = 850] loss: 1.653, acc: 0.646
EPOCH = 31 loss: 1.653, acc: 0.646, val_loss: 2.004, val_acc: 0.627

================================================================================2025-08_10 16:22:14
******** [step = 50] loss: 1.567, acc: 0.656
******** [step = 100] loss: 1.568, acc: 0.657
******** [step = 150] loss: 1.572, acc: 0.656
******** [step = 200] loss: 1.578, acc: 0.656
******** [step = 250] loss: 1.586, acc: 0.655
******** [step = 300] loss: 1.591, acc: 0.654
******** [step = 350] loss: 1.597, acc: 0.653
******** [step = 400] loss: 1.603, acc: 0.652
******** [step = 450] loss: 1.607, acc: 0.652
******** [step = 500] loss: 1.611, acc: 0.652
******** [step = 550] loss: 1.615, acc: 0.651
******** [step = 600] loss: 1.619, acc: 0.651
******** [step = 650] loss: 1.625, acc: 0.650
******** [step = 700] loss: 1.629, acc: 0.650
******** [step = 750] loss: 1.633, acc: 0.649
******** [step = 800] loss: 1.635, acc: 0.649
******** [step = 850] loss: 1.637, acc: 0.649
EPOCH = 32 loss: 1.637, acc: 0.649, val_loss: 1.993, val_acc: 0.629

================================================================================2025-08_10 16:23:34
******** [step = 50] loss: 1.547, acc: 0.658
******** [step = 100] loss: 1.556, acc: 0.658
******** [step = 150] loss: 1.563, acc: 0.657
******** [step = 200] loss: 1.565, acc: 0.657
******** [step = 250] loss: 1.572, acc: 0.656
******** [step = 300] loss: 1.576, acc: 0.656
******** [step = 350] loss: 1.583, acc: 0.655
******** [step = 400] loss: 1.587, acc: 0.655
******** [step = 450] loss: 1.594, acc: 0.654
******** [step = 500] loss: 1.599, acc: 0.654
******** [step = 550] loss: 1.605, acc: 0.653
******** [step = 600] loss: 1.607, acc: 0.653
******** [step = 650] loss: 1.611, acc: 0.652
******** [step = 700] loss: 1.615, acc: 0.652
******** [step = 750] loss: 1.618, acc: 0.652
******** [step = 800] loss: 1.623, acc: 0.651
******** [step = 850] loss: 1.630, acc: 0.651
EPOCH = 33 loss: 1.630, acc: 0.651, val_loss: 1.981, val_acc: 0.633

================================================================================2025-08_10 16:24:55
******** [step = 50] loss: 1.580, acc: 0.655
******** [step = 100] loss: 1.565, acc: 0.658
******** [step = 150] loss: 1.568, acc: 0.658
******** [step = 200] loss: 1.567, acc: 0.658
******** [step = 250] loss: 1.570, acc: 0.657
******** [step = 300] loss: 1.576, acc: 0.657
******** [step = 350] loss: 1.575, acc: 0.657
******** [step = 400] loss: 1.579, acc: 0.656
******** [step = 450] loss: 1.586, acc: 0.655
******** [step = 500] loss: 1.588, acc: 0.655
******** [step = 550] loss: 1.592, acc: 0.655
******** [step = 600] loss: 1.596, acc: 0.655
******** [step = 650] loss: 1.598, acc: 0.655
******** [step = 700] loss: 1.602, acc: 0.654
******** [step = 750] loss: 1.605, acc: 0.654
******** [step = 800] loss: 1.609, acc: 0.653
******** [step = 850] loss: 1.614, acc: 0.653
EPOCH = 34 loss: 1.614, acc: 0.653, val_loss: 1.970, val_acc: 0.636

================================================================================2025-08_10 16:26:16
******** [step = 50] loss: 1.542, acc: 0.660
******** [step = 100] loss: 1.534, acc: 0.662
******** [step = 150] loss: 1.539, acc: 0.662
******** [step = 200] loss: 1.545, acc: 0.662
******** [step = 250] loss: 1.550, acc: 0.661
******** [step = 300] loss: 1.555, acc: 0.660
******** [step = 350] loss: 1.562, acc: 0.659
******** [step = 400] loss: 1.564, acc: 0.659
******** [step = 450] loss: 1.568, acc: 0.659
******** [step = 500] loss: 1.573, acc: 0.658
******** [step = 550] loss: 1.579, acc: 0.657
******** [step = 600] loss: 1.582, acc: 0.657
******** [step = 650] loss: 1.586, acc: 0.657
******** [step = 700] loss: 1.591, acc: 0.656
******** [step = 750] loss: 1.596, acc: 0.656
******** [step = 800] loss: 1.600, acc: 0.655
******** [step = 850] loss: 1.604, acc: 0.655
EPOCH = 35 loss: 1.604, acc: 0.655, val_loss: 1.966, val_acc: 0.636

================================================================================2025-08_10 16:27:36
******** [step = 50] loss: 1.528, acc: 0.663
******** [step = 100] loss: 1.527, acc: 0.664
******** [step = 150] loss: 1.536, acc: 0.663
******** [step = 200] loss: 1.537, acc: 0.663
******** [step = 250] loss: 1.540, acc: 0.662
******** [step = 300] loss: 1.545, acc: 0.662
******** [step = 350] loss: 1.550, acc: 0.661
******** [step = 400] loss: 1.555, acc: 0.660
******** [step = 450] loss: 1.558, acc: 0.660
******** [step = 500] loss: 1.562, acc: 0.660
******** [step = 550] loss: 1.567, acc: 0.659
******** [step = 600] loss: 1.572, acc: 0.659
******** [step = 650] loss: 1.577, acc: 0.658
******** [step = 700] loss: 1.580, acc: 0.658
******** [step = 750] loss: 1.584, acc: 0.657
******** [step = 800] loss: 1.588, acc: 0.657
******** [step = 850] loss: 1.593, acc: 0.656
EPOCH = 36 loss: 1.593, acc: 0.656, val_loss: 1.963, val_acc: 0.637

================================================================================2025-08_10 16:29:06
******** [step = 50] loss: 1.521, acc: 0.662
******** [step = 100] loss: 1.507, acc: 0.666
******** [step = 150] loss: 1.514, acc: 0.665
******** [step = 200] loss: 1.527, acc: 0.664
******** [step = 250] loss: 1.533, acc: 0.663
******** [step = 300] loss: 1.537, acc: 0.663
******** [step = 350] loss: 1.543, acc: 0.662
******** [step = 400] loss: 1.550, acc: 0.661
******** [step = 450] loss: 1.555, acc: 0.660
******** [step = 500] loss: 1.559, acc: 0.660
******** [step = 550] loss: 1.563, acc: 0.660
******** [step = 600] loss: 1.565, acc: 0.660
******** [step = 650] loss: 1.569, acc: 0.659
******** [step = 700] loss: 1.574, acc: 0.659
******** [step = 750] loss: 1.579, acc: 0.658
******** [step = 800] loss: 1.581, acc: 0.658
******** [step = 850] loss: 1.582, acc: 0.658
EPOCH = 37 loss: 1.582, acc: 0.658, val_loss: 1.955, val_acc: 0.638

================================================================================2025-08_10 16:30:27
******** [step = 50] loss: 1.504, acc: 0.667
******** [step = 100] loss: 1.499, acc: 0.668
******** [step = 150] loss: 1.496, acc: 0.669
******** [step = 200] loss: 1.499, acc: 0.668
******** [step = 250] loss: 1.508, acc: 0.667
******** [step = 300] loss: 1.517, acc: 0.666
******** [step = 350] loss: 1.524, acc: 0.665
******** [step = 400] loss: 1.528, acc: 0.665
******** [step = 450] loss: 1.534, acc: 0.664
******** [step = 500] loss: 1.541, acc: 0.663
******** [step = 550] loss: 1.547, acc: 0.663
******** [step = 600] loss: 1.552, acc: 0.662
******** [step = 650] loss: 1.555, acc: 0.662
******** [step = 700] loss: 1.560, acc: 0.661
******** [step = 750] loss: 1.563, acc: 0.661
******** [step = 800] loss: 1.568, acc: 0.660
******** [step = 850] loss: 1.571, acc: 0.660
EPOCH = 38 loss: 1.571, acc: 0.660, val_loss: 1.949, val_acc: 0.639

================================================================================2025-08_10 16:31:50
******** [step = 50] loss: 1.491, acc: 0.671
******** [step = 100] loss: 1.496, acc: 0.670
******** [step = 150] loss: 1.503, acc: 0.668
******** [step = 200] loss: 1.507, acc: 0.668
******** [step = 250] loss: 1.515, acc: 0.667
******** [step = 300] loss: 1.519, acc: 0.666
******** [step = 350] loss: 1.522, acc: 0.665
******** [step = 400] loss: 1.525, acc: 0.665
******** [step = 450] loss: 1.529, acc: 0.665
******** [step = 500] loss: 1.531, acc: 0.665
******** [step = 550] loss: 1.536, acc: 0.664
******** [step = 600] loss: 1.539, acc: 0.664
******** [step = 650] loss: 1.544, acc: 0.663
******** [step = 700] loss: 1.549, acc: 0.663
******** [step = 750] loss: 1.552, acc: 0.663
******** [step = 800] loss: 1.556, acc: 0.662
******** [step = 850] loss: 1.560, acc: 0.662
EPOCH = 39 loss: 1.560, acc: 0.662, val_loss: 1.943, val_acc: 0.641

================================================================================2025-08_10 16:33:12
******** [step = 50] loss: 1.472, acc: 0.673
******** [step = 100] loss: 1.482, acc: 0.670
******** [step = 150] loss: 1.490, acc: 0.670
******** [step = 200] loss: 1.492, acc: 0.669
******** [step = 250] loss: 1.496, acc: 0.669
******** [step = 300] loss: 1.503, acc: 0.668
******** [step = 350] loss: 1.510, acc: 0.667
******** [step = 400] loss: 1.517, acc: 0.666
******** [step = 450] loss: 1.520, acc: 0.666
******** [step = 500] loss: 1.523, acc: 0.666
******** [step = 550] loss: 1.528, acc: 0.665
******** [step = 600] loss: 1.531, acc: 0.665
******** [step = 650] loss: 1.538, acc: 0.664
******** [step = 700] loss: 1.541, acc: 0.664
******** [step = 750] loss: 1.545, acc: 0.664
******** [step = 800] loss: 1.549, acc: 0.663
******** [step = 850] loss: 1.550, acc: 0.663
EPOCH = 40 loss: 1.550, acc: 0.663, val_loss: 1.937, val_acc: 0.641

================================================================================2025-08_10 16:34:39
******** [step = 50] loss: 1.468, acc: 0.673
******** [step = 100] loss: 1.473, acc: 0.673
******** [step = 150] loss: 1.475, acc: 0.673
******** [step = 200] loss: 1.483, acc: 0.672
******** [step = 250] loss: 1.487, acc: 0.671
******** [step = 300] loss: 1.491, acc: 0.671
******** [step = 350] loss: 1.497, acc: 0.670
******** [step = 400] loss: 1.505, acc: 0.669
******** [step = 450] loss: 1.510, acc: 0.668
******** [step = 500] loss: 1.514, acc: 0.667
******** [step = 550] loss: 1.518, acc: 0.667
******** [step = 600] loss: 1.523, acc: 0.666
******** [step = 650] loss: 1.527, acc: 0.666
******** [step = 700] loss: 1.531, acc: 0.666
******** [step = 750] loss: 1.535, acc: 0.665
******** [step = 800] loss: 1.538, acc: 0.665
******** [step = 850] loss: 1.542, acc: 0.665
EPOCH = 41 loss: 1.542, acc: 0.665, val_loss: 1.941, val_acc: 0.641

================================================================================2025-08_10 16:36:05
******** [step = 50] loss: 1.470, acc: 0.673
******** [step = 100] loss: 1.461, acc: 0.675
******** [step = 150] loss: 1.464, acc: 0.675
******** [step = 200] loss: 1.467, acc: 0.675
******** [step = 250] loss: 1.474, acc: 0.674
******** [step = 300] loss: 1.480, acc: 0.673
******** [step = 350] loss: 1.485, acc: 0.672
******** [step = 400] loss: 1.495, acc: 0.671
******** [step = 450] loss: 1.502, acc: 0.670
******** [step = 500] loss: 1.504, acc: 0.670
******** [step = 550] loss: 1.510, acc: 0.669
******** [step = 600] loss: 1.513, acc: 0.669
******** [step = 650] loss: 1.518, acc: 0.668
******** [step = 700] loss: 1.522, acc: 0.668
******** [step = 750] loss: 1.526, acc: 0.667
******** [step = 800] loss: 1.529, acc: 0.667
******** [step = 850] loss: 1.531, acc: 0.667
EPOCH = 42 loss: 1.531, acc: 0.667, val_loss: 1.925, val_acc: 0.644

================================================================================2025-08_10 16:37:27
******** [step = 50] loss: 1.448, acc: 0.676
******** [step = 100] loss: 1.457, acc: 0.675
******** [step = 150] loss: 1.453, acc: 0.676
******** [step = 200] loss: 1.461, acc: 0.675
******** [step = 250] loss: 1.465, acc: 0.674
******** [step = 300] loss: 1.471, acc: 0.674
******** [step = 350] loss: 1.475, acc: 0.673
******** [step = 400] loss: 1.480, acc: 0.672
******** [step = 450] loss: 1.485, acc: 0.672
******** [step = 500] loss: 1.490, acc: 0.672
******** [step = 550] loss: 1.494, acc: 0.671
******** [step = 600] loss: 1.500, acc: 0.670
******** [step = 650] loss: 1.505, acc: 0.670
******** [step = 700] loss: 1.510, acc: 0.669
******** [step = 750] loss: 1.516, acc: 0.669
******** [step = 800] loss: 1.520, acc: 0.668
******** [step = 850] loss: 1.525, acc: 0.668
EPOCH = 43 loss: 1.525, acc: 0.668, val_loss: 1.927, val_acc: 0.644

================================================================================2025-08_10 16:38:49
******** [step = 50] loss: 1.459, acc: 0.675
******** [step = 100] loss: 1.449, acc: 0.676
******** [step = 150] loss: 1.459, acc: 0.674
******** [step = 200] loss: 1.460, acc: 0.674
******** [step = 250] loss: 1.466, acc: 0.674
******** [step = 300] loss: 1.472, acc: 0.674
******** [step = 350] loss: 1.474, acc: 0.674
******** [step = 400] loss: 1.478, acc: 0.673
******** [step = 450] loss: 1.483, acc: 0.673
******** [step = 500] loss: 1.487, acc: 0.672
******** [step = 550] loss: 1.492, acc: 0.672
******** [step = 600] loss: 1.495, acc: 0.672
******** [step = 650] loss: 1.499, acc: 0.671
******** [step = 700] loss: 1.504, acc: 0.671
******** [step = 750] loss: 1.508, acc: 0.670
******** [step = 800] loss: 1.511, acc: 0.670
******** [step = 850] loss: 1.515, acc: 0.670
EPOCH = 44 loss: 1.515, acc: 0.670, val_loss: 1.925, val_acc: 0.645

================================================================================2025-08_10 16:40:15
******** [step = 50] loss: 1.427, acc: 0.680
******** [step = 100] loss: 1.434, acc: 0.680
******** [step = 150] loss: 1.443, acc: 0.678
******** [step = 200] loss: 1.441, acc: 0.678
******** [step = 250] loss: 1.453, acc: 0.676
******** [step = 300] loss: 1.458, acc: 0.675
******** [step = 350] loss: 1.464, acc: 0.675
******** [step = 400] loss: 1.467, acc: 0.674
******** [step = 450] loss: 1.473, acc: 0.674
******** [step = 500] loss: 1.477, acc: 0.674
******** [step = 550] loss: 1.482, acc: 0.673
******** [step = 600] loss: 1.488, acc: 0.673
******** [step = 650] loss: 1.492, acc: 0.672
******** [step = 700] loss: 1.495, acc: 0.672
******** [step = 750] loss: 1.499, acc: 0.672
******** [step = 800] loss: 1.501, acc: 0.671
******** [step = 850] loss: 1.505, acc: 0.671
EPOCH = 45 loss: 1.505, acc: 0.671, val_loss: 1.935, val_acc: 0.643

================================================================================2025-08_10 16:41:37
******** [step = 50] loss: 1.432, acc: 0.679
******** [step = 100] loss: 1.420, acc: 0.681
******** [step = 150] loss: 1.426, acc: 0.680
******** [step = 200] loss: 1.440, acc: 0.678
******** [step = 250] loss: 1.448, acc: 0.676
******** [step = 300] loss: 1.453, acc: 0.676
******** [step = 350] loss: 1.459, acc: 0.676
******** [step = 400] loss: 1.462, acc: 0.675
******** [step = 450] loss: 1.469, acc: 0.675
******** [step = 500] loss: 1.472, acc: 0.674
******** [step = 550] loss: 1.477, acc: 0.673
******** [step = 600] loss: 1.480, acc: 0.673
******** [step = 650] loss: 1.484, acc: 0.673
******** [step = 700] loss: 1.486, acc: 0.673
******** [step = 750] loss: 1.490, acc: 0.672
******** [step = 800] loss: 1.495, acc: 0.672
******** [step = 850] loss: 1.497, acc: 0.672
EPOCH = 46 loss: 1.497, acc: 0.672, val_loss: 1.917, val_acc: 0.646

================================================================================2025-08_10 16:42:56
******** [step = 50] loss: 1.442, acc: 0.676
******** [step = 100] loss: 1.432, acc: 0.679
******** [step = 150] loss: 1.431, acc: 0.680
******** [step = 200] loss: 1.438, acc: 0.679
******** [step = 250] loss: 1.439, acc: 0.679
******** [step = 300] loss: 1.445, acc: 0.678
******** [step = 350] loss: 1.450, acc: 0.677
******** [step = 400] loss: 1.455, acc: 0.676
******** [step = 450] loss: 1.461, acc: 0.675
******** [step = 500] loss: 1.465, acc: 0.675
******** [step = 550] loss: 1.471, acc: 0.675
******** [step = 600] loss: 1.473, acc: 0.674
******** [step = 650] loss: 1.474, acc: 0.674
******** [step = 700] loss: 1.478, acc: 0.674
******** [step = 750] loss: 1.483, acc: 0.673
******** [step = 800] loss: 1.487, acc: 0.673
******** [step = 850] loss: 1.489, acc: 0.673
EPOCH = 47 loss: 1.489, acc: 0.673, val_loss: 1.908, val_acc: 0.647

================================================================================2025-08_10 16:44:19
******** [step = 50] loss: 1.396, acc: 0.684
******** [step = 100] loss: 1.409, acc: 0.684
******** [step = 150] loss: 1.411, acc: 0.683
******** [step = 200] loss: 1.424, acc: 0.681
******** [step = 250] loss: 1.428, acc: 0.681
******** [step = 300] loss: 1.433, acc: 0.680
******** [step = 350] loss: 1.439, acc: 0.680
******** [step = 400] loss: 1.446, acc: 0.679
******** [step = 450] loss: 1.449, acc: 0.678
******** [step = 500] loss: 1.454, acc: 0.678
******** [step = 550] loss: 1.461, acc: 0.677
******** [step = 600] loss: 1.464, acc: 0.677
******** [step = 650] loss: 1.469, acc: 0.676
******** [step = 700] loss: 1.473, acc: 0.676
******** [step = 750] loss: 1.478, acc: 0.675
******** [step = 800] loss: 1.481, acc: 0.675
******** [step = 850] loss: 1.485, acc: 0.674
EPOCH = 48 loss: 1.485, acc: 0.674, val_loss: 1.905, val_acc: 0.649

================================================================================2025-08_10 16:45:41
******** [step = 50] loss: 1.424, acc: 0.682
******** [step = 100] loss: 1.423, acc: 0.683
******** [step = 150] loss: 1.422, acc: 0.682
******** [step = 200] loss: 1.428, acc: 0.681
******** [step = 250] loss: 1.433, acc: 0.680
******** [step = 300] loss: 1.434, acc: 0.680
******** [step = 350] loss: 1.435, acc: 0.680
******** [step = 400] loss: 1.443, acc: 0.679
******** [step = 450] loss: 1.444, acc: 0.679
******** [step = 500] loss: 1.448, acc: 0.679
******** [step = 550] loss: 1.452, acc: 0.678
******** [step = 600] loss: 1.456, acc: 0.678
******** [step = 650] loss: 1.460, acc: 0.677
******** [step = 700] loss: 1.465, acc: 0.677
******** [step = 750] loss: 1.468, acc: 0.677
******** [step = 800] loss: 1.473, acc: 0.676
******** [step = 850] loss: 1.476, acc: 0.676
EPOCH = 49 loss: 1.476, acc: 0.676, val_loss: 1.898, val_acc: 0.650

================================================================================2025-08_10 16:47:01
******** [step = 50] loss: 1.402, acc: 0.683
******** [step = 100] loss: 1.401, acc: 0.685
******** [step = 150] loss: 1.410, acc: 0.684
******** [step = 200] loss: 1.416, acc: 0.683
******** [step = 250] loss: 1.418, acc: 0.683
******** [step = 300] loss: 1.425, acc: 0.682
******** [step = 350] loss: 1.431, acc: 0.681
******** [step = 400] loss: 1.435, acc: 0.680
******** [step = 450] loss: 1.438, acc: 0.680
******** [step = 500] loss: 1.443, acc: 0.680
******** [step = 550] loss: 1.447, acc: 0.679
******** [step = 600] loss: 1.451, acc: 0.679
******** [step = 650] loss: 1.454, acc: 0.679
******** [step = 700] loss: 1.459, acc: 0.678
******** [step = 750] loss: 1.463, acc: 0.678
******** [step = 800] loss: 1.466, acc: 0.677
******** [step = 850] loss: 1.471, acc: 0.677
EPOCH = 50 loss: 1.471, acc: 0.677, val_loss: 1.898, val_acc: 0.650

================================================================================2025-08_10 16:48:23
******** [step = 50] loss: 1.412, acc: 0.683
******** [step = 100] loss: 1.397, acc: 0.687
******** [step = 150] loss: 1.400, acc: 0.686
******** [step = 200] loss: 1.409, acc: 0.685
******** [step = 250] loss: 1.416, acc: 0.683
******** [step = 300] loss: 1.423, acc: 0.682
******** [step = 350] loss: 1.428, acc: 0.682
******** [step = 400] loss: 1.432, acc: 0.681
******** [step = 450] loss: 1.438, acc: 0.680
******** [step = 500] loss: 1.441, acc: 0.680
******** [step = 550] loss: 1.444, acc: 0.680
******** [step = 600] loss: 1.445, acc: 0.680
******** [step = 650] loss: 1.450, acc: 0.680
******** [step = 700] loss: 1.453, acc: 0.679
******** [step = 750] loss: 1.457, acc: 0.679
******** [step = 800] loss: 1.460, acc: 0.679
******** [step = 850] loss: 1.466, acc: 0.678
EPOCH = 51 loss: 1.466, acc: 0.678, val_loss: 1.895, val_acc: 0.651

================================================================================2025-08_10 16:49:53
******** [step = 50] loss: 1.366, acc: 0.691
******** [step = 100] loss: 1.373, acc: 0.689
******** [step = 150] loss: 1.387, acc: 0.687
******** [step = 200] loss: 1.398, acc: 0.686
******** [step = 250] loss: 1.404, acc: 0.685
******** [step = 300] loss: 1.410, acc: 0.685
******** [step = 350] loss: 1.414, acc: 0.684
******** [step = 400] loss: 1.420, acc: 0.683
******** [step = 450] loss: 1.425, acc: 0.683
******** [step = 500] loss: 1.430, acc: 0.682
******** [step = 550] loss: 1.438, acc: 0.681
******** [step = 600] loss: 1.442, acc: 0.680
******** [step = 650] loss: 1.443, acc: 0.680
******** [step = 700] loss: 1.447, acc: 0.680
******** [step = 750] loss: 1.452, acc: 0.679
******** [step = 800] loss: 1.454, acc: 0.679
******** [step = 850] loss: 1.458, acc: 0.679
EPOCH = 52 loss: 1.458, acc: 0.679, val_loss: 1.891, val_acc: 0.651

================================================================================2025-08_10 16:51:20
******** [step = 50] loss: 1.363, acc: 0.693
******** [step = 100] loss: 1.367, acc: 0.693
******** [step = 150] loss: 1.378, acc: 0.691
******** [step = 200] loss: 1.385, acc: 0.690
******** [step = 250] loss: 1.391, acc: 0.689
******** [step = 300] loss: 1.399, acc: 0.687
******** [step = 350] loss: 1.407, acc: 0.686
******** [step = 400] loss: 1.410, acc: 0.686
******** [step = 450] loss: 1.415, acc: 0.685
******** [step = 500] loss: 1.419, acc: 0.685
******** [step = 550] loss: 1.423, acc: 0.684
******** [step = 600] loss: 1.427, acc: 0.684
******** [step = 650] loss: 1.431, acc: 0.683
******** [step = 700] loss: 1.435, acc: 0.683
******** [step = 750] loss: 1.440, acc: 0.682
******** [step = 800] loss: 1.444, acc: 0.682
******** [step = 850] loss: 1.448, acc: 0.681
EPOCH = 53 loss: 1.448, acc: 0.681, val_loss: 1.885, val_acc: 0.653

================================================================================2025-08_10 16:52:40
******** [step = 50] loss: 1.370, acc: 0.691
******** [step = 100] loss: 1.371, acc: 0.691
******** [step = 150] loss: 1.374, acc: 0.690
******** [step = 200] loss: 1.378, acc: 0.690
******** [step = 250] loss: 1.385, acc: 0.689
******** [step = 300] loss: 1.391, acc: 0.687
******** [step = 350] loss: 1.398, acc: 0.686
******** [step = 400] loss: 1.402, acc: 0.686
******** [step = 450] loss: 1.406, acc: 0.685
******** [step = 500] loss: 1.412, acc: 0.685
******** [step = 550] loss: 1.418, acc: 0.684
******** [step = 600] loss: 1.423, acc: 0.683
******** [step = 650] loss: 1.427, acc: 0.683
******** [step = 700] loss: 1.432, acc: 0.683
******** [step = 750] loss: 1.436, acc: 0.682
******** [step = 800] loss: 1.440, acc: 0.682
******** [step = 850] loss: 1.445, acc: 0.681
EPOCH = 54 loss: 1.445, acc: 0.681, val_loss: 1.885, val_acc: 0.654

================================================================================2025-08_10 16:54:01
******** [step = 50] loss: 1.386, acc: 0.688
******** [step = 100] loss: 1.375, acc: 0.691
******** [step = 150] loss: 1.379, acc: 0.689
******** [step = 200] loss: 1.378, acc: 0.690
******** [step = 250] loss: 1.384, acc: 0.689
******** [step = 300] loss: 1.389, acc: 0.689
******** [step = 350] loss: 1.394, acc: 0.688
******** [step = 400] loss: 1.400, acc: 0.687
******** [step = 450] loss: 1.407, acc: 0.686
******** [step = 500] loss: 1.411, acc: 0.686
******** [step = 550] loss: 1.415, acc: 0.685
******** [step = 600] loss: 1.419, acc: 0.685
******** [step = 650] loss: 1.423, acc: 0.685
******** [step = 700] loss: 1.427, acc: 0.684
******** [step = 750] loss: 1.432, acc: 0.683
******** [step = 800] loss: 1.435, acc: 0.683
******** [step = 850] loss: 1.438, acc: 0.683
EPOCH = 55 loss: 1.438, acc: 0.683, val_loss: 1.884, val_acc: 0.654

================================================================================2025-08_10 16:55:21
******** [step = 50] loss: 1.366, acc: 0.691
******** [step = 100] loss: 1.365, acc: 0.692
******** [step = 150] loss: 1.375, acc: 0.690
******** [step = 200] loss: 1.378, acc: 0.690
******** [step = 250] loss: 1.383, acc: 0.689
******** [step = 300] loss: 1.384, acc: 0.689
******** [step = 350] loss: 1.388, acc: 0.688
******** [step = 400] loss: 1.395, acc: 0.687
******** [step = 450] loss: 1.400, acc: 0.687
******** [step = 500] loss: 1.403, acc: 0.686
******** [step = 550] loss: 1.408, acc: 0.686
******** [step = 600] loss: 1.413, acc: 0.685
******** [step = 650] loss: 1.418, acc: 0.685
******** [step = 700] loss: 1.421, acc: 0.685
******** [step = 750] loss: 1.425, acc: 0.684
******** [step = 800] loss: 1.429, acc: 0.684
******** [step = 850] loss: 1.434, acc: 0.683
EPOCH = 56 loss: 1.434, acc: 0.683, val_loss: 1.881, val_acc: 0.653

================================================================================2025-08_10 16:56:41
******** [step = 50] loss: 1.349, acc: 0.694
******** [step = 100] loss: 1.359, acc: 0.693
******** [step = 150] loss: 1.359, acc: 0.693
******** [step = 200] loss: 1.365, acc: 0.691
******** [step = 250] loss: 1.370, acc: 0.691
******** [step = 300] loss: 1.372, acc: 0.691
******** [step = 350] loss: 1.382, acc: 0.689
******** [step = 400] loss: 1.387, acc: 0.688
******** [step = 450] loss: 1.393, acc: 0.688
******** [step = 500] loss: 1.398, acc: 0.687
******** [step = 550] loss: 1.403, acc: 0.687
******** [step = 600] loss: 1.407, acc: 0.686
******** [step = 650] loss: 1.412, acc: 0.686
******** [step = 700] loss: 1.416, acc: 0.685
******** [step = 750] loss: 1.421, acc: 0.685
******** [step = 800] loss: 1.424, acc: 0.685
******** [step = 850] loss: 1.428, acc: 0.684
EPOCH = 57 loss: 1.428, acc: 0.684, val_loss: 1.878, val_acc: 0.655

================================================================================2025-08_10 16:58:01
******** [step = 50] loss: 1.350, acc: 0.693
******** [step = 100] loss: 1.347, acc: 0.694
******** [step = 150] loss: 1.354, acc: 0.693
******** [step = 200] loss: 1.358, acc: 0.693
******** [step = 250] loss: 1.365, acc: 0.692
******** [step = 300] loss: 1.372, acc: 0.691
******** [step = 350] loss: 1.375, acc: 0.691
******** [step = 400] loss: 1.382, acc: 0.689
******** [step = 450] loss: 1.388, acc: 0.689
******** [step = 500] loss: 1.394, acc: 0.688
******** [step = 550] loss: 1.398, acc: 0.688
******** [step = 600] loss: 1.403, acc: 0.687
******** [step = 650] loss: 1.408, acc: 0.687
******** [step = 700] loss: 1.412, acc: 0.686
******** [step = 750] loss: 1.416, acc: 0.686
******** [step = 800] loss: 1.419, acc: 0.686
******** [step = 850] loss: 1.422, acc: 0.685
EPOCH = 58 loss: 1.422, acc: 0.685, val_loss: 1.874, val_acc: 0.655

================================================================================2025-08_10 16:59:22
******** [step = 50] loss: 1.350, acc: 0.694
******** [step = 100] loss: 1.349, acc: 0.693
******** [step = 150] loss: 1.352, acc: 0.695
******** [step = 200] loss: 1.360, acc: 0.692
******** [step = 250] loss: 1.364, acc: 0.692
******** [step = 300] loss: 1.368, acc: 0.692
******** [step = 350] loss: 1.372, acc: 0.691
******** [step = 400] loss: 1.375, acc: 0.691
******** [step = 450] loss: 1.380, acc: 0.690
******** [step = 500] loss: 1.385, acc: 0.689
******** [step = 550] loss: 1.391, acc: 0.688
******** [step = 600] loss: 1.397, acc: 0.688
******** [step = 650] loss: 1.399, acc: 0.688
******** [step = 700] loss: 1.404, acc: 0.687
******** [step = 750] loss: 1.409, acc: 0.687
******** [step = 800] loss: 1.414, acc: 0.687
******** [step = 850] loss: 1.418, acc: 0.686
EPOCH = 59 loss: 1.418, acc: 0.686, val_loss: 1.876, val_acc: 0.656

================================================================================2025-08_10 17:00:42
******** [step = 50] loss: 1.312, acc: 0.701
******** [step = 100] loss: 1.323, acc: 0.700
******** [step = 150] loss: 1.333, acc: 0.698
******** [step = 200] loss: 1.346, acc: 0.696
******** [step = 250] loss: 1.351, acc: 0.695
******** [step = 300] loss: 1.359, acc: 0.694
******** [step = 350] loss: 1.366, acc: 0.694
******** [step = 400] loss: 1.371, acc: 0.693
******** [step = 450] loss: 1.377, acc: 0.692
******** [step = 500] loss: 1.382, acc: 0.691
******** [step = 550] loss: 1.386, acc: 0.691
******** [step = 600] loss: 1.391, acc: 0.690
******** [step = 650] loss: 1.396, acc: 0.689
******** [step = 700] loss: 1.401, acc: 0.689
******** [step = 750] loss: 1.404, acc: 0.688
******** [step = 800] loss: 1.408, acc: 0.688
******** [step = 850] loss: 1.414, acc: 0.687
EPOCH = 60 loss: 1.414, acc: 0.687, val_loss: 1.869, val_acc: 0.657

================================================================================2025-08_10 17:02:05
******** [step = 50] loss: 1.323, acc: 0.698
******** [step = 100] loss: 1.336, acc: 0.697
******** [step = 150] loss: 1.344, acc: 0.696
******** [step = 200] loss: 1.348, acc: 0.695
******** [step = 250] loss: 1.353, acc: 0.695
******** [step = 300] loss: 1.355, acc: 0.695
******** [step = 350] loss: 1.359, acc: 0.694
******** [step = 400] loss: 1.366, acc: 0.693
******** [step = 450] loss: 1.371, acc: 0.692
******** [step = 500] loss: 1.376, acc: 0.692
******** [step = 550] loss: 1.380, acc: 0.691
******** [step = 600] loss: 1.383, acc: 0.691
******** [step = 650] loss: 1.389, acc: 0.690
******** [step = 700] loss: 1.393, acc: 0.690
******** [step = 750] loss: 1.397, acc: 0.689
******** [step = 800] loss: 1.402, acc: 0.689
******** [step = 850] loss: 1.404, acc: 0.689
EPOCH = 61 loss: 1.404, acc: 0.689, val_loss: 1.866, val_acc: 0.658

================================================================================2025-08_10 17:03:28
******** [step = 50] loss: 1.338, acc: 0.697
******** [step = 100] loss: 1.328, acc: 0.699
******** [step = 150] loss: 1.332, acc: 0.698
******** [step = 200] loss: 1.341, acc: 0.697
******** [step = 250] loss: 1.344, acc: 0.696
******** [step = 300] loss: 1.349, acc: 0.696
******** [step = 350] loss: 1.354, acc: 0.695
******** [step = 400] loss: 1.361, acc: 0.694
******** [step = 450] loss: 1.367, acc: 0.693
******** [step = 500] loss: 1.375, acc: 0.692
******** [step = 550] loss: 1.379, acc: 0.691
******** [step = 600] loss: 1.383, acc: 0.691
******** [step = 650] loss: 1.387, acc: 0.691
******** [step = 700] loss: 1.393, acc: 0.690
******** [step = 750] loss: 1.397, acc: 0.689
******** [step = 800] loss: 1.400, acc: 0.689
******** [step = 850] loss: 1.403, acc: 0.689
EPOCH = 62 loss: 1.403, acc: 0.689, val_loss: 1.870, val_acc: 0.658

================================================================================2025-08_10 17:04:49
******** [step = 50] loss: 1.306, acc: 0.702
******** [step = 100] loss: 1.309, acc: 0.702
******** [step = 150] loss: 1.313, acc: 0.701
******** [step = 200] loss: 1.325, acc: 0.699
******** [step = 250] loss: 1.334, acc: 0.698
******** [step = 300] loss: 1.342, acc: 0.696
******** [step = 350] loss: 1.350, acc: 0.695
******** [step = 400] loss: 1.357, acc: 0.694
******** [step = 450] loss: 1.363, acc: 0.693
******** [step = 500] loss: 1.367, acc: 0.693
******** [step = 550] loss: 1.373, acc: 0.692
******** [step = 600] loss: 1.379, acc: 0.692
******** [step = 650] loss: 1.384, acc: 0.691
******** [step = 700] loss: 1.387, acc: 0.691
******** [step = 750] loss: 1.392, acc: 0.690
******** [step = 800] loss: 1.395, acc: 0.690
******** [step = 850] loss: 1.399, acc: 0.690
EPOCH = 63 loss: 1.399, acc: 0.690, val_loss: 1.868, val_acc: 0.658

================================================================================2025-08_10 17:06:08
******** [step = 50] loss: 1.302, acc: 0.701
******** [step = 100] loss: 1.318, acc: 0.699
******** [step = 150] loss: 1.330, acc: 0.698
******** [step = 200] loss: 1.334, acc: 0.698
******** [step = 250] loss: 1.341, acc: 0.697
******** [step = 300] loss: 1.346, acc: 0.696
******** [step = 350] loss: 1.351, acc: 0.695
******** [step = 400] loss: 1.358, acc: 0.695
******** [step = 450] loss: 1.361, acc: 0.694
******** [step = 500] loss: 1.365, acc: 0.694
******** [step = 550] loss: 1.370, acc: 0.693
******** [step = 600] loss: 1.375, acc: 0.693
******** [step = 650] loss: 1.378, acc: 0.692
******** [step = 700] loss: 1.382, acc: 0.692
******** [step = 750] loss: 1.387, acc: 0.691
******** [step = 800] loss: 1.390, acc: 0.691
******** [step = 850] loss: 1.393, acc: 0.691
EPOCH = 64 loss: 1.393, acc: 0.691, val_loss: 1.863, val_acc: 0.660

================================================================================2025-08_10 17:07:30
******** [step = 50] loss: 1.326, acc: 0.701
******** [step = 100] loss: 1.323, acc: 0.701
******** [step = 150] loss: 1.334, acc: 0.699
******** [step = 200] loss: 1.335, acc: 0.699
******** [step = 250] loss: 1.335, acc: 0.698
******** [step = 300] loss: 1.338, acc: 0.698
******** [step = 350] loss: 1.343, acc: 0.697
******** [step = 400] loss: 1.350, acc: 0.696
******** [step = 450] loss: 1.355, acc: 0.695
******** [step = 500] loss: 1.360, acc: 0.694
******** [step = 550] loss: 1.364, acc: 0.694
******** [step = 600] loss: 1.368, acc: 0.693
******** [step = 650] loss: 1.373, acc: 0.693
******** [step = 700] loss: 1.377, acc: 0.692
******** [step = 750] loss: 1.381, acc: 0.692
******** [step = 800] loss: 1.384, acc: 0.692
******** [step = 850] loss: 1.387, acc: 0.691
EPOCH = 65 loss: 1.387, acc: 0.691, val_loss: 1.862, val_acc: 0.659

================================================================================2025-08_10 17:08:50
******** [step = 50] loss: 1.318, acc: 0.700
******** [step = 100] loss: 1.321, acc: 0.700
******** [step = 150] loss: 1.321, acc: 0.700
******** [step = 200] loss: 1.323, acc: 0.700
******** [step = 250] loss: 1.330, acc: 0.698
******** [step = 300] loss: 1.333, acc: 0.698
******** [step = 350] loss: 1.341, acc: 0.697
******** [step = 400] loss: 1.348, acc: 0.696
******** [step = 450] loss: 1.350, acc: 0.695
******** [step = 500] loss: 1.354, acc: 0.695
******** [step = 550] loss: 1.357, acc: 0.694
******** [step = 600] loss: 1.360, acc: 0.694
******** [step = 650] loss: 1.365, acc: 0.694
******** [step = 700] loss: 1.370, acc: 0.693
******** [step = 750] loss: 1.375, acc: 0.693
******** [step = 800] loss: 1.379, acc: 0.693
******** [step = 850] loss: 1.382, acc: 0.692
EPOCH = 66 loss: 1.382, acc: 0.692, val_loss: 1.860, val_acc: 0.662

================================================================================2025-08_10 17:10:10
******** [step = 50] loss: 1.300, acc: 0.703
******** [step = 100] loss: 1.310, acc: 0.702
******** [step = 150] loss: 1.315, acc: 0.703
******** [step = 200] loss: 1.320, acc: 0.702
******** [step = 250] loss: 1.324, acc: 0.701
******** [step = 300] loss: 1.331, acc: 0.700
******** [step = 350] loss: 1.336, acc: 0.699
******** [step = 400] loss: 1.342, acc: 0.698
******** [step = 450] loss: 1.345, acc: 0.698
******** [step = 500] loss: 1.351, acc: 0.697
******** [step = 550] loss: 1.357, acc: 0.696
******** [step = 600] loss: 1.361, acc: 0.695
******** [step = 650] loss: 1.364, acc: 0.695
******** [step = 700] loss: 1.367, acc: 0.695
******** [step = 750] loss: 1.370, acc: 0.695
******** [step = 800] loss: 1.373, acc: 0.694
******** [step = 850] loss: 1.378, acc: 0.694
EPOCH = 67 loss: 1.378, acc: 0.694, val_loss: 1.860, val_acc: 0.659

================================================================================2025-08_10 17:11:32
******** [step = 50] loss: 1.306, acc: 0.701
******** [step = 100] loss: 1.310, acc: 0.700
******** [step = 150] loss: 1.315, acc: 0.700
******** [step = 200] loss: 1.318, acc: 0.700
******** [step = 250] loss: 1.323, acc: 0.700
******** [step = 300] loss: 1.329, acc: 0.699
******** [step = 350] loss: 1.332, acc: 0.699
******** [step = 400] loss: 1.336, acc: 0.698
******** [step = 450] loss: 1.340, acc: 0.698
******** [step = 500] loss: 1.345, acc: 0.697
******** [step = 550] loss: 1.347, acc: 0.697
******** [step = 600] loss: 1.352, acc: 0.697
******** [step = 650] loss: 1.356, acc: 0.696
******** [step = 700] loss: 1.360, acc: 0.696
******** [step = 750] loss: 1.364, acc: 0.695
******** [step = 800] loss: 1.369, acc: 0.695
******** [step = 850] loss: 1.373, acc: 0.694
EPOCH = 68 loss: 1.373, acc: 0.694, val_loss: 1.851, val_acc: 0.662

================================================================================2025-08_10 17:12:55
******** [step = 50] loss: 1.291, acc: 0.705
******** [step = 100] loss: 1.305, acc: 0.703
******** [step = 150] loss: 1.306, acc: 0.703
******** [step = 200] loss: 1.310, acc: 0.702
******** [step = 250] loss: 1.317, acc: 0.701
******** [step = 300] loss: 1.322, acc: 0.700
******** [step = 350] loss: 1.325, acc: 0.700
******** [step = 400] loss: 1.331, acc: 0.699
******** [step = 450] loss: 1.337, acc: 0.698
******** [step = 500] loss: 1.342, acc: 0.698
******** [step = 550] loss: 1.346, acc: 0.697
******** [step = 600] loss: 1.349, acc: 0.697
******** [step = 650] loss: 1.354, acc: 0.697
******** [step = 700] loss: 1.358, acc: 0.696
******** [step = 750] loss: 1.362, acc: 0.696
******** [step = 800] loss: 1.367, acc: 0.695
******** [step = 850] loss: 1.372, acc: 0.695
EPOCH = 69 loss: 1.372, acc: 0.695, val_loss: 1.852, val_acc: 0.660

================================================================================2025-08_10 17:14:15
******** [step = 50] loss: 1.289, acc: 0.704
******** [step = 100] loss: 1.293, acc: 0.703
******** [step = 150] loss: 1.297, acc: 0.703
******** [step = 200] loss: 1.307, acc: 0.702
******** [step = 250] loss: 1.315, acc: 0.701
******** [step = 300] loss: 1.321, acc: 0.701
******** [step = 350] loss: 1.325, acc: 0.700
******** [step = 400] loss: 1.328, acc: 0.700
******** [step = 450] loss: 1.332, acc: 0.699
******** [step = 500] loss: 1.338, acc: 0.698
******** [step = 550] loss: 1.342, acc: 0.698
******** [step = 600] loss: 1.345, acc: 0.698
******** [step = 650] loss: 1.350, acc: 0.697
******** [step = 700] loss: 1.353, acc: 0.697
******** [step = 750] loss: 1.356, acc: 0.697
******** [step = 800] loss: 1.361, acc: 0.696
******** [step = 850] loss: 1.364, acc: 0.696
EPOCH = 70 loss: 1.364, acc: 0.696, val_loss: 1.857, val_acc: 0.658

================================================================================2025-08_10 17:15:35
******** [step = 50] loss: 1.290, acc: 0.703
******** [step = 100] loss: 1.289, acc: 0.704
******** [step = 150] loss: 1.298, acc: 0.704
******** [step = 200] loss: 1.304, acc: 0.704
******** [step = 250] loss: 1.303, acc: 0.703
******** [step = 300] loss: 1.305, acc: 0.703
******** [step = 350] loss: 1.309, acc: 0.703
******** [step = 400] loss: 1.317, acc: 0.701
******** [step = 450] loss: 1.325, acc: 0.700
******** [step = 500] loss: 1.332, acc: 0.699
******** [step = 550] loss: 1.336, acc: 0.699
******** [step = 600] loss: 1.340, acc: 0.699
******** [step = 650] loss: 1.345, acc: 0.698
******** [step = 700] loss: 1.350, acc: 0.697
******** [step = 750] loss: 1.353, acc: 0.697
******** [step = 800] loss: 1.357, acc: 0.697
******** [step = 850] loss: 1.361, acc: 0.696
EPOCH = 71 loss: 1.361, acc: 0.696, val_loss: 1.852, val_acc: 0.662

================================================================================2025-08_10 17:16:54
******** [step = 50] loss: 1.277, acc: 0.704
******** [step = 100] loss: 1.283, acc: 0.705
******** [step = 150] loss: 1.297, acc: 0.703
******** [step = 200] loss: 1.296, acc: 0.703
******** [step = 250] loss: 1.300, acc: 0.703
******** [step = 300] loss: 1.304, acc: 0.702
******** [step = 350] loss: 1.310, acc: 0.701
******** [step = 400] loss: 1.317, acc: 0.701
******** [step = 450] loss: 1.320, acc: 0.701
******** [step = 500] loss: 1.326, acc: 0.700
******** [step = 550] loss: 1.332, acc: 0.699
******** [step = 600] loss: 1.337, acc: 0.698
******** [step = 650] loss: 1.341, acc: 0.698
******** [step = 700] loss: 1.346, acc: 0.698
******** [step = 750] loss: 1.349, acc: 0.697
******** [step = 800] loss: 1.353, acc: 0.697
******** [step = 850] loss: 1.356, acc: 0.697
EPOCH = 72 loss: 1.356, acc: 0.697, val_loss: 1.852, val_acc: 0.662

================================================================================2025-08_10 17:18:23
******** [step = 50] loss: 1.273, acc: 0.706
******** [step = 100] loss: 1.279, acc: 0.706
******** [step = 150] loss: 1.291, acc: 0.705
******** [step = 200] loss: 1.294, acc: 0.704
******** [step = 250] loss: 1.297, acc: 0.704
******** [step = 300] loss: 1.305, acc: 0.703
******** [step = 350] loss: 1.311, acc: 0.702
******** [step = 400] loss: 1.315, acc: 0.702
******** [step = 450] loss: 1.321, acc: 0.701
******** [step = 500] loss: 1.323, acc: 0.701
******** [step = 550] loss: 1.330, acc: 0.700
******** [step = 600] loss: 1.334, acc: 0.700
******** [step = 650] loss: 1.339, acc: 0.699
******** [step = 700] loss: 1.342, acc: 0.699
******** [step = 750] loss: 1.345, acc: 0.699
******** [step = 800] loss: 1.349, acc: 0.698
******** [step = 850] loss: 1.352, acc: 0.698
EPOCH = 73 loss: 1.352, acc: 0.698, val_loss: 1.846, val_acc: 0.664

================================================================================2025-08_10 17:19:55
******** [step = 50] loss: 1.276, acc: 0.707
******** [step = 100] loss: 1.276, acc: 0.707
******** [step = 150] loss: 1.279, acc: 0.707
******** [step = 200] loss: 1.288, acc: 0.706
******** [step = 250] loss: 1.296, acc: 0.705
******** [step = 300] loss: 1.304, acc: 0.704
******** [step = 350] loss: 1.307, acc: 0.703
******** [step = 400] loss: 1.313, acc: 0.702
******** [step = 450] loss: 1.318, acc: 0.702
******** [step = 500] loss: 1.322, acc: 0.701
******** [step = 550] loss: 1.326, acc: 0.701
******** [step = 600] loss: 1.330, acc: 0.701
******** [step = 650] loss: 1.334, acc: 0.700
******** [step = 700] loss: 1.338, acc: 0.700
******** [step = 750] loss: 1.343, acc: 0.700
******** [step = 800] loss: 1.346, acc: 0.699
******** [step = 850] loss: 1.349, acc: 0.699
EPOCH = 74 loss: 1.349, acc: 0.699, val_loss: 1.848, val_acc: 0.664

================================================================================2025-08_10 17:21:21
******** [step = 50] loss: 1.266, acc: 0.709
******** [step = 100] loss: 1.283, acc: 0.706
******** [step = 150] loss: 1.283, acc: 0.706
******** [step = 200] loss: 1.289, acc: 0.705
******** [step = 250] loss: 1.292, acc: 0.705
******** [step = 300] loss: 1.297, acc: 0.705
******** [step = 350] loss: 1.304, acc: 0.704
******** [step = 400] loss: 1.305, acc: 0.704
******** [step = 450] loss: 1.309, acc: 0.703
******** [step = 500] loss: 1.312, acc: 0.703
******** [step = 550] loss: 1.316, acc: 0.702
******** [step = 600] loss: 1.321, acc: 0.702
******** [step = 650] loss: 1.327, acc: 0.701
******** [step = 700] loss: 1.332, acc: 0.701
******** [step = 750] loss: 1.337, acc: 0.700
******** [step = 800] loss: 1.340, acc: 0.700
******** [step = 850] loss: 1.343, acc: 0.700
EPOCH = 75 loss: 1.343, acc: 0.700, val_loss: 1.842, val_acc: 0.664

================================================================================2025-08_10 17:22:43
******** [step = 50] loss: 1.279, acc: 0.707
******** [step = 100] loss: 1.271, acc: 0.709
******** [step = 150] loss: 1.280, acc: 0.707
******** [step = 200] loss: 1.286, acc: 0.706
******** [step = 250] loss: 1.292, acc: 0.706
******** [step = 300] loss: 1.295, acc: 0.705
******** [step = 350] loss: 1.300, acc: 0.704
******** [step = 400] loss: 1.304, acc: 0.704
******** [step = 450] loss: 1.307, acc: 0.704
******** [step = 500] loss: 1.312, acc: 0.703
******** [step = 550] loss: 1.316, acc: 0.703
******** [step = 600] loss: 1.322, acc: 0.702
******** [step = 650] loss: 1.326, acc: 0.702
******** [step = 700] loss: 1.330, acc: 0.701
******** [step = 750] loss: 1.333, acc: 0.701
******** [step = 800] loss: 1.336, acc: 0.701
******** [step = 850] loss: 1.340, acc: 0.700
EPOCH = 76 loss: 1.340, acc: 0.700, val_loss: 1.839, val_acc: 0.665

================================================================================2025-08_10 17:24:03
******** [step = 50] loss: 1.266, acc: 0.708
******** [step = 100] loss: 1.255, acc: 0.711
******** [step = 150] loss: 1.261, acc: 0.709
******** [step = 200] loss: 1.269, acc: 0.709
******** [step = 250] loss: 1.278, acc: 0.708
******** [step = 300] loss: 1.283, acc: 0.707
******** [step = 350] loss: 1.290, acc: 0.706
******** [step = 400] loss: 1.296, acc: 0.706
******** [step = 450] loss: 1.301, acc: 0.705
******** [step = 500] loss: 1.306, acc: 0.704
******** [step = 550] loss: 1.310, acc: 0.704
******** [step = 600] loss: 1.314, acc: 0.704
******** [step = 650] loss: 1.319, acc: 0.703
******** [step = 700] loss: 1.322, acc: 0.703
******** [step = 750] loss: 1.326, acc: 0.702
******** [step = 800] loss: 1.331, acc: 0.702
******** [step = 850] loss: 1.335, acc: 0.701
EPOCH = 77 loss: 1.335, acc: 0.701, val_loss: 1.836, val_acc: 0.666

================================================================================2025-08_10 17:25:24
******** [step = 50] loss: 1.254, acc: 0.714
******** [step = 100] loss: 1.259, acc: 0.711
******** [step = 150] loss: 1.265, acc: 0.711
******** [step = 200] loss: 1.267, acc: 0.710
******** [step = 250] loss: 1.276, acc: 0.708
******** [step = 300] loss: 1.282, acc: 0.708
******** [step = 350] loss: 1.289, acc: 0.707
******** [step = 400] loss: 1.296, acc: 0.706
******** [step = 450] loss: 1.303, acc: 0.705
******** [step = 500] loss: 1.306, acc: 0.705
******** [step = 550] loss: 1.311, acc: 0.704
******** [step = 600] loss: 1.314, acc: 0.704
******** [step = 650] loss: 1.317, acc: 0.704
******** [step = 700] loss: 1.321, acc: 0.703
******** [step = 750] loss: 1.325, acc: 0.703
******** [step = 800] loss: 1.329, acc: 0.703
******** [step = 850] loss: 1.332, acc: 0.702
EPOCH = 78 loss: 1.332, acc: 0.702, val_loss: 1.838, val_acc: 0.665

================================================================================2025-08_10 17:26:44
******** [step = 50] loss: 1.252, acc: 0.711
******** [step = 100] loss: 1.244, acc: 0.712
******** [step = 150] loss: 1.251, acc: 0.711
******** [step = 200] loss: 1.258, acc: 0.711
******** [step = 250] loss: 1.265, acc: 0.710
******** [step = 300] loss: 1.271, acc: 0.709
******** [step = 350] loss: 1.278, acc: 0.708
******** [step = 400] loss: 1.282, acc: 0.708
******** [step = 450] loss: 1.287, acc: 0.707
******** [step = 500] loss: 1.294, acc: 0.706
******** [step = 550] loss: 1.300, acc: 0.706
******** [step = 600] loss: 1.306, acc: 0.705
******** [step = 650] loss: 1.311, acc: 0.704
******** [step = 700] loss: 1.315, acc: 0.704
******** [step = 750] loss: 1.320, acc: 0.703
******** [step = 800] loss: 1.324, acc: 0.703
******** [step = 850] loss: 1.328, acc: 0.702
EPOCH = 79 loss: 1.328, acc: 0.702, val_loss: 1.833, val_acc: 0.666

================================================================================2025-08_10 17:28:12
******** [step = 50] loss: 1.236, acc: 0.712
******** [step = 100] loss: 1.245, acc: 0.713
******** [step = 150] loss: 1.249, acc: 0.713
******** [step = 200] loss: 1.254, acc: 0.712
******** [step = 250] loss: 1.264, acc: 0.711
******** [step = 300] loss: 1.270, acc: 0.710
******** [step = 350] loss: 1.275, acc: 0.709
******** [step = 400] loss: 1.283, acc: 0.708
******** [step = 450] loss: 1.289, acc: 0.708
******** [step = 500] loss: 1.293, acc: 0.707
******** [step = 550] loss: 1.298, acc: 0.707
******** [step = 600] loss: 1.303, acc: 0.706
******** [step = 650] loss: 1.307, acc: 0.705
******** [step = 700] loss: 1.311, acc: 0.705
******** [step = 750] loss: 1.314, acc: 0.705
******** [step = 800] loss: 1.319, acc: 0.704
******** [step = 850] loss: 1.323, acc: 0.704
EPOCH = 80 loss: 1.323, acc: 0.704, val_loss: 1.829, val_acc: 0.666

================================================================================2025-08_10 17:29:34
finishing training...
Training complete in 110m 19s
    epoch  ...   val_acc
0     1.0  ...  0.401311
1     2.0  ...  0.416920
2     3.0  ...  0.465290
3     4.0  ...  0.477400
4     5.0  ...  0.499520
..    ...  ...       ...
75   76.0  ...  0.665112
76   77.0  ...  0.666042
77   78.0  ...  0.665238
78   79.0  ...  0.666108
79   80.0  ...  0.666187

[80 rows x 5 columns]
== Done ==
Sun Aug 10 05:30:02 PM EDT 2025
---------------------------------------
Begin Slurm Epilog: Aug-10-2025 17:30:03
Job ID:        6782330
User ID:       xchen920
Account:       gts-apm7
Job name:      channel_trans
Resources:     cpu=4,gres/gpu:v100=1,mem=16G,node=1
Rsrc Used:     cput=07:39:12,vmem=0,walltime=01:54:48,mem=34952K,energy_used=0
Partition:     gpu-v100
QOS:           inferno
Nodes:         atl1-1-02-009-35-0
---------------------------------------
