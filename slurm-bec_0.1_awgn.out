---------------------------------------
Begin Slurm Prolog: Aug-11-2025 20:11:32
Job ID:    6923955
User ID:   xchen920
Account:   gts-apm7
Job name:  channel_trans
Partition: gpu-v100
QOS:       inferno
---------------------------------------
== Job info ==
Mon Aug 11 08:11:32 PM EDT 2025
atl1-1-03-006-35-0.pace.gatech.edu
/usr/local/pace-apps/lmod/lmod/init/bash: line 200: conda: command not found
== GPU check ==
Mon Aug 11 20:11:47 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:D8:00.0 Off |                    0 |
| N/A   33C    P0             25W /  250W |       0MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
== Launch ==
/storage/scratch1/4/xchen920/project
0.10.0
device= cuda:0
  0%|          | 0/135842 [00:00<?, ?it/s] 12%|█▏        | 16831/135842 [00:00<00:01, 99144.19it/s] 28%|██▊       | 38406/135842 [00:00<00:00, 152406.73it/s] 41%|████      | 55176/135842 [00:00<00:00, 114700.51it/s] 51%|█████     | 69378/135842 [00:00<00:00, 89818.43it/s]  66%|██████▌   | 89376/135842 [00:00<00:00, 115462.92it/s] 79%|███████▉  | 107136/135842 [00:01<00:00, 86369.64it/s] 92%|█████████▏| 125368/135842 [00:01<00:00, 104632.90it/s]100%|██████████| 135842/135842 [00:01<00:00, 107348.29it/s]
  0%|          | 0/108673 [00:00<?, ?it/s] 16%|█▌        | 17395/108673 [00:00<00:02, 44671.37it/s] 33%|███▎      | 35364/108673 [00:00<00:00, 80908.46it/s] 49%|████▉     | 53238/108673 [00:00<00:00, 108020.94it/s] 66%|██████▌   | 71350/108673 [00:00<00:00, 128751.44it/s] 81%|████████  | 87520/108673 [00:01<00:00, 67111.62it/s]  97%|█████████▋| 105416/108673 [00:01<00:00, 85748.29it/s]100%|██████████| 108673/108673 [00:01<00:00, 85241.98it/s]
  0%|          | 0/27169 [00:00<?, ?it/s] 65%|██████▍   | 17629/27169 [00:00<00:00, 176281.76it/s]100%|██████████| 27169/27169 [00:00<00:00, 178334.80it/s]
tensor([    3,    16, 11658,  1523,   477,     6,   469,   123,    12,    38,
           11,  2877,  3567,    40,    39,  9576,   254,   761,   209,     4,
            2,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1])
torch.Size([52, 128]) torch.Size([52, 128])
++++++++++++++++ 213
len(train_dataloader): 850
torch.Size([128, 52]) torch.Size([128, 52])
tensor([   3,   34,   11,   79,   13,   19,   23, 2110,   78,  352,  392, 1158,
           7,  167,  426,  840,   10,    4,    2,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1]) torch.int64
tensor([  3,  24,  12,  94,   5, 673,  28, 514,  40, 131, 213, 845,   4,   2,
          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,
          1,   1,   1,   1,   1,   1,   1,   1,   1,   1]) torch.int64
*************************** start training...

================================================================================2025-08_11 20:14:56
******** [step = 50] loss: 9.343, acc: 0.010
******** [step = 100] loss: 8.943, acc: 0.099
******** [step = 150] loss: 8.602, acc: 0.140
******** [step = 200] loss: 8.285, acc: 0.166
******** [step = 250] loss: 7.989, acc: 0.182
******** [step = 300] loss: 7.695, acc: 0.193
******** [step = 350] loss: 7.398, acc: 0.203
******** [step = 400] loss: 7.118, acc: 0.213
******** [step = 450] loss: 6.862, acc: 0.224
******** [step = 500] loss: 6.636, acc: 0.235
******** [step = 550] loss: 6.438, acc: 0.244
******** [step = 600] loss: 6.264, acc: 0.253
******** [step = 650] loss: 6.107, acc: 0.261
******** [step = 700] loss: 5.964, acc: 0.268
******** [step = 750] loss: 5.835, acc: 0.275
******** [step = 800] loss: 5.719, acc: 0.281
******** [step = 850] loss: 5.612, acc: 0.287
EPOCH = 1 loss: 5.612, acc: 0.287, val_loss: 3.778, val_acc: 0.393

================================================================================2025-08_11 20:17:03
******** [step = 50] loss: 3.871, acc: 0.373
******** [step = 100] loss: 3.833, acc: 0.378
******** [step = 150] loss: 3.800, acc: 0.381
******** [step = 200] loss: 3.777, acc: 0.383
******** [step = 250] loss: 3.752, acc: 0.385
******** [step = 300] loss: 3.729, acc: 0.387
******** [step = 350] loss: 3.708, acc: 0.390
******** [step = 400] loss: 3.687, acc: 0.391
******** [step = 450] loss: 3.669, acc: 0.393
******** [step = 500] loss: 3.650, acc: 0.395
******** [step = 550] loss: 3.635, acc: 0.397
******** [step = 600] loss: 3.618, acc: 0.398
******** [step = 650] loss: 3.602, acc: 0.400
******** [step = 700] loss: 3.585, acc: 0.402
******** [step = 750] loss: 3.571, acc: 0.403
******** [step = 800] loss: 3.557, acc: 0.405
******** [step = 850] loss: 3.541, acc: 0.407
EPOCH = 2 loss: 3.541, acc: 0.407, val_loss: 3.217, val_acc: 0.446

================================================================================2025-08_11 20:19:08
******** [step = 50] loss: 3.286, acc: 0.427
******** [step = 100] loss: 3.265, acc: 0.432
******** [step = 150] loss: 3.252, acc: 0.433
******** [step = 200] loss: 3.235, acc: 0.435
******** [step = 250] loss: 3.228, acc: 0.436
******** [step = 300] loss: 3.225, acc: 0.437
******** [step = 350] loss: 3.221, acc: 0.437
******** [step = 400] loss: 3.216, acc: 0.438
******** [step = 450] loss: 3.209, acc: 0.439
******** [step = 500] loss: 3.201, acc: 0.439
******** [step = 550] loss: 3.196, acc: 0.440
******** [step = 600] loss: 3.188, acc: 0.441
******** [step = 650] loss: 3.183, acc: 0.442
******** [step = 700] loss: 3.177, acc: 0.442
******** [step = 750] loss: 3.171, acc: 0.443
******** [step = 800] loss: 3.166, acc: 0.444
******** [step = 850] loss: 3.159, acc: 0.445
EPOCH = 3 loss: 3.159, acc: 0.445, val_loss: 3.017, val_acc: 0.461

================================================================================2025-08_11 20:21:13
******** [step = 50] loss: 3.045, acc: 0.453
******** [step = 100] loss: 3.020, acc: 0.455
******** [step = 150] loss: 3.008, acc: 0.456
******** [step = 200] loss: 3.002, acc: 0.457
******** [step = 250] loss: 2.994, acc: 0.458
******** [step = 300] loss: 2.991, acc: 0.459
******** [step = 350] loss: 2.988, acc: 0.459
******** [step = 400] loss: 2.983, acc: 0.460
******** [step = 450] loss: 2.980, acc: 0.460
******** [step = 500] loss: 2.976, acc: 0.461
******** [step = 550] loss: 2.973, acc: 0.462
******** [step = 600] loss: 2.970, acc: 0.463
******** [step = 650] loss: 2.967, acc: 0.463
******** [step = 700] loss: 2.964, acc: 0.464
******** [step = 750] loss: 2.960, acc: 0.464
******** [step = 800] loss: 2.958, acc: 0.464
******** [step = 850] loss: 2.954, acc: 0.465
EPOCH = 4 loss: 2.954, acc: 0.465, val_loss: 2.852, val_acc: 0.483

================================================================================2025-08_11 20:23:17
******** [step = 50] loss: 2.813, acc: 0.476
******** [step = 100] loss: 2.812, acc: 0.476
******** [step = 150] loss: 2.811, acc: 0.476
******** [step = 200] loss: 2.809, acc: 0.477
******** [step = 250] loss: 2.810, acc: 0.478
******** [step = 300] loss: 2.807, acc: 0.479
******** [step = 350] loss: 2.812, acc: 0.479
******** [step = 400] loss: 2.811, acc: 0.479
******** [step = 450] loss: 2.812, acc: 0.479
******** [step = 500] loss: 2.812, acc: 0.479
******** [step = 550] loss: 2.810, acc: 0.480
******** [step = 600] loss: 2.808, acc: 0.481
******** [step = 650] loss: 2.807, acc: 0.481
******** [step = 700] loss: 2.804, acc: 0.482
******** [step = 750] loss: 2.801, acc: 0.482
******** [step = 800] loss: 2.797, acc: 0.483
******** [step = 850] loss: 2.795, acc: 0.484
EPOCH = 5 loss: 2.795, acc: 0.484, val_loss: 2.677, val_acc: 0.511

================================================================================2025-08_11 20:25:20
******** [step = 50] loss: 2.673, acc: 0.496
******** [step = 100] loss: 2.645, acc: 0.500
******** [step = 150] loss: 2.641, acc: 0.501
******** [step = 200] loss: 2.637, acc: 0.502
******** [step = 250] loss: 2.636, acc: 0.502
******** [step = 300] loss: 2.640, acc: 0.503
******** [step = 350] loss: 2.637, acc: 0.503
******** [step = 400] loss: 2.633, acc: 0.504
******** [step = 450] loss: 2.634, acc: 0.504
******** [step = 500] loss: 2.635, acc: 0.504
******** [step = 550] loss: 2.633, acc: 0.505
******** [step = 600] loss: 2.630, acc: 0.506
******** [step = 650] loss: 2.627, acc: 0.506
******** [step = 700] loss: 2.624, acc: 0.507
******** [step = 750] loss: 2.621, acc: 0.508
******** [step = 800] loss: 2.618, acc: 0.508
******** [step = 850] loss: 2.614, acc: 0.509
EPOCH = 6 loss: 2.614, acc: 0.509, val_loss: 2.500, val_acc: 0.538

================================================================================2025-08_11 20:27:26
******** [step = 50] loss: 2.450, acc: 0.527
******** [step = 100] loss: 2.444, acc: 0.528
******** [step = 150] loss: 2.446, acc: 0.528
******** [step = 200] loss: 2.452, acc: 0.528
******** [step = 250] loss: 2.453, acc: 0.528
******** [step = 300] loss: 2.453, acc: 0.529
******** [step = 350] loss: 2.453, acc: 0.529
******** [step = 400] loss: 2.454, acc: 0.530
******** [step = 450] loss: 2.450, acc: 0.531
******** [step = 500] loss: 2.448, acc: 0.532
******** [step = 550] loss: 2.445, acc: 0.532
******** [step = 600] loss: 2.445, acc: 0.533
******** [step = 650] loss: 2.443, acc: 0.533
******** [step = 700] loss: 2.441, acc: 0.534
******** [step = 750] loss: 2.440, acc: 0.534
******** [step = 800] loss: 2.437, acc: 0.535
******** [step = 850] loss: 2.436, acc: 0.535
EPOCH = 7 loss: 2.436, acc: 0.535, val_loss: 2.350, val_acc: 0.562

================================================================================2025-08_11 20:29:32
******** [step = 50] loss: 2.326, acc: 0.546
******** [step = 100] loss: 2.293, acc: 0.552
******** [step = 150] loss: 2.288, acc: 0.553
******** [step = 200] loss: 2.287, acc: 0.554
******** [step = 250] loss: 2.286, acc: 0.554
******** [step = 300] loss: 2.287, acc: 0.554
******** [step = 350] loss: 2.288, acc: 0.555
******** [step = 400] loss: 2.289, acc: 0.555
******** [step = 450] loss: 2.286, acc: 0.555
******** [step = 500] loss: 2.285, acc: 0.556
******** [step = 550] loss: 2.286, acc: 0.556
******** [step = 600] loss: 2.284, acc: 0.556
******** [step = 650] loss: 2.282, acc: 0.557
******** [step = 700] loss: 2.280, acc: 0.558
******** [step = 750] loss: 2.280, acc: 0.558
******** [step = 800] loss: 2.277, acc: 0.558
******** [step = 850] loss: 2.275, acc: 0.559
EPOCH = 8 loss: 2.275, acc: 0.559, val_loss: 2.222, val_acc: 0.583

================================================================================2025-08_11 20:31:35
******** [step = 50] loss: 2.136, acc: 0.575
******** [step = 100] loss: 2.116, acc: 0.578
******** [step = 150] loss: 2.119, acc: 0.578
******** [step = 200] loss: 2.128, acc: 0.577
******** [step = 250] loss: 2.133, acc: 0.577
******** [step = 300] loss: 2.129, acc: 0.577
******** [step = 350] loss: 2.132, acc: 0.578
******** [step = 400] loss: 2.132, acc: 0.578
******** [step = 450] loss: 2.134, acc: 0.578
******** [step = 500] loss: 2.136, acc: 0.578
******** [step = 550] loss: 2.137, acc: 0.578
******** [step = 600] loss: 2.138, acc: 0.579
******** [step = 650] loss: 2.140, acc: 0.579
******** [step = 700] loss: 2.140, acc: 0.579
******** [step = 750] loss: 2.140, acc: 0.579
******** [step = 800] loss: 2.139, acc: 0.579
******** [step = 850] loss: 2.138, acc: 0.580
EPOCH = 9 loss: 2.138, acc: 0.580, val_loss: 2.118, val_acc: 0.600

================================================================================2025-08_11 20:33:44
******** [step = 50] loss: 2.011, acc: 0.595
******** [step = 100] loss: 2.016, acc: 0.595
******** [step = 150] loss: 2.010, acc: 0.596
******** [step = 200] loss: 2.009, acc: 0.596
******** [step = 250] loss: 2.012, acc: 0.596
******** [step = 300] loss: 2.016, acc: 0.596
******** [step = 350] loss: 2.016, acc: 0.596
******** [step = 400] loss: 2.017, acc: 0.597
******** [step = 450] loss: 2.020, acc: 0.596
******** [step = 500] loss: 2.023, acc: 0.596
******** [step = 550] loss: 2.022, acc: 0.596
******** [step = 600] loss: 2.024, acc: 0.596
******** [step = 650] loss: 2.025, acc: 0.597
******** [step = 700] loss: 2.026, acc: 0.597
******** [step = 750] loss: 2.025, acc: 0.597
******** [step = 800] loss: 2.026, acc: 0.597
******** [step = 850] loss: 2.027, acc: 0.597
EPOCH = 10 loss: 2.027, acc: 0.597, val_loss: 2.036, val_acc: 0.615

================================================================================2025-08_11 20:35:52
******** [step = 50] loss: 1.914, acc: 0.609
******** [step = 100] loss: 1.898, acc: 0.612
******** [step = 150] loss: 1.903, acc: 0.612
******** [step = 200] loss: 1.910, acc: 0.612
******** [step = 250] loss: 1.913, acc: 0.612
******** [step = 300] loss: 1.917, acc: 0.612
******** [step = 350] loss: 1.919, acc: 0.612
******** [step = 400] loss: 1.920, acc: 0.612
******** [step = 450] loss: 1.921, acc: 0.612
******** [step = 500] loss: 1.921, acc: 0.612
******** [step = 550] loss: 1.922, acc: 0.613
******** [step = 600] loss: 1.922, acc: 0.613
******** [step = 650] loss: 1.924, acc: 0.613
******** [step = 700] loss: 1.925, acc: 0.613
******** [step = 750] loss: 1.928, acc: 0.613
******** [step = 800] loss: 1.931, acc: 0.613
******** [step = 850] loss: 1.930, acc: 0.613
EPOCH = 11 loss: 1.930, acc: 0.613, val_loss: 1.955, val_acc: 0.633

================================================================================2025-08_11 20:38:01
******** [step = 50] loss: 1.803, acc: 0.629
******** [step = 100] loss: 1.808, acc: 0.629
******** [step = 150] loss: 1.813, acc: 0.629
******** [step = 200] loss: 1.819, acc: 0.628
******** [step = 250] loss: 1.822, acc: 0.628
******** [step = 300] loss: 1.825, acc: 0.628
******** [step = 350] loss: 1.831, acc: 0.627
******** [step = 400] loss: 1.831, acc: 0.627
******** [step = 450] loss: 1.834, acc: 0.627
******** [step = 500] loss: 1.837, acc: 0.627
******** [step = 550] loss: 1.839, acc: 0.627
******** [step = 600] loss: 1.840, acc: 0.627
******** [step = 650] loss: 1.842, acc: 0.627
******** [step = 700] loss: 1.845, acc: 0.627
******** [step = 750] loss: 1.847, acc: 0.627
******** [step = 800] loss: 1.847, acc: 0.627
******** [step = 850] loss: 1.851, acc: 0.627
EPOCH = 12 loss: 1.851, acc: 0.627, val_loss: 1.893, val_acc: 0.644

================================================================================2025-08_11 20:40:13
******** [step = 50] loss: 1.746, acc: 0.637
******** [step = 100] loss: 1.744, acc: 0.639
******** [step = 150] loss: 1.751, acc: 0.639
******** [step = 200] loss: 1.748, acc: 0.640
******** [step = 250] loss: 1.749, acc: 0.641
******** [step = 300] loss: 1.749, acc: 0.641
******** [step = 350] loss: 1.753, acc: 0.641
******** [step = 400] loss: 1.756, acc: 0.641
******** [step = 450] loss: 1.758, acc: 0.641
******** [step = 500] loss: 1.761, acc: 0.641
******** [step = 550] loss: 1.761, acc: 0.641
******** [step = 600] loss: 1.764, acc: 0.641
******** [step = 650] loss: 1.769, acc: 0.641
******** [step = 700] loss: 1.773, acc: 0.640
******** [step = 750] loss: 1.776, acc: 0.640
******** [step = 800] loss: 1.778, acc: 0.640
******** [step = 850] loss: 1.778, acc: 0.640
EPOCH = 13 loss: 1.778, acc: 0.640, val_loss: 1.848, val_acc: 0.652

================================================================================2025-08_11 20:42:25
******** [step = 50] loss: 1.668, acc: 0.653
******** [step = 100] loss: 1.644, acc: 0.656
******** [step = 150] loss: 1.657, acc: 0.654
******** [step = 200] loss: 1.666, acc: 0.653
******** [step = 250] loss: 1.675, acc: 0.653
******** [step = 300] loss: 1.685, acc: 0.652
******** [step = 350] loss: 1.690, acc: 0.652
******** [step = 400] loss: 1.692, acc: 0.652
******** [step = 450] loss: 1.697, acc: 0.651
******** [step = 500] loss: 1.701, acc: 0.651
******** [step = 550] loss: 1.706, acc: 0.650
******** [step = 600] loss: 1.710, acc: 0.650
******** [step = 650] loss: 1.712, acc: 0.650
******** [step = 700] loss: 1.713, acc: 0.650
******** [step = 750] loss: 1.713, acc: 0.651
******** [step = 800] loss: 1.716, acc: 0.650
******** [step = 850] loss: 1.719, acc: 0.650
EPOCH = 14 loss: 1.719, acc: 0.650, val_loss: 1.808, val_acc: 0.661

================================================================================2025-08_11 20:44:35
******** [step = 50] loss: 1.649, acc: 0.656
******** [step = 100] loss: 1.633, acc: 0.660
******** [step = 150] loss: 1.630, acc: 0.661
******** [step = 200] loss: 1.630, acc: 0.661
******** [step = 250] loss: 1.633, acc: 0.661
******** [step = 300] loss: 1.637, acc: 0.661
******** [step = 350] loss: 1.643, acc: 0.660
******** [step = 400] loss: 1.645, acc: 0.660
******** [step = 450] loss: 1.646, acc: 0.660
******** [step = 500] loss: 1.646, acc: 0.660
******** [step = 550] loss: 1.648, acc: 0.660
******** [step = 600] loss: 1.650, acc: 0.660
******** [step = 650] loss: 1.652, acc: 0.660
******** [step = 700] loss: 1.654, acc: 0.660
******** [step = 750] loss: 1.658, acc: 0.660
******** [step = 800] loss: 1.662, acc: 0.659
******** [step = 850] loss: 1.662, acc: 0.660
EPOCH = 15 loss: 1.662, acc: 0.660, val_loss: 1.759, val_acc: 0.670

================================================================================2025-08_11 20:46:44
******** [step = 50] loss: 1.567, acc: 0.670
******** [step = 100] loss: 1.560, acc: 0.671
******** [step = 150] loss: 1.565, acc: 0.671
******** [step = 200] loss: 1.571, acc: 0.671
******** [step = 250] loss: 1.576, acc: 0.670
******** [step = 300] loss: 1.580, acc: 0.670
******** [step = 350] loss: 1.583, acc: 0.670
******** [step = 400] loss: 1.587, acc: 0.670
******** [step = 450] loss: 1.589, acc: 0.670
******** [step = 500] loss: 1.594, acc: 0.669
******** [step = 550] loss: 1.596, acc: 0.669
******** [step = 600] loss: 1.599, acc: 0.669
******** [step = 650] loss: 1.601, acc: 0.669
******** [step = 700] loss: 1.605, acc: 0.668
******** [step = 750] loss: 1.607, acc: 0.668
******** [step = 800] loss: 1.607, acc: 0.669
******** [step = 850] loss: 1.610, acc: 0.668
EPOCH = 16 loss: 1.610, acc: 0.668, val_loss: 1.719, val_acc: 0.678

================================================================================2025-08_11 20:48:48
******** [step = 50] loss: 1.521, acc: 0.682
******** [step = 100] loss: 1.513, acc: 0.682
******** [step = 150] loss: 1.514, acc: 0.681
******** [step = 200] loss: 1.519, acc: 0.681
******** [step = 250] loss: 1.522, acc: 0.680
******** [step = 300] loss: 1.528, acc: 0.679
******** [step = 350] loss: 1.533, acc: 0.679
******** [step = 400] loss: 1.538, acc: 0.678
******** [step = 450] loss: 1.542, acc: 0.678
******** [step = 500] loss: 1.543, acc: 0.678
******** [step = 550] loss: 1.547, acc: 0.677
******** [step = 600] loss: 1.550, acc: 0.677
******** [step = 650] loss: 1.554, acc: 0.677
******** [step = 700] loss: 1.558, acc: 0.677
******** [step = 750] loss: 1.560, acc: 0.677
******** [step = 800] loss: 1.562, acc: 0.677
******** [step = 850] loss: 1.563, acc: 0.677
EPOCH = 17 loss: 1.563, acc: 0.677, val_loss: 1.693, val_acc: 0.681

================================================================================2025-08_11 20:50:52
******** [step = 50] loss: 1.496, acc: 0.683
******** [step = 100] loss: 1.480, acc: 0.687
******** [step = 150] loss: 1.480, acc: 0.687
******** [step = 200] loss: 1.482, acc: 0.687
******** [step = 250] loss: 1.480, acc: 0.687
******** [step = 300] loss: 1.485, acc: 0.687
******** [step = 350] loss: 1.493, acc: 0.686
******** [step = 400] loss: 1.497, acc: 0.685
******** [step = 450] loss: 1.501, acc: 0.685
******** [step = 500] loss: 1.506, acc: 0.684
******** [step = 550] loss: 1.508, acc: 0.684
******** [step = 600] loss: 1.508, acc: 0.684
******** [step = 650] loss: 1.507, acc: 0.685
******** [step = 700] loss: 1.509, acc: 0.685
******** [step = 750] loss: 1.513, acc: 0.684
******** [step = 800] loss: 1.514, acc: 0.684
******** [step = 850] loss: 1.518, acc: 0.684
EPOCH = 18 loss: 1.518, acc: 0.684, val_loss: 1.657, val_acc: 0.689

================================================================================2025-08_11 20:53:00
******** [step = 50] loss: 1.421, acc: 0.697
******** [step = 100] loss: 1.411, acc: 0.699
******** [step = 150] loss: 1.417, acc: 0.698
******** [step = 200] loss: 1.426, acc: 0.697
******** [step = 250] loss: 1.431, acc: 0.696
******** [step = 300] loss: 1.437, acc: 0.696
******** [step = 350] loss: 1.442, acc: 0.695
******** [step = 400] loss: 1.449, acc: 0.694
******** [step = 450] loss: 1.452, acc: 0.694
******** [step = 500] loss: 1.456, acc: 0.694
******** [step = 550] loss: 1.459, acc: 0.694
******** [step = 600] loss: 1.462, acc: 0.693
******** [step = 650] loss: 1.467, acc: 0.693
******** [step = 700] loss: 1.469, acc: 0.693
******** [step = 750] loss: 1.474, acc: 0.692
******** [step = 800] loss: 1.475, acc: 0.693
******** [step = 850] loss: 1.477, acc: 0.692
EPOCH = 19 loss: 1.477, acc: 0.692, val_loss: 1.633, val_acc: 0.693

================================================================================2025-08_11 20:55:02
******** [step = 50] loss: 1.384, acc: 0.705
******** [step = 100] loss: 1.389, acc: 0.703
******** [step = 150] loss: 1.389, acc: 0.703
******** [step = 200] loss: 1.394, acc: 0.703
******** [step = 250] loss: 1.400, acc: 0.702
******** [step = 300] loss: 1.405, acc: 0.701
******** [step = 350] loss: 1.411, acc: 0.700
******** [step = 400] loss: 1.415, acc: 0.700
******** [step = 450] loss: 1.418, acc: 0.700
******** [step = 500] loss: 1.422, acc: 0.699
******** [step = 550] loss: 1.426, acc: 0.699
******** [step = 600] loss: 1.427, acc: 0.699
******** [step = 650] loss: 1.429, acc: 0.699
******** [step = 700] loss: 1.433, acc: 0.699
******** [step = 750] loss: 1.435, acc: 0.698
******** [step = 800] loss: 1.440, acc: 0.698
******** [step = 850] loss: 1.440, acc: 0.698
EPOCH = 20 loss: 1.440, acc: 0.698, val_loss: 1.610, val_acc: 0.699

================================================================================2025-08_11 20:57:05
******** [step = 50] loss: 1.361, acc: 0.707
******** [step = 100] loss: 1.353, acc: 0.708
******** [step = 150] loss: 1.351, acc: 0.708
******** [step = 200] loss: 1.356, acc: 0.709
******** [step = 250] loss: 1.358, acc: 0.708
******** [step = 300] loss: 1.365, acc: 0.708
******** [step = 350] loss: 1.372, acc: 0.707
******** [step = 400] loss: 1.379, acc: 0.706
******** [step = 450] loss: 1.379, acc: 0.706
******** [step = 500] loss: 1.383, acc: 0.706
******** [step = 550] loss: 1.389, acc: 0.706
******** [step = 600] loss: 1.391, acc: 0.705
******** [step = 650] loss: 1.395, acc: 0.705
******** [step = 700] loss: 1.398, acc: 0.705
******** [step = 750] loss: 1.400, acc: 0.705
******** [step = 800] loss: 1.403, acc: 0.704
******** [step = 850] loss: 1.406, acc: 0.704
EPOCH = 21 loss: 1.406, acc: 0.704, val_loss: 1.598, val_acc: 0.704

================================================================================2025-08_11 20:59:07
******** [step = 50] loss: 1.316, acc: 0.715
******** [step = 100] loss: 1.316, acc: 0.715
******** [step = 150] loss: 1.317, acc: 0.716
******** [step = 200] loss: 1.318, acc: 0.715
******** [step = 250] loss: 1.328, acc: 0.715
******** [step = 300] loss: 1.335, acc: 0.713
******** [step = 350] loss: 1.341, acc: 0.712
******** [step = 400] loss: 1.343, acc: 0.712
******** [step = 450] loss: 1.350, acc: 0.711
******** [step = 500] loss: 1.354, acc: 0.711
******** [step = 550] loss: 1.358, acc: 0.711
******** [step = 600] loss: 1.362, acc: 0.710
******** [step = 650] loss: 1.365, acc: 0.710
******** [step = 700] loss: 1.367, acc: 0.710
******** [step = 750] loss: 1.371, acc: 0.710
******** [step = 800] loss: 1.373, acc: 0.709
******** [step = 850] loss: 1.374, acc: 0.710
EPOCH = 22 loss: 1.374, acc: 0.710, val_loss: 1.563, val_acc: 0.709

================================================================================2025-08_11 21:01:11
******** [step = 50] loss: 1.326, acc: 0.716
******** [step = 100] loss: 1.312, acc: 0.717
******** [step = 150] loss: 1.311, acc: 0.718
******** [step = 200] loss: 1.312, acc: 0.718
******** [step = 250] loss: 1.315, acc: 0.717
******** [step = 300] loss: 1.320, acc: 0.717
******** [step = 350] loss: 1.321, acc: 0.717
******** [step = 400] loss: 1.324, acc: 0.716
******** [step = 450] loss: 1.328, acc: 0.716
******** [step = 500] loss: 1.329, acc: 0.716
******** [step = 550] loss: 1.332, acc: 0.716
******** [step = 600] loss: 1.336, acc: 0.715
******** [step = 650] loss: 1.338, acc: 0.715
******** [step = 700] loss: 1.340, acc: 0.715
******** [step = 750] loss: 1.343, acc: 0.715
******** [step = 800] loss: 1.344, acc: 0.715
******** [step = 850] loss: 1.348, acc: 0.715
EPOCH = 23 loss: 1.348, acc: 0.715, val_loss: 1.549, val_acc: 0.711

================================================================================2025-08_11 21:03:19
******** [step = 50] loss: 1.279, acc: 0.722
******** [step = 100] loss: 1.259, acc: 0.725
******** [step = 150] loss: 1.269, acc: 0.724
******** [step = 200] loss: 1.273, acc: 0.723
******** [step = 250] loss: 1.279, acc: 0.723
******** [step = 300] loss: 1.285, acc: 0.723
******** [step = 350] loss: 1.289, acc: 0.722
******** [step = 400] loss: 1.291, acc: 0.722
******** [step = 450] loss: 1.296, acc: 0.722
******** [step = 500] loss: 1.301, acc: 0.721
******** [step = 550] loss: 1.304, acc: 0.720
******** [step = 600] loss: 1.307, acc: 0.720
******** [step = 650] loss: 1.310, acc: 0.720
******** [step = 700] loss: 1.313, acc: 0.720
******** [step = 750] loss: 1.317, acc: 0.719
******** [step = 800] loss: 1.321, acc: 0.719
******** [step = 850] loss: 1.323, acc: 0.719
EPOCH = 24 loss: 1.323, acc: 0.719, val_loss: 1.534, val_acc: 0.715

================================================================================2025-08_11 21:05:30
******** [step = 50] loss: 1.250, acc: 0.728
******** [step = 100] loss: 1.238, acc: 0.731
******** [step = 150] loss: 1.240, acc: 0.730
******** [step = 200] loss: 1.249, acc: 0.728
******** [step = 250] loss: 1.253, acc: 0.728
******** [step = 300] loss: 1.257, acc: 0.727
******** [step = 350] loss: 1.261, acc: 0.727
******** [step = 400] loss: 1.263, acc: 0.727
******** [step = 450] loss: 1.266, acc: 0.727
******** [step = 500] loss: 1.274, acc: 0.726
******** [step = 550] loss: 1.280, acc: 0.725
******** [step = 600] loss: 1.283, acc: 0.725
******** [step = 650] loss: 1.286, acc: 0.725
******** [step = 700] loss: 1.289, acc: 0.724
******** [step = 750] loss: 1.294, acc: 0.724
******** [step = 800] loss: 1.296, acc: 0.724
******** [step = 850] loss: 1.298, acc: 0.723
EPOCH = 25 loss: 1.298, acc: 0.723, val_loss: 1.512, val_acc: 0.721

================================================================================2025-08_11 21:07:33
******** [step = 50] loss: 1.211, acc: 0.735
******** [step = 100] loss: 1.224, acc: 0.733
******** [step = 150] loss: 1.218, acc: 0.734
******** [step = 200] loss: 1.226, acc: 0.733
******** [step = 250] loss: 1.234, acc: 0.732
******** [step = 300] loss: 1.238, acc: 0.732
******** [step = 350] loss: 1.242, acc: 0.731
******** [step = 400] loss: 1.246, acc: 0.731
******** [step = 450] loss: 1.252, acc: 0.730
******** [step = 500] loss: 1.254, acc: 0.729
******** [step = 550] loss: 1.256, acc: 0.729
******** [step = 600] loss: 1.260, acc: 0.729
******** [step = 650] loss: 1.264, acc: 0.729
******** [step = 700] loss: 1.265, acc: 0.728
******** [step = 750] loss: 1.269, acc: 0.728
******** [step = 800] loss: 1.272, acc: 0.728
******** [step = 850] loss: 1.274, acc: 0.728
EPOCH = 26 loss: 1.274, acc: 0.728, val_loss: 1.500, val_acc: 0.722

================================================================================2025-08_11 21:09:37
******** [step = 50] loss: 1.197, acc: 0.736
******** [step = 100] loss: 1.190, acc: 0.737
******** [step = 150] loss: 1.191, acc: 0.738
******** [step = 200] loss: 1.189, acc: 0.739
******** [step = 250] loss: 1.190, acc: 0.739
******** [step = 300] loss: 1.202, acc: 0.737
******** [step = 350] loss: 1.209, acc: 0.736
******** [step = 400] loss: 1.214, acc: 0.736
******** [step = 450] loss: 1.220, acc: 0.735
******** [step = 500] loss: 1.221, acc: 0.735
******** [step = 550] loss: 1.227, acc: 0.734
******** [step = 600] loss: 1.233, acc: 0.733
******** [step = 650] loss: 1.237, acc: 0.733
******** [step = 700] loss: 1.241, acc: 0.733
******** [step = 750] loss: 1.246, acc: 0.732
******** [step = 800] loss: 1.250, acc: 0.732
******** [step = 850] loss: 1.253, acc: 0.731
EPOCH = 27 loss: 1.253, acc: 0.731, val_loss: 1.486, val_acc: 0.725

================================================================================2025-08_11 21:11:44
******** [step = 50] loss: 1.176, acc: 0.741
******** [step = 100] loss: 1.174, acc: 0.741
******** [step = 150] loss: 1.173, acc: 0.742
******** [step = 200] loss: 1.174, acc: 0.742
******** [step = 250] loss: 1.179, acc: 0.742
******** [step = 300] loss: 1.190, acc: 0.740
******** [step = 350] loss: 1.196, acc: 0.739
******** [step = 400] loss: 1.199, acc: 0.739
******** [step = 450] loss: 1.204, acc: 0.739
******** [step = 500] loss: 1.209, acc: 0.738
******** [step = 550] loss: 1.214, acc: 0.737
******** [step = 600] loss: 1.219, acc: 0.736
******** [step = 650] loss: 1.223, acc: 0.736
******** [step = 700] loss: 1.224, acc: 0.736
******** [step = 750] loss: 1.228, acc: 0.736
******** [step = 800] loss: 1.231, acc: 0.735
******** [step = 850] loss: 1.234, acc: 0.735
EPOCH = 28 loss: 1.234, acc: 0.735, val_loss: 1.475, val_acc: 0.727

================================================================================2025-08_11 21:13:53
******** [step = 50] loss: 1.133, acc: 0.747
******** [step = 100] loss: 1.137, acc: 0.748
******** [step = 150] loss: 1.144, acc: 0.747
******** [step = 200] loss: 1.154, acc: 0.746
******** [step = 250] loss: 1.162, acc: 0.745
******** [step = 300] loss: 1.170, acc: 0.744
******** [step = 350] loss: 1.178, acc: 0.743
******** [step = 400] loss: 1.181, acc: 0.742
******** [step = 450] loss: 1.186, acc: 0.742
******** [step = 500] loss: 1.189, acc: 0.741
******** [step = 550] loss: 1.196, acc: 0.740
******** [step = 600] loss: 1.199, acc: 0.740
******** [step = 650] loss: 1.204, acc: 0.739
******** [step = 700] loss: 1.205, acc: 0.739
******** [step = 750] loss: 1.210, acc: 0.739
******** [step = 800] loss: 1.214, acc: 0.739
******** [step = 850] loss: 1.216, acc: 0.738
EPOCH = 29 loss: 1.216, acc: 0.738, val_loss: 1.463, val_acc: 0.730

================================================================================2025-08_11 21:15:57
******** [step = 50] loss: 1.120, acc: 0.749
******** [step = 100] loss: 1.130, acc: 0.749
******** [step = 150] loss: 1.127, acc: 0.749
******** [step = 200] loss: 1.135, acc: 0.748
******** [step = 250] loss: 1.143, acc: 0.747
******** [step = 300] loss: 1.148, acc: 0.747
******** [step = 350] loss: 1.154, acc: 0.746
******** [step = 400] loss: 1.161, acc: 0.745
******** [step = 450] loss: 1.166, acc: 0.745
******** [step = 500] loss: 1.170, acc: 0.745
******** [step = 550] loss: 1.176, acc: 0.744
******** [step = 600] loss: 1.180, acc: 0.743
******** [step = 650] loss: 1.184, acc: 0.743
******** [step = 700] loss: 1.189, acc: 0.742
******** [step = 750] loss: 1.192, acc: 0.742
******** [step = 800] loss: 1.196, acc: 0.742
******** [step = 850] loss: 1.201, acc: 0.741
EPOCH = 30 loss: 1.201, acc: 0.741, val_loss: 1.456, val_acc: 0.731

================================================================================2025-08_11 21:18:05
******** [step = 50] loss: 1.122, acc: 0.752
******** [step = 100] loss: 1.130, acc: 0.751
******** [step = 150] loss: 1.129, acc: 0.751
******** [step = 200] loss: 1.133, acc: 0.750
******** [step = 250] loss: 1.137, acc: 0.750
******** [step = 300] loss: 1.141, acc: 0.749
******** [step = 350] loss: 1.148, acc: 0.748
******** [step = 400] loss: 1.155, acc: 0.748
******** [step = 450] loss: 1.156, acc: 0.747
******** [step = 500] loss: 1.159, acc: 0.747
******** [step = 550] loss: 1.163, acc: 0.746
******** [step = 600] loss: 1.166, acc: 0.746
******** [step = 650] loss: 1.169, acc: 0.746
******** [step = 700] loss: 1.172, acc: 0.745
******** [step = 750] loss: 1.175, acc: 0.745
******** [step = 800] loss: 1.179, acc: 0.745
******** [step = 850] loss: 1.181, acc: 0.744
EPOCH = 31 loss: 1.181, acc: 0.744, val_loss: 1.446, val_acc: 0.733

================================================================================2025-08_11 21:20:10
******** [step = 50] loss: 1.109, acc: 0.753
******** [step = 100] loss: 1.111, acc: 0.753
******** [step = 150] loss: 1.115, acc: 0.753
******** [step = 200] loss: 1.120, acc: 0.753
******** [step = 250] loss: 1.126, acc: 0.752
******** [step = 300] loss: 1.130, acc: 0.752
******** [step = 350] loss: 1.136, acc: 0.751
******** [step = 400] loss: 1.140, acc: 0.750
******** [step = 450] loss: 1.147, acc: 0.749
******** [step = 500] loss: 1.152, acc: 0.749
******** [step = 550] loss: 1.153, acc: 0.748
******** [step = 600] loss: 1.154, acc: 0.748
******** [step = 650] loss: 1.156, acc: 0.748
******** [step = 700] loss: 1.158, acc: 0.748
******** [step = 750] loss: 1.161, acc: 0.748
******** [step = 800] loss: 1.163, acc: 0.748
******** [step = 850] loss: 1.167, acc: 0.747
EPOCH = 32 loss: 1.167, acc: 0.747, val_loss: 1.439, val_acc: 0.735

================================================================================2025-08_11 21:22:27
******** [step = 50] loss: 1.091, acc: 0.755
******** [step = 100] loss: 1.092, acc: 0.755
******** [step = 150] loss: 1.098, acc: 0.755
******** [step = 200] loss: 1.102, acc: 0.755
******** [step = 250] loss: 1.110, acc: 0.754
******** [step = 300] loss: 1.112, acc: 0.754
******** [step = 350] loss: 1.114, acc: 0.754
******** [step = 400] loss: 1.118, acc: 0.753
******** [step = 450] loss: 1.125, acc: 0.753
******** [step = 500] loss: 1.126, acc: 0.753
******** [step = 550] loss: 1.129, acc: 0.753
******** [step = 600] loss: 1.134, acc: 0.752
******** [step = 650] loss: 1.137, acc: 0.752
******** [step = 700] loss: 1.142, acc: 0.751
******** [step = 750] loss: 1.144, acc: 0.751
******** [step = 800] loss: 1.146, acc: 0.751
******** [step = 850] loss: 1.150, acc: 0.751
EPOCH = 33 loss: 1.150, acc: 0.751, val_loss: 1.429, val_acc: 0.737

================================================================================2025-08_11 21:24:37
******** [step = 50] loss: 1.054, acc: 0.764
******** [step = 100] loss: 1.058, acc: 0.764
******** [step = 150] loss: 1.067, acc: 0.762
******** [step = 200] loss: 1.078, acc: 0.760
******** [step = 250] loss: 1.081, acc: 0.759
******** [step = 300] loss: 1.087, acc: 0.759
******** [step = 350] loss: 1.094, acc: 0.758
******** [step = 400] loss: 1.098, acc: 0.757
******** [step = 450] loss: 1.104, acc: 0.756
******** [step = 500] loss: 1.110, acc: 0.755
******** [step = 550] loss: 1.116, acc: 0.754
******** [step = 600] loss: 1.120, acc: 0.754
******** [step = 650] loss: 1.124, acc: 0.754
******** [step = 700] loss: 1.127, acc: 0.754
******** [step = 750] loss: 1.131, acc: 0.753
******** [step = 800] loss: 1.135, acc: 0.753
******** [step = 850] loss: 1.138, acc: 0.753
EPOCH = 34 loss: 1.138, acc: 0.753, val_loss: 1.422, val_acc: 0.737

================================================================================2025-08_11 21:26:44
******** [step = 50] loss: 1.068, acc: 0.760
******** [step = 100] loss: 1.065, acc: 0.761
******** [step = 150] loss: 1.067, acc: 0.762
******** [step = 200] loss: 1.072, acc: 0.761
******** [step = 250] loss: 1.076, acc: 0.760
******** [step = 300] loss: 1.079, acc: 0.760
******** [step = 350] loss: 1.085, acc: 0.759
******** [step = 400] loss: 1.087, acc: 0.759
******** [step = 450] loss: 1.094, acc: 0.758
******** [step = 500] loss: 1.099, acc: 0.757
******** [step = 550] loss: 1.102, acc: 0.757
******** [step = 600] loss: 1.106, acc: 0.757
******** [step = 650] loss: 1.111, acc: 0.756
******** [step = 700] loss: 1.115, acc: 0.756
******** [step = 750] loss: 1.121, acc: 0.755
******** [step = 800] loss: 1.124, acc: 0.755
******** [step = 850] loss: 1.126, acc: 0.755
EPOCH = 35 loss: 1.126, acc: 0.755, val_loss: 1.410, val_acc: 0.741

================================================================================2025-08_11 21:28:48
******** [step = 50] loss: 1.049, acc: 0.763
******** [step = 100] loss: 1.038, acc: 0.766
******** [step = 150] loss: 1.044, acc: 0.766
******** [step = 200] loss: 1.053, acc: 0.764
******** [step = 250] loss: 1.061, acc: 0.763
******** [step = 300] loss: 1.066, acc: 0.763
******** [step = 350] loss: 1.070, acc: 0.762
******** [step = 400] loss: 1.074, acc: 0.762
******** [step = 450] loss: 1.077, acc: 0.761
******** [step = 500] loss: 1.084, acc: 0.760
******** [step = 550] loss: 1.090, acc: 0.760
******** [step = 600] loss: 1.095, acc: 0.759
******** [step = 650] loss: 1.099, acc: 0.759
******** [step = 700] loss: 1.102, acc: 0.759
******** [step = 750] loss: 1.106, acc: 0.758
******** [step = 800] loss: 1.109, acc: 0.758
******** [step = 850] loss: 1.113, acc: 0.758
EPOCH = 36 loss: 1.113, acc: 0.758, val_loss: 1.403, val_acc: 0.742

================================================================================2025-08_11 21:30:56
******** [step = 50] loss: 1.038, acc: 0.767
******** [step = 100] loss: 1.030, acc: 0.767
******** [step = 150] loss: 1.034, acc: 0.767
******** [step = 200] loss: 1.039, acc: 0.767
******** [step = 250] loss: 1.046, acc: 0.766
******** [step = 300] loss: 1.052, acc: 0.765
******** [step = 350] loss: 1.056, acc: 0.765
******** [step = 400] loss: 1.063, acc: 0.764
******** [step = 450] loss: 1.069, acc: 0.763
******** [step = 500] loss: 1.073, acc: 0.763
******** [step = 550] loss: 1.077, acc: 0.762
******** [step = 600] loss: 1.081, acc: 0.762
******** [step = 650] loss: 1.085, acc: 0.761
******** [step = 700] loss: 1.091, acc: 0.761
******** [step = 750] loss: 1.094, acc: 0.760
******** [step = 800] loss: 1.097, acc: 0.760
******** [step = 850] loss: 1.102, acc: 0.759
EPOCH = 37 loss: 1.102, acc: 0.759, val_loss: 1.399, val_acc: 0.743

================================================================================2025-08_11 21:33:02
******** [step = 50] loss: 1.012, acc: 0.774
******** [step = 100] loss: 1.035, acc: 0.769
******** [step = 150] loss: 1.039, acc: 0.768
******** [step = 200] loss: 1.044, acc: 0.768
******** [step = 250] loss: 1.046, acc: 0.767
******** [step = 300] loss: 1.050, acc: 0.766
******** [step = 350] loss: 1.056, acc: 0.766
******** [step = 400] loss: 1.059, acc: 0.765
******** [step = 450] loss: 1.064, acc: 0.764
******** [step = 500] loss: 1.067, acc: 0.764
******** [step = 550] loss: 1.071, acc: 0.764
******** [step = 600] loss: 1.074, acc: 0.763
******** [step = 650] loss: 1.077, acc: 0.763
******** [step = 700] loss: 1.079, acc: 0.762
******** [step = 750] loss: 1.082, acc: 0.762
******** [step = 800] loss: 1.085, acc: 0.762
******** [step = 850] loss: 1.088, acc: 0.762
EPOCH = 38 loss: 1.088, acc: 0.762, val_loss: 1.390, val_acc: 0.746

================================================================================2025-08_11 21:35:09
******** [step = 50] loss: 1.010, acc: 0.772
******** [step = 100] loss: 1.011, acc: 0.773
******** [step = 150] loss: 1.015, acc: 0.772
******** [step = 200] loss: 1.026, acc: 0.771
******** [step = 250] loss: 1.034, acc: 0.769
******** [step = 300] loss: 1.038, acc: 0.769
******** [step = 350] loss: 1.041, acc: 0.769
******** [step = 400] loss: 1.046, acc: 0.768
******** [step = 450] loss: 1.048, acc: 0.767
******** [step = 500] loss: 1.051, acc: 0.767
******** [step = 550] loss: 1.055, acc: 0.767
******** [step = 600] loss: 1.059, acc: 0.766
******** [step = 650] loss: 1.062, acc: 0.766
******** [step = 700] loss: 1.066, acc: 0.765
******** [step = 750] loss: 1.070, acc: 0.765
******** [step = 800] loss: 1.073, acc: 0.765
******** [step = 850] loss: 1.077, acc: 0.764
EPOCH = 39 loss: 1.077, acc: 0.764, val_loss: 1.381, val_acc: 0.747

================================================================================2025-08_11 21:37:11
******** [step = 50] loss: 1.005, acc: 0.775
******** [step = 100] loss: 1.005, acc: 0.775
******** [step = 150] loss: 1.013, acc: 0.773
******** [step = 200] loss: 1.016, acc: 0.772
******** [step = 250] loss: 1.024, acc: 0.771
******** [step = 300] loss: 1.029, acc: 0.771
******** [step = 350] loss: 1.030, acc: 0.771
******** [step = 400] loss: 1.032, acc: 0.770
******** [step = 450] loss: 1.035, acc: 0.770
******** [step = 500] loss: 1.039, acc: 0.769
******** [step = 550] loss: 1.044, acc: 0.769
******** [step = 600] loss: 1.049, acc: 0.768
******** [step = 650] loss: 1.053, acc: 0.768
******** [step = 700] loss: 1.057, acc: 0.767
******** [step = 750] loss: 1.061, acc: 0.767
******** [step = 800] loss: 1.065, acc: 0.766
******** [step = 850] loss: 1.068, acc: 0.766
EPOCH = 40 loss: 1.068, acc: 0.766, val_loss: 1.377, val_acc: 0.747

================================================================================2025-08_11 21:39:19
******** [step = 50] loss: 1.004, acc: 0.774
******** [step = 100] loss: 0.997, acc: 0.775
******** [step = 150] loss: 0.997, acc: 0.775
******** [step = 200] loss: 0.999, acc: 0.776
******** [step = 250] loss: 1.010, acc: 0.773
******** [step = 300] loss: 1.013, acc: 0.773
******** [step = 350] loss: 1.020, acc: 0.772
******** [step = 400] loss: 1.025, acc: 0.772
******** [step = 450] loss: 1.027, acc: 0.771
******** [step = 500] loss: 1.030, acc: 0.771
******** [step = 550] loss: 1.035, acc: 0.770
******** [step = 600] loss: 1.040, acc: 0.770
******** [step = 650] loss: 1.042, acc: 0.770
******** [step = 700] loss: 1.044, acc: 0.769
******** [step = 750] loss: 1.047, acc: 0.769
******** [step = 800] loss: 1.051, acc: 0.769
******** [step = 850] loss: 1.056, acc: 0.768
EPOCH = 41 loss: 1.056, acc: 0.768, val_loss: 1.369, val_acc: 0.750

================================================================================2025-08_11 21:41:28
******** [step = 50] loss: 0.962, acc: 0.783
******** [step = 100] loss: 0.986, acc: 0.778
******** [step = 150] loss: 0.994, acc: 0.776
******** [step = 200] loss: 0.993, acc: 0.777
******** [step = 250] loss: 0.999, acc: 0.776
******** [step = 300] loss: 1.003, acc: 0.775
******** [step = 350] loss: 1.009, acc: 0.774
******** [step = 400] loss: 1.010, acc: 0.774
******** [step = 450] loss: 1.013, acc: 0.774
******** [step = 500] loss: 1.018, acc: 0.773
******** [step = 550] loss: 1.024, acc: 0.772
******** [step = 600] loss: 1.029, acc: 0.772
******** [step = 650] loss: 1.035, acc: 0.771
******** [step = 700] loss: 1.038, acc: 0.771
******** [step = 750] loss: 1.040, acc: 0.770
******** [step = 800] loss: 1.044, acc: 0.770
******** [step = 850] loss: 1.046, acc: 0.770
EPOCH = 42 loss: 1.046, acc: 0.770, val_loss: 1.368, val_acc: 0.750

================================================================================2025-08_11 21:43:34
******** [step = 50] loss: 0.970, acc: 0.782
******** [step = 100] loss: 0.960, acc: 0.784
******** [step = 150] loss: 0.966, acc: 0.782
******** [step = 200] loss: 0.978, acc: 0.780
******** [step = 250] loss: 0.985, acc: 0.778
******** [step = 300] loss: 0.990, acc: 0.778
******** [step = 350] loss: 0.995, acc: 0.777
******** [step = 400] loss: 1.000, acc: 0.776
******** [step = 450] loss: 1.005, acc: 0.776
******** [step = 500] loss: 1.011, acc: 0.775
******** [step = 550] loss: 1.014, acc: 0.774
******** [step = 600] loss: 1.019, acc: 0.774
******** [step = 650] loss: 1.024, acc: 0.773
******** [step = 700] loss: 1.028, acc: 0.773
******** [step = 750] loss: 1.032, acc: 0.772
******** [step = 800] loss: 1.036, acc: 0.772
******** [step = 850] loss: 1.039, acc: 0.771
EPOCH = 43 loss: 1.039, acc: 0.771, val_loss: 1.369, val_acc: 0.750

================================================================================2025-08_11 21:45:42
******** [step = 50] loss: 0.956, acc: 0.781
******** [step = 100] loss: 0.957, acc: 0.781
******** [step = 150] loss: 0.961, acc: 0.782
******** [step = 200] loss: 0.974, acc: 0.780
******** [step = 250] loss: 0.983, acc: 0.779
******** [step = 300] loss: 0.988, acc: 0.778
******** [step = 350] loss: 0.991, acc: 0.778
******** [step = 400] loss: 0.993, acc: 0.777
******** [step = 450] loss: 0.998, acc: 0.777
******** [step = 500] loss: 1.004, acc: 0.776
******** [step = 550] loss: 1.007, acc: 0.775
******** [step = 600] loss: 1.011, acc: 0.775
******** [step = 650] loss: 1.013, acc: 0.775
******** [step = 700] loss: 1.017, acc: 0.774
******** [step = 750] loss: 1.021, acc: 0.774
******** [step = 800] loss: 1.025, acc: 0.774
******** [step = 850] loss: 1.027, acc: 0.773
EPOCH = 44 loss: 1.027, acc: 0.773, val_loss: 1.361, val_acc: 0.751

================================================================================2025-08_11 21:47:50
******** [step = 50] loss: 0.943, acc: 0.785
******** [step = 100] loss: 0.938, acc: 0.787
******** [step = 150] loss: 0.952, acc: 0.785
******** [step = 200] loss: 0.958, acc: 0.783
******** [step = 250] loss: 0.966, acc: 0.782
******** [step = 300] loss: 0.973, acc: 0.781
******** [step = 350] loss: 0.977, acc: 0.781
******** [step = 400] loss: 0.983, acc: 0.780
******** [step = 450] loss: 0.987, acc: 0.779
******** [step = 500] loss: 0.992, acc: 0.779
******** [step = 550] loss: 0.997, acc: 0.778
******** [step = 600] loss: 1.002, acc: 0.777
******** [step = 650] loss: 1.006, acc: 0.777
******** [step = 700] loss: 1.009, acc: 0.776
******** [step = 750] loss: 1.014, acc: 0.776
******** [step = 800] loss: 1.018, acc: 0.775
******** [step = 850] loss: 1.020, acc: 0.775
EPOCH = 45 loss: 1.020, acc: 0.775, val_loss: 1.355, val_acc: 0.753

================================================================================2025-08_11 21:49:59
******** [step = 50] loss: 0.924, acc: 0.787
******** [step = 100] loss: 0.932, acc: 0.787
******** [step = 150] loss: 0.943, acc: 0.785
******** [step = 200] loss: 0.947, acc: 0.785
******** [step = 250] loss: 0.953, acc: 0.784
******** [step = 300] loss: 0.959, acc: 0.783
******** [step = 350] loss: 0.963, acc: 0.783
******** [step = 400] loss: 0.969, acc: 0.781
******** [step = 450] loss: 0.976, acc: 0.780
******** [step = 500] loss: 0.983, acc: 0.779
******** [step = 550] loss: 0.987, acc: 0.779
******** [step = 600] loss: 0.991, acc: 0.779
******** [step = 650] loss: 0.996, acc: 0.778
******** [step = 700] loss: 1.000, acc: 0.778
******** [step = 750] loss: 1.005, acc: 0.777
******** [step = 800] loss: 1.009, acc: 0.777
******** [step = 850] loss: 1.012, acc: 0.776
EPOCH = 46 loss: 1.012, acc: 0.776, val_loss: 1.345, val_acc: 0.755

================================================================================2025-08_11 21:52:07
******** [step = 50] loss: 0.933, acc: 0.784
******** [step = 100] loss: 0.942, acc: 0.784
******** [step = 150] loss: 0.945, acc: 0.784
******** [step = 200] loss: 0.952, acc: 0.784
******** [step = 250] loss: 0.955, acc: 0.783
******** [step = 300] loss: 0.957, acc: 0.783
******** [step = 350] loss: 0.959, acc: 0.783
******** [step = 400] loss: 0.966, acc: 0.782
******** [step = 450] loss: 0.970, acc: 0.782
******** [step = 500] loss: 0.976, acc: 0.781
******** [step = 550] loss: 0.981, acc: 0.780
******** [step = 600] loss: 0.986, acc: 0.780
******** [step = 650] loss: 0.989, acc: 0.780
******** [step = 700] loss: 0.992, acc: 0.779
******** [step = 750] loss: 0.995, acc: 0.779
******** [step = 800] loss: 0.999, acc: 0.779
******** [step = 850] loss: 1.003, acc: 0.778
EPOCH = 47 loss: 1.003, acc: 0.778, val_loss: 1.345, val_acc: 0.755

================================================================================2025-08_11 21:54:18
******** [step = 50] loss: 0.932, acc: 0.788
******** [step = 100] loss: 0.939, acc: 0.787
******** [step = 150] loss: 0.937, acc: 0.788
******** [step = 200] loss: 0.935, acc: 0.788
******** [step = 250] loss: 0.945, acc: 0.787
******** [step = 300] loss: 0.949, acc: 0.786
******** [step = 350] loss: 0.954, acc: 0.785
******** [step = 400] loss: 0.957, acc: 0.785
******** [step = 450] loss: 0.962, acc: 0.784
******** [step = 500] loss: 0.966, acc: 0.784
******** [step = 550] loss: 0.972, acc: 0.783
******** [step = 600] loss: 0.975, acc: 0.783
******** [step = 650] loss: 0.980, acc: 0.782
******** [step = 700] loss: 0.983, acc: 0.781
******** [step = 750] loss: 0.987, acc: 0.781
******** [step = 800] loss: 0.992, acc: 0.781
******** [step = 850] loss: 0.995, acc: 0.780
EPOCH = 48 loss: 0.995, acc: 0.780, val_loss: 1.342, val_acc: 0.756

================================================================================2025-08_11 21:56:23
******** [step = 50] loss: 0.907, acc: 0.789
******** [step = 100] loss: 0.911, acc: 0.789
******** [step = 150] loss: 0.916, acc: 0.789
******** [step = 200] loss: 0.924, acc: 0.789
******** [step = 250] loss: 0.933, acc: 0.788
******** [step = 300] loss: 0.936, acc: 0.787
******** [step = 350] loss: 0.943, acc: 0.786
******** [step = 400] loss: 0.948, acc: 0.786
******** [step = 450] loss: 0.952, acc: 0.785
******** [step = 500] loss: 0.959, acc: 0.784
******** [step = 550] loss: 0.965, acc: 0.783
******** [step = 600] loss: 0.968, acc: 0.783
******** [step = 650] loss: 0.972, acc: 0.783
******** [step = 700] loss: 0.976, acc: 0.782
******** [step = 750] loss: 0.980, acc: 0.782
******** [step = 800] loss: 0.985, acc: 0.781
******** [step = 850] loss: 0.989, acc: 0.781
EPOCH = 49 loss: 0.989, acc: 0.781, val_loss: 1.339, val_acc: 0.757

================================================================================2025-08_11 21:58:30
******** [step = 50] loss: 0.908, acc: 0.791
******** [step = 100] loss: 0.912, acc: 0.791
******** [step = 150] loss: 0.914, acc: 0.791
******** [step = 200] loss: 0.922, acc: 0.791
******** [step = 250] loss: 0.927, acc: 0.790
******** [step = 300] loss: 0.932, acc: 0.789
******** [step = 350] loss: 0.937, acc: 0.788
******** [step = 400] loss: 0.942, acc: 0.787
******** [step = 450] loss: 0.946, acc: 0.787
******** [step = 500] loss: 0.952, acc: 0.786
******** [step = 550] loss: 0.956, acc: 0.785
******** [step = 600] loss: 0.961, acc: 0.785
******** [step = 650] loss: 0.966, acc: 0.784
******** [step = 700] loss: 0.970, acc: 0.784
******** [step = 750] loss: 0.974, acc: 0.784
******** [step = 800] loss: 0.979, acc: 0.783
******** [step = 850] loss: 0.984, acc: 0.782
EPOCH = 50 loss: 0.984, acc: 0.782, val_loss: 1.335, val_acc: 0.758

================================================================================2025-08_11 22:00:35
******** [step = 50] loss: 0.891, acc: 0.797
******** [step = 100] loss: 0.904, acc: 0.794
******** [step = 150] loss: 0.908, acc: 0.793
******** [step = 200] loss: 0.914, acc: 0.792
******** [step = 250] loss: 0.918, acc: 0.791
******** [step = 300] loss: 0.927, acc: 0.790
******** [step = 350] loss: 0.935, acc: 0.789
******** [step = 400] loss: 0.940, acc: 0.788
******** [step = 450] loss: 0.944, acc: 0.788
******** [step = 500] loss: 0.948, acc: 0.787
******** [step = 550] loss: 0.953, acc: 0.787
******** [step = 600] loss: 0.955, acc: 0.786
******** [step = 650] loss: 0.960, acc: 0.786
******** [step = 700] loss: 0.965, acc: 0.785
******** [step = 750] loss: 0.968, acc: 0.785
******** [step = 800] loss: 0.972, acc: 0.784
******** [step = 850] loss: 0.975, acc: 0.784
EPOCH = 51 loss: 0.975, acc: 0.784, val_loss: 1.331, val_acc: 0.758

================================================================================2025-08_11 22:02:39
******** [step = 50] loss: 0.890, acc: 0.796
******** [step = 100] loss: 0.895, acc: 0.795
******** [step = 150] loss: 0.899, acc: 0.794
******** [step = 200] loss: 0.906, acc: 0.793
******** [step = 250] loss: 0.910, acc: 0.792
******** [step = 300] loss: 0.916, acc: 0.791
******** [step = 350] loss: 0.922, acc: 0.791
******** [step = 400] loss: 0.928, acc: 0.790
******** [step = 450] loss: 0.934, acc: 0.789
******** [step = 500] loss: 0.937, acc: 0.789
******** [step = 550] loss: 0.942, acc: 0.788
******** [step = 600] loss: 0.947, acc: 0.787
******** [step = 650] loss: 0.953, acc: 0.787
******** [step = 700] loss: 0.957, acc: 0.786
******** [step = 750] loss: 0.961, acc: 0.786
******** [step = 800] loss: 0.965, acc: 0.785
******** [step = 850] loss: 0.970, acc: 0.784
EPOCH = 52 loss: 0.970, acc: 0.784, val_loss: 1.326, val_acc: 0.759

================================================================================2025-08_11 22:04:45
******** [step = 50] loss: 0.873, acc: 0.797
******** [step = 100] loss: 0.878, acc: 0.797
******** [step = 150] loss: 0.892, acc: 0.795
******** [step = 200] loss: 0.896, acc: 0.794
******** [step = 250] loss: 0.904, acc: 0.793
******** [step = 300] loss: 0.911, acc: 0.792
******** [step = 350] loss: 0.920, acc: 0.791
******** [step = 400] loss: 0.924, acc: 0.791
******** [step = 450] loss: 0.929, acc: 0.790
******** [step = 500] loss: 0.934, acc: 0.790
******** [step = 550] loss: 0.938, acc: 0.789
******** [step = 600] loss: 0.943, acc: 0.789
******** [step = 650] loss: 0.947, acc: 0.788
******** [step = 700] loss: 0.951, acc: 0.787
******** [step = 750] loss: 0.956, acc: 0.787
******** [step = 800] loss: 0.960, acc: 0.786
******** [step = 850] loss: 0.963, acc: 0.786
EPOCH = 53 loss: 0.963, acc: 0.786, val_loss: 1.321, val_acc: 0.761

================================================================================2025-08_11 22:06:51
******** [step = 50] loss: 0.878, acc: 0.795
******** [step = 100] loss: 0.877, acc: 0.798
******** [step = 150] loss: 0.887, acc: 0.796
******** [step = 200] loss: 0.896, acc: 0.795
******** [step = 250] loss: 0.900, acc: 0.794
******** [step = 300] loss: 0.903, acc: 0.794
******** [step = 350] loss: 0.908, acc: 0.793
******** [step = 400] loss: 0.914, acc: 0.792
******** [step = 450] loss: 0.919, acc: 0.791
******** [step = 500] loss: 0.924, acc: 0.791
******** [step = 550] loss: 0.927, acc: 0.790
******** [step = 600] loss: 0.933, acc: 0.790
******** [step = 650] loss: 0.937, acc: 0.789
******** [step = 700] loss: 0.943, acc: 0.789
******** [step = 750] loss: 0.947, acc: 0.788
******** [step = 800] loss: 0.951, acc: 0.787
******** [step = 850] loss: 0.956, acc: 0.787
EPOCH = 54 loss: 0.956, acc: 0.787, val_loss: 1.323, val_acc: 0.760

================================================================================2025-08_11 22:08:56
******** [step = 50] loss: 0.874, acc: 0.799
******** [step = 100] loss: 0.880, acc: 0.799
******** [step = 150] loss: 0.887, acc: 0.797
******** [step = 200] loss: 0.887, acc: 0.798
******** [step = 250] loss: 0.894, acc: 0.796
******** [step = 300] loss: 0.902, acc: 0.795
******** [step = 350] loss: 0.910, acc: 0.794
******** [step = 400] loss: 0.915, acc: 0.793
******** [step = 450] loss: 0.917, acc: 0.793
******** [step = 500] loss: 0.923, acc: 0.792
******** [step = 550] loss: 0.925, acc: 0.791
******** [step = 600] loss: 0.931, acc: 0.791
******** [step = 650] loss: 0.936, acc: 0.790
******** [step = 700] loss: 0.939, acc: 0.790
******** [step = 750] loss: 0.943, acc: 0.789
******** [step = 800] loss: 0.945, acc: 0.789
******** [step = 850] loss: 0.946, acc: 0.789
EPOCH = 55 loss: 0.946, acc: 0.789, val_loss: 1.322, val_acc: 0.762

================================================================================2025-08_11 22:11:01
******** [step = 50] loss: 0.861, acc: 0.799
******** [step = 100] loss: 0.877, acc: 0.798
******** [step = 150] loss: 0.881, acc: 0.796
******** [step = 200] loss: 0.883, acc: 0.796
******** [step = 250] loss: 0.893, acc: 0.795
******** [step = 300] loss: 0.897, acc: 0.794
******** [step = 350] loss: 0.900, acc: 0.794
******** [step = 400] loss: 0.905, acc: 0.793
******** [step = 450] loss: 0.909, acc: 0.793
******** [step = 500] loss: 0.915, acc: 0.792
******** [step = 550] loss: 0.918, acc: 0.792
******** [step = 600] loss: 0.922, acc: 0.791
******** [step = 650] loss: 0.928, acc: 0.791
******** [step = 700] loss: 0.932, acc: 0.790
******** [step = 750] loss: 0.936, acc: 0.790
******** [step = 800] loss: 0.940, acc: 0.789
******** [step = 850] loss: 0.943, acc: 0.789
EPOCH = 56 loss: 0.943, acc: 0.789, val_loss: 1.318, val_acc: 0.762

================================================================================2025-08_11 22:13:04
******** [step = 50] loss: 0.874, acc: 0.797
******** [step = 100] loss: 0.865, acc: 0.799
******** [step = 150] loss: 0.864, acc: 0.800
******** [step = 200] loss: 0.872, acc: 0.799
******** [step = 250] loss: 0.877, acc: 0.799
******** [step = 300] loss: 0.885, acc: 0.797
******** [step = 350] loss: 0.889, acc: 0.797
******** [step = 400] loss: 0.896, acc: 0.796
******** [step = 450] loss: 0.901, acc: 0.795
******** [step = 500] loss: 0.907, acc: 0.794
******** [step = 550] loss: 0.911, acc: 0.794
******** [step = 600] loss: 0.916, acc: 0.793
******** [step = 650] loss: 0.920, acc: 0.793
******** [step = 700] loss: 0.925, acc: 0.792
******** [step = 750] loss: 0.929, acc: 0.792
******** [step = 800] loss: 0.932, acc: 0.791
******** [step = 850] loss: 0.938, acc: 0.791
EPOCH = 57 loss: 0.938, acc: 0.791, val_loss: 1.310, val_acc: 0.763

================================================================================2025-08_11 22:15:09
******** [step = 50] loss: 0.871, acc: 0.800
******** [step = 100] loss: 0.870, acc: 0.800
******** [step = 150] loss: 0.872, acc: 0.800
******** [step = 200] loss: 0.876, acc: 0.799
******** [step = 250] loss: 0.884, acc: 0.798
******** [step = 300] loss: 0.885, acc: 0.798
******** [step = 350] loss: 0.887, acc: 0.798
******** [step = 400] loss: 0.893, acc: 0.797
******** [step = 450] loss: 0.896, acc: 0.797
******** [step = 500] loss: 0.900, acc: 0.796
******** [step = 550] loss: 0.904, acc: 0.796
******** [step = 600] loss: 0.911, acc: 0.795
******** [step = 650] loss: 0.914, acc: 0.794
******** [step = 700] loss: 0.917, acc: 0.794
******** [step = 750] loss: 0.922, acc: 0.793
******** [step = 800] loss: 0.925, acc: 0.793
******** [step = 850] loss: 0.929, acc: 0.793
EPOCH = 58 loss: 0.929, acc: 0.793, val_loss: 1.309, val_acc: 0.764

================================================================================2025-08_11 22:17:17
******** [step = 50] loss: 0.852, acc: 0.803
******** [step = 100] loss: 0.855, acc: 0.803
******** [step = 150] loss: 0.862, acc: 0.802
******** [step = 200] loss: 0.867, acc: 0.801
******** [step = 250] loss: 0.873, acc: 0.800
******** [step = 300] loss: 0.876, acc: 0.800
******** [step = 350] loss: 0.882, acc: 0.799
******** [step = 400] loss: 0.887, acc: 0.798
******** [step = 450] loss: 0.893, acc: 0.797
******** [step = 500] loss: 0.899, acc: 0.796
******** [step = 550] loss: 0.905, acc: 0.796
******** [step = 600] loss: 0.909, acc: 0.795
******** [step = 650] loss: 0.912, acc: 0.795
******** [step = 700] loss: 0.916, acc: 0.794
******** [step = 750] loss: 0.919, acc: 0.794
******** [step = 800] loss: 0.922, acc: 0.794
******** [step = 850] loss: 0.926, acc: 0.793
EPOCH = 59 loss: 0.926, acc: 0.793, val_loss: 1.304, val_acc: 0.766

================================================================================2025-08_11 22:19:26
******** [step = 50] loss: 0.836, acc: 0.806
******** [step = 100] loss: 0.842, acc: 0.804
******** [step = 150] loss: 0.849, acc: 0.803
******** [step = 200] loss: 0.854, acc: 0.802
******** [step = 250] loss: 0.861, acc: 0.801
******** [step = 300] loss: 0.867, acc: 0.801
******** [step = 350] loss: 0.874, acc: 0.800
******** [step = 400] loss: 0.881, acc: 0.799
******** [step = 450] loss: 0.887, acc: 0.798
******** [step = 500] loss: 0.891, acc: 0.797
******** [step = 550] loss: 0.894, acc: 0.797
******** [step = 600] loss: 0.899, acc: 0.797
******** [step = 650] loss: 0.904, acc: 0.796
******** [step = 700] loss: 0.908, acc: 0.796
******** [step = 750] loss: 0.912, acc: 0.795
******** [step = 800] loss: 0.916, acc: 0.795
******** [step = 850] loss: 0.923, acc: 0.794
EPOCH = 60 loss: 0.923, acc: 0.794, val_loss: 1.304, val_acc: 0.766

================================================================================2025-08_11 22:21:33
******** [step = 50] loss: 0.865, acc: 0.800
******** [step = 100] loss: 0.855, acc: 0.803
******** [step = 150] loss: 0.855, acc: 0.802
******** [step = 200] loss: 0.860, acc: 0.802
******** [step = 250] loss: 0.869, acc: 0.800
******** [step = 300] loss: 0.873, acc: 0.800
******** [step = 350] loss: 0.877, acc: 0.799
******** [step = 400] loss: 0.878, acc: 0.799
******** [step = 450] loss: 0.885, acc: 0.798
******** [step = 500] loss: 0.888, acc: 0.798
******** [step = 550] loss: 0.892, acc: 0.798
******** [step = 600] loss: 0.898, acc: 0.797
******** [step = 650] loss: 0.902, acc: 0.796
******** [step = 700] loss: 0.905, acc: 0.796
******** [step = 750] loss: 0.909, acc: 0.796
******** [step = 800] loss: 0.912, acc: 0.796
******** [step = 850] loss: 0.914, acc: 0.795
EPOCH = 61 loss: 0.914, acc: 0.795, val_loss: 1.306, val_acc: 0.766

================================================================================2025-08_11 22:23:39
******** [step = 50] loss: 0.823, acc: 0.808
******** [step = 100] loss: 0.832, acc: 0.807
******** [step = 150] loss: 0.833, acc: 0.807
******** [step = 200] loss: 0.846, acc: 0.805
******** [step = 250] loss: 0.856, acc: 0.803
******** [step = 300] loss: 0.860, acc: 0.802
******** [step = 350] loss: 0.865, acc: 0.802
******** [step = 400] loss: 0.873, acc: 0.801
******** [step = 450] loss: 0.878, acc: 0.800
******** [step = 500] loss: 0.882, acc: 0.800
******** [step = 550] loss: 0.887, acc: 0.799
******** [step = 600] loss: 0.890, acc: 0.799
******** [step = 650] loss: 0.894, acc: 0.798
******** [step = 700] loss: 0.899, acc: 0.798
******** [step = 750] loss: 0.903, acc: 0.797
******** [step = 800] loss: 0.909, acc: 0.797
******** [step = 850] loss: 0.912, acc: 0.796
EPOCH = 62 loss: 0.912, acc: 0.796, val_loss: 1.302, val_acc: 0.766

================================================================================2025-08_11 22:25:51
******** [step = 50] loss: 0.829, acc: 0.807
******** [step = 100] loss: 0.834, acc: 0.806
******** [step = 150] loss: 0.842, acc: 0.804
******** [step = 200] loss: 0.841, acc: 0.804
******** [step = 250] loss: 0.849, acc: 0.804
******** [step = 300] loss: 0.854, acc: 0.803
******** [step = 350] loss: 0.861, acc: 0.802
******** [step = 400] loss: 0.866, acc: 0.801
******** [step = 450] loss: 0.872, acc: 0.801
******** [step = 500] loss: 0.878, acc: 0.800
******** [step = 550] loss: 0.882, acc: 0.799
******** [step = 600] loss: 0.887, acc: 0.799
******** [step = 650] loss: 0.892, acc: 0.798
******** [step = 700] loss: 0.895, acc: 0.798
******** [step = 750] loss: 0.899, acc: 0.797
******** [step = 800] loss: 0.903, acc: 0.797
******** [step = 850] loss: 0.905, acc: 0.797
EPOCH = 63 loss: 0.905, acc: 0.797, val_loss: 1.301, val_acc: 0.766

================================================================================2025-08_11 22:27:59
******** [step = 50] loss: 0.827, acc: 0.808
******** [step = 100] loss: 0.828, acc: 0.808
******** [step = 150] loss: 0.835, acc: 0.807
******** [step = 200] loss: 0.841, acc: 0.807
******** [step = 250] loss: 0.846, acc: 0.806
******** [step = 300] loss: 0.850, acc: 0.805
******** [step = 350] loss: 0.856, acc: 0.804
******** [step = 400] loss: 0.861, acc: 0.803
******** [step = 450] loss: 0.865, acc: 0.803
******** [step = 500] loss: 0.871, acc: 0.802
******** [step = 550] loss: 0.875, acc: 0.801
******** [step = 600] loss: 0.879, acc: 0.801
******** [step = 650] loss: 0.883, acc: 0.800
******** [step = 700] loss: 0.888, acc: 0.799
******** [step = 750] loss: 0.892, acc: 0.799
******** [step = 800] loss: 0.896, acc: 0.799
******** [step = 850] loss: 0.900, acc: 0.798
EPOCH = 64 loss: 0.900, acc: 0.798, val_loss: 1.294, val_acc: 0.767

================================================================================2025-08_11 22:30:03
******** [step = 50] loss: 0.822, acc: 0.810
******** [step = 100] loss: 0.822, acc: 0.810
******** [step = 150] loss: 0.832, acc: 0.808
******** [step = 200] loss: 0.839, acc: 0.806
******** [step = 250] loss: 0.845, acc: 0.805
******** [step = 300] loss: 0.849, acc: 0.805
******** [step = 350] loss: 0.855, acc: 0.804
******** [step = 400] loss: 0.858, acc: 0.804
******** [step = 450] loss: 0.863, acc: 0.803
******** [step = 500] loss: 0.868, acc: 0.802
******** [step = 550] loss: 0.871, acc: 0.802
******** [step = 600] loss: 0.875, acc: 0.801
******** [step = 650] loss: 0.880, acc: 0.801
******** [step = 700] loss: 0.884, acc: 0.800
******** [step = 750] loss: 0.888, acc: 0.800
******** [step = 800] loss: 0.891, acc: 0.800
******** [step = 850] loss: 0.897, acc: 0.799
EPOCH = 65 loss: 0.897, acc: 0.799, val_loss: 1.294, val_acc: 0.768

================================================================================2025-08_11 22:32:07
******** [step = 50] loss: 0.827, acc: 0.807
******** [step = 100] loss: 0.831, acc: 0.807
******** [step = 150] loss: 0.835, acc: 0.807
******** [step = 200] loss: 0.838, acc: 0.807
******** [step = 250] loss: 0.841, acc: 0.806
******** [step = 300] loss: 0.847, acc: 0.805
******** [step = 350] loss: 0.850, acc: 0.805
******** [step = 400] loss: 0.858, acc: 0.804
******** [step = 450] loss: 0.862, acc: 0.803
******** [step = 500] loss: 0.868, acc: 0.802
******** [step = 550] loss: 0.872, acc: 0.802
******** [step = 600] loss: 0.876, acc: 0.801
******** [step = 650] loss: 0.880, acc: 0.801
******** [step = 700] loss: 0.882, acc: 0.801
******** [step = 750] loss: 0.885, acc: 0.800
******** [step = 800] loss: 0.890, acc: 0.800
******** [step = 850] loss: 0.893, acc: 0.799
EPOCH = 66 loss: 0.893, acc: 0.799, val_loss: 1.290, val_acc: 0.768

================================================================================2025-08_11 22:34:10
******** [step = 50] loss: 0.815, acc: 0.811
******** [step = 100] loss: 0.814, acc: 0.811
******** [step = 150] loss: 0.819, acc: 0.810
******** [step = 200] loss: 0.823, acc: 0.810
******** [step = 250] loss: 0.830, acc: 0.810
******** [step = 300] loss: 0.835, acc: 0.809
******** [step = 350] loss: 0.840, acc: 0.808
******** [step = 400] loss: 0.848, acc: 0.806
******** [step = 450] loss: 0.853, acc: 0.806
******** [step = 500] loss: 0.858, acc: 0.805
******** [step = 550] loss: 0.862, acc: 0.805
******** [step = 600] loss: 0.867, acc: 0.804
******** [step = 650] loss: 0.872, acc: 0.803
******** [step = 700] loss: 0.875, acc: 0.803
******** [step = 750] loss: 0.879, acc: 0.802
******** [step = 800] loss: 0.884, acc: 0.802
******** [step = 850] loss: 0.888, acc: 0.801
EPOCH = 67 loss: 0.888, acc: 0.801, val_loss: 1.291, val_acc: 0.769

================================================================================2025-08_11 22:36:13
******** [step = 50] loss: 0.820, acc: 0.809
******** [step = 100] loss: 0.814, acc: 0.811
******** [step = 150] loss: 0.818, acc: 0.811
******** [step = 200] loss: 0.828, acc: 0.809
******** [step = 250] loss: 0.833, acc: 0.808
******** [step = 300] loss: 0.836, acc: 0.808
******** [step = 350] loss: 0.840, acc: 0.807
******** [step = 400] loss: 0.844, acc: 0.807
******** [step = 450] loss: 0.850, acc: 0.806
******** [step = 500] loss: 0.854, acc: 0.805
******** [step = 550] loss: 0.858, acc: 0.805
******** [step = 600] loss: 0.862, acc: 0.804
******** [step = 650] loss: 0.866, acc: 0.804
******** [step = 700] loss: 0.870, acc: 0.804
******** [step = 750] loss: 0.874, acc: 0.803
******** [step = 800] loss: 0.878, acc: 0.803
******** [step = 850] loss: 0.883, acc: 0.802
EPOCH = 68 loss: 0.883, acc: 0.802, val_loss: 1.287, val_acc: 0.770

================================================================================2025-08_11 22:38:21
******** [step = 50] loss: 0.799, acc: 0.815
******** [step = 100] loss: 0.810, acc: 0.812
******** [step = 150] loss: 0.815, acc: 0.811
******** [step = 200] loss: 0.820, acc: 0.810
******** [step = 250] loss: 0.823, acc: 0.809
******** [step = 300] loss: 0.828, acc: 0.809
******** [step = 350] loss: 0.834, acc: 0.808
******** [step = 400] loss: 0.840, acc: 0.807
******** [step = 450] loss: 0.845, acc: 0.807
******** [step = 500] loss: 0.849, acc: 0.806
******** [step = 550] loss: 0.855, acc: 0.805
******** [step = 600] loss: 0.859, acc: 0.805
******** [step = 650] loss: 0.863, acc: 0.804
******** [step = 700] loss: 0.867, acc: 0.804
******** [step = 750] loss: 0.871, acc: 0.803
******** [step = 800] loss: 0.875, acc: 0.803
******** [step = 850] loss: 0.878, acc: 0.803
EPOCH = 69 loss: 0.878, acc: 0.803, val_loss: 1.289, val_acc: 0.769

================================================================================2025-08_11 22:40:29
******** [step = 50] loss: 0.803, acc: 0.813
******** [step = 100] loss: 0.798, acc: 0.813
******** [step = 150] loss: 0.796, acc: 0.814
******** [step = 200] loss: 0.806, acc: 0.813
******** [step = 250] loss: 0.810, acc: 0.812
******** [step = 300] loss: 0.819, acc: 0.811
******** [step = 350] loss: 0.825, acc: 0.810
******** [step = 400] loss: 0.829, acc: 0.809
******** [step = 450] loss: 0.835, acc: 0.808
******** [step = 500] loss: 0.842, acc: 0.807
******** [step = 550] loss: 0.848, acc: 0.807
******** [step = 600] loss: 0.852, acc: 0.806
******** [step = 650] loss: 0.857, acc: 0.806
******** [step = 700] loss: 0.860, acc: 0.805
******** [step = 750] loss: 0.866, acc: 0.805
******** [step = 800] loss: 0.871, acc: 0.804
******** [step = 850] loss: 0.876, acc: 0.803
EPOCH = 70 loss: 0.876, acc: 0.803, val_loss: 1.286, val_acc: 0.770

================================================================================2025-08_11 22:42:32
******** [step = 50] loss: 0.816, acc: 0.807
******** [step = 100] loss: 0.811, acc: 0.810
******** [step = 150] loss: 0.815, acc: 0.810
******** [step = 200] loss: 0.817, acc: 0.810
******** [step = 250] loss: 0.824, acc: 0.809
******** [step = 300] loss: 0.828, acc: 0.808
******** [step = 350] loss: 0.834, acc: 0.808
******** [step = 400] loss: 0.841, acc: 0.807
******** [step = 450] loss: 0.841, acc: 0.807
******** [step = 500] loss: 0.844, acc: 0.807
******** [step = 550] loss: 0.847, acc: 0.806
******** [step = 600] loss: 0.850, acc: 0.806
******** [step = 650] loss: 0.855, acc: 0.805
******** [step = 700] loss: 0.859, acc: 0.805
******** [step = 750] loss: 0.863, acc: 0.804
******** [step = 800] loss: 0.865, acc: 0.804
******** [step = 850] loss: 0.868, acc: 0.804
EPOCH = 71 loss: 0.868, acc: 0.804, val_loss: 1.281, val_acc: 0.771

================================================================================2025-08_11 22:44:37
******** [step = 50] loss: 0.798, acc: 0.816
******** [step = 100] loss: 0.807, acc: 0.813
******** [step = 150] loss: 0.803, acc: 0.813
******** [step = 200] loss: 0.807, acc: 0.813
******** [step = 250] loss: 0.811, acc: 0.812
******** [step = 300] loss: 0.816, acc: 0.811
******** [step = 350] loss: 0.823, acc: 0.810
******** [step = 400] loss: 0.828, acc: 0.809
******** [step = 450] loss: 0.833, acc: 0.809
******** [step = 500] loss: 0.837, acc: 0.808
******** [step = 550] loss: 0.841, acc: 0.808
******** [step = 600] loss: 0.845, acc: 0.807
******** [step = 650] loss: 0.849, acc: 0.807
******** [step = 700] loss: 0.853, acc: 0.806
******** [step = 750] loss: 0.857, acc: 0.806
******** [step = 800] loss: 0.861, acc: 0.805
******** [step = 850] loss: 0.865, acc: 0.805
EPOCH = 72 loss: 0.865, acc: 0.805, val_loss: 1.285, val_acc: 0.770

================================================================================2025-08_11 22:46:40
******** [step = 50] loss: 0.779, acc: 0.818
******** [step = 100] loss: 0.785, acc: 0.816
******** [step = 150] loss: 0.794, acc: 0.815
******** [step = 200] loss: 0.804, acc: 0.814
******** [step = 250] loss: 0.810, acc: 0.813
******** [step = 300] loss: 0.814, acc: 0.812
******** [step = 350] loss: 0.819, acc: 0.812
******** [step = 400] loss: 0.824, acc: 0.811
******** [step = 450] loss: 0.827, acc: 0.810
******** [step = 500] loss: 0.829, acc: 0.810
******** [step = 550] loss: 0.834, acc: 0.809
******** [step = 600] loss: 0.839, acc: 0.809
******** [step = 650] loss: 0.843, acc: 0.808
******** [step = 700] loss: 0.851, acc: 0.807
******** [step = 750] loss: 0.854, acc: 0.807
******** [step = 800] loss: 0.859, acc: 0.806
******** [step = 850] loss: 0.864, acc: 0.806
EPOCH = 73 loss: 0.864, acc: 0.806, val_loss: 1.286, val_acc: 0.770

================================================================================2025-08_11 22:48:47
******** [step = 50] loss: 0.792, acc: 0.816
******** [step = 100] loss: 0.790, acc: 0.816
******** [step = 150] loss: 0.790, acc: 0.817
******** [step = 200] loss: 0.799, acc: 0.815
******** [step = 250] loss: 0.807, acc: 0.813
******** [step = 300] loss: 0.812, acc: 0.812
******** [step = 350] loss: 0.820, acc: 0.811
******** [step = 400] loss: 0.824, acc: 0.811
******** [step = 450] loss: 0.828, acc: 0.810
******** [step = 500] loss: 0.833, acc: 0.809
******** [step = 550] loss: 0.837, acc: 0.809
******** [step = 600] loss: 0.843, acc: 0.808
******** [step = 650] loss: 0.847, acc: 0.808
******** [step = 700] loss: 0.852, acc: 0.807
******** [step = 750] loss: 0.855, acc: 0.806
******** [step = 800] loss: 0.859, acc: 0.806
******** [step = 850] loss: 0.862, acc: 0.806
EPOCH = 74 loss: 0.862, acc: 0.806, val_loss: 1.279, val_acc: 0.771

================================================================================2025-08_11 22:50:56
******** [step = 50] loss: 0.777, acc: 0.817
******** [step = 100] loss: 0.783, acc: 0.816
******** [step = 150] loss: 0.791, acc: 0.815
******** [step = 200] loss: 0.795, acc: 0.814
******** [step = 250] loss: 0.799, acc: 0.814
******** [step = 300] loss: 0.804, acc: 0.814
******** [step = 350] loss: 0.808, acc: 0.813
******** [step = 400] loss: 0.814, acc: 0.812
******** [step = 450] loss: 0.822, acc: 0.811
******** [step = 500] loss: 0.827, acc: 0.810
******** [step = 550] loss: 0.830, acc: 0.810
******** [step = 600] loss: 0.835, acc: 0.810
******** [step = 650] loss: 0.839, acc: 0.809
******** [step = 700] loss: 0.844, acc: 0.809
******** [step = 750] loss: 0.849, acc: 0.808
******** [step = 800] loss: 0.851, acc: 0.808
******** [step = 850] loss: 0.855, acc: 0.807
EPOCH = 75 loss: 0.855, acc: 0.807, val_loss: 1.278, val_acc: 0.772

================================================================================2025-08_11 22:53:00
******** [step = 50] loss: 0.777, acc: 0.820
******** [step = 100] loss: 0.787, acc: 0.819
******** [step = 150] loss: 0.790, acc: 0.817
******** [step = 200] loss: 0.791, acc: 0.817
******** [step = 250] loss: 0.796, acc: 0.816
******** [step = 300] loss: 0.802, acc: 0.815
******** [step = 350] loss: 0.806, acc: 0.814
******** [step = 400] loss: 0.810, acc: 0.814
******** [step = 450] loss: 0.815, acc: 0.813
******** [step = 500] loss: 0.820, acc: 0.812
******** [step = 550] loss: 0.826, acc: 0.811
******** [step = 600] loss: 0.828, acc: 0.811
******** [step = 650] loss: 0.832, acc: 0.811
******** [step = 700] loss: 0.836, acc: 0.810
******** [step = 750] loss: 0.842, acc: 0.809
******** [step = 800] loss: 0.846, acc: 0.809
******** [step = 850] loss: 0.850, acc: 0.808
EPOCH = 76 loss: 0.850, acc: 0.808, val_loss: 1.275, val_acc: 0.774

================================================================================2025-08_11 22:55:12
******** [step = 50] loss: 0.766, acc: 0.821
******** [step = 100] loss: 0.786, acc: 0.818
******** [step = 150] loss: 0.795, acc: 0.816
******** [step = 200] loss: 0.797, acc: 0.815
******** [step = 250] loss: 0.801, acc: 0.814
******** [step = 300] loss: 0.803, acc: 0.814
******** [step = 350] loss: 0.805, acc: 0.814
******** [step = 400] loss: 0.811, acc: 0.813
******** [step = 450] loss: 0.819, acc: 0.812
******** [step = 500] loss: 0.822, acc: 0.811
******** [step = 550] loss: 0.824, acc: 0.811
******** [step = 600] loss: 0.828, acc: 0.811
******** [step = 650] loss: 0.832, acc: 0.810
******** [step = 700] loss: 0.837, acc: 0.810
******** [step = 750] loss: 0.840, acc: 0.809
******** [step = 800] loss: 0.843, acc: 0.809
******** [step = 850] loss: 0.846, acc: 0.809
EPOCH = 77 loss: 0.846, acc: 0.809, val_loss: 1.273, val_acc: 0.773

================================================================================2025-08_11 22:57:17
******** [step = 50] loss: 0.765, acc: 0.821
******** [step = 100] loss: 0.768, acc: 0.820
******** [step = 150] loss: 0.773, acc: 0.819
******** [step = 200] loss: 0.777, acc: 0.818
******** [step = 250] loss: 0.790, acc: 0.815
******** [step = 300] loss: 0.795, acc: 0.815
******** [step = 350] loss: 0.800, acc: 0.814
******** [step = 400] loss: 0.805, acc: 0.814
******** [step = 450] loss: 0.811, acc: 0.813
******** [step = 500] loss: 0.816, acc: 0.812
******** [step = 550] loss: 0.820, acc: 0.812
******** [step = 600] loss: 0.825, acc: 0.811
******** [step = 650] loss: 0.829, acc: 0.811
******** [step = 700] loss: 0.833, acc: 0.810
******** [step = 750] loss: 0.837, acc: 0.810
******** [step = 800] loss: 0.840, acc: 0.809
******** [step = 850] loss: 0.843, acc: 0.809
EPOCH = 78 loss: 0.843, acc: 0.809, val_loss: 1.271, val_acc: 0.773

================================================================================2025-08_11 22:59:27
******** [step = 50] loss: 0.767, acc: 0.820
******** [step = 100] loss: 0.771, acc: 0.820
******** [step = 150] loss: 0.772, acc: 0.820
******** [step = 200] loss: 0.779, acc: 0.819
******** [step = 250] loss: 0.784, acc: 0.818
******** [step = 300] loss: 0.785, acc: 0.817
******** [step = 350] loss: 0.789, acc: 0.817
******** [step = 400] loss: 0.795, acc: 0.816
******** [step = 450] loss: 0.801, acc: 0.816
******** [step = 500] loss: 0.808, acc: 0.815
******** [step = 550] loss: 0.813, acc: 0.814
******** [step = 600] loss: 0.817, acc: 0.813
******** [step = 650] loss: 0.822, acc: 0.813
******** [step = 700] loss: 0.827, acc: 0.812
******** [step = 750] loss: 0.832, acc: 0.811
******** [step = 800] loss: 0.836, acc: 0.811
******** [step = 850] loss: 0.839, acc: 0.810
EPOCH = 79 loss: 0.839, acc: 0.810, val_loss: 1.274, val_acc: 0.771

================================================================================2025-08_11 23:01:36
******** [step = 50] loss: 0.768, acc: 0.821
******** [step = 100] loss: 0.757, acc: 0.823
******** [step = 150] loss: 0.763, acc: 0.822
******** [step = 200] loss: 0.772, acc: 0.821
******** [step = 250] loss: 0.776, acc: 0.820
******** [step = 300] loss: 0.783, acc: 0.819
******** [step = 350] loss: 0.788, acc: 0.818
******** [step = 400] loss: 0.792, acc: 0.817
******** [step = 450] loss: 0.800, acc: 0.816
******** [step = 500] loss: 0.805, acc: 0.815
******** [step = 550] loss: 0.809, acc: 0.814
******** [step = 600] loss: 0.814, acc: 0.814
******** [step = 650] loss: 0.821, acc: 0.813
******** [step = 700] loss: 0.823, acc: 0.813
******** [step = 750] loss: 0.827, acc: 0.812
******** [step = 800] loss: 0.831, acc: 0.812
******** [step = 850] loss: 0.836, acc: 0.811
EPOCH = 80 loss: 0.836, acc: 0.811, val_loss: 1.266, val_acc: 0.776

================================================================================2025-08_11 23:03:38
finishing training...
Training complete in 168m 44s
    epoch  ...   val_acc
0     1.0  ...  0.392747
1     2.0  ...  0.445856
2     3.0  ...  0.460589
3     4.0  ...  0.482719
4     5.0  ...  0.510539
..    ...  ...       ...
75   76.0  ...  0.773581
76   77.0  ...  0.772868
77   78.0  ...  0.773089
78   79.0  ...  0.771372
79   80.0  ...  0.775713

[80 rows x 5 columns]
== Done ==
Mon Aug 11 11:04:14 PM EDT 2025
---------------------------------------
Begin Slurm Epilog: Aug-11-2025 23:04:14
Job ID:        6923955
User ID:       xchen920
Account:       gts-apm7
Job name:      channel_trans
Resources:     cpu=4,gres/gpu:v100=1,mem=16G,node=1
Rsrc Used:     cput=11:30:48,vmem=0,walltime=02:52:42,mem=36220K,energy_used=0
Partition:     gpu-v100
QOS:           inferno
Nodes:         atl1-1-03-006-35-0
---------------------------------------
