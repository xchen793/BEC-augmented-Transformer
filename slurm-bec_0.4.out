---------------------------------------
Begin Slurm Prolog: Aug-10-2025 17:34:20
Job ID:    6783673
User ID:   xchen920
Account:   gts-apm7
Job name:  channel_trans
Partition: gpu-v100
QOS:       inferno
---------------------------------------
== Job info ==
Sun Aug 10 05:34:20 PM EDT 2025
atl1-1-01-003-33-0.pace.gatech.edu
== GPU check ==
Sun Aug 10 17:34:27 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-16GB           On  |   00000000:AF:00.0 Off |                    0 |
| N/A   35C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
== Launch ==
/storage/scratch1/4/xchen920/project
0.10.0
device= cuda:0
  0%|          | 0/135842 [00:00<?, ?it/s] 12%|█▏        | 16831/135842 [00:00<00:01, 104350.91it/s] 28%|██▊       | 37988/135842 [00:00<00:00, 154708.01it/s] 40%|████      | 54730/135842 [00:00<00:00, 118047.45it/s] 51%|█████     | 69378/135842 [00:00<00:00, 93886.49it/s]  66%|██████▌   | 89061/135842 [00:00<00:00, 118575.77it/s] 79%|███████▉  | 107136/135842 [00:01<00:00, 90023.57it/s] 92%|█████████▏| 125151/135842 [00:01<00:00, 107706.84it/s]100%|██████████| 135842/135842 [00:01<00:00, 110689.25it/s]
  0%|          | 0/108673 [00:00<?, ?it/s] 16%|█▌        | 17395/108673 [00:00<00:01, 47104.44it/s] 33%|███▎      | 35334/108673 [00:00<00:00, 84003.13it/s] 49%|████▉     | 53225/108673 [00:00<00:00, 111043.72it/s] 66%|██████▌   | 71325/108673 [00:00<00:00, 131278.74it/s] 81%|████████  | 87522/108673 [00:01<00:00, 70201.25it/s]  97%|█████████▋| 105376/108673 [00:01<00:00, 88935.52it/s]100%|██████████| 108673/108673 [00:01<00:00, 88452.76it/s]
  0%|          | 0/27169 [00:00<?, ?it/s] 65%|██████▍   | 17643/27169 [00:00<00:00, 176417.13it/s]100%|██████████| 27169/27169 [00:00<00:00, 178259.48it/s]
tensor([    3,    40,    20,   559,    24, 13749,    45,    74,     6,    10,
          165,     6,    10,  1768,    25,  3354,    43,    18,   140,    26,
           22,  2340,  2070,     4,     2,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1])
torch.Size([52, 128]) torch.Size([52, 128])
++++++++++++++++ 213
len(train_dataloader): 850
torch.Size([128, 52]) torch.Size([128, 52])
tensor([   3,   19,   23,   81,  252,   16, 1255,   35,   12,   21,   60,    9,
          28,  106, 3389,    7,  444,  123,   17,   15,  226,  109,  335,    4,
           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1]) torch.int64
tensor([   3,    5,  151,   44,  588,   15,   14,   27,   36,   10,  363,    7,
          34, 1288,  111,    6,   75,   36,  454,    7,   20,    4,    2,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1]) torch.int64
*************************** start training...

================================================================================2025-08_10 17:37:02
******** [step = 50] loss: 9.360, acc: 0.009
******** [step = 100] loss: 8.941, acc: 0.077
******** [step = 150] loss: 8.594, acc: 0.124
******** [step = 200] loss: 8.263, acc: 0.155
******** [step = 250] loss: 7.952, acc: 0.174
******** [step = 300] loss: 7.647, acc: 0.189
******** [step = 350] loss: 7.346, acc: 0.201
******** [step = 400] loss: 7.064, acc: 0.213
******** [step = 450] loss: 6.812, acc: 0.224
******** [step = 500] loss: 6.591, acc: 0.235
******** [step = 550] loss: 6.396, acc: 0.245
******** [step = 600] loss: 6.222, acc: 0.254
******** [step = 650] loss: 6.067, acc: 0.262
******** [step = 700] loss: 5.927, acc: 0.269
******** [step = 750] loss: 5.800, acc: 0.276
******** [step = 800] loss: 5.683, acc: 0.283
******** [step = 850] loss: 5.578, acc: 0.289
EPOCH = 1 loss: 5.578, acc: 0.289, val_loss: 3.736, val_acc: 0.403

================================================================================2025-08_10 17:38:38
******** [step = 50] loss: 3.826, acc: 0.386
******** [step = 100] loss: 3.779, acc: 0.390
******** [step = 150] loss: 3.741, acc: 0.394
******** [step = 200] loss: 3.709, acc: 0.397
******** [step = 250] loss: 3.684, acc: 0.400
******** [step = 300] loss: 3.659, acc: 0.403
******** [step = 350] loss: 3.640, acc: 0.405
******** [step = 400] loss: 3.619, acc: 0.407
******** [step = 450] loss: 3.599, acc: 0.410
******** [step = 500] loss: 3.582, acc: 0.411
******** [step = 550] loss: 3.559, acc: 0.414
******** [step = 600] loss: 3.539, acc: 0.416
******** [step = 650] loss: 3.523, acc: 0.417
******** [step = 700] loss: 3.506, acc: 0.419
******** [step = 750] loss: 3.491, acc: 0.421
******** [step = 800] loss: 3.476, acc: 0.422
******** [step = 850] loss: 3.463, acc: 0.423
EPOCH = 2 loss: 3.463, acc: 0.423, val_loss: 3.128, val_acc: 0.462

================================================================================2025-08_10 17:40:09
******** [step = 50] loss: 3.156, acc: 0.449
******** [step = 100] loss: 3.153, acc: 0.450
******** [step = 150] loss: 3.147, acc: 0.452
******** [step = 200] loss: 3.139, acc: 0.453
******** [step = 250] loss: 3.134, acc: 0.453
******** [step = 300] loss: 3.126, acc: 0.454
******** [step = 350] loss: 3.121, acc: 0.455
******** [step = 400] loss: 3.113, acc: 0.456
******** [step = 450] loss: 3.109, acc: 0.457
******** [step = 500] loss: 3.099, acc: 0.458
******** [step = 550] loss: 3.092, acc: 0.459
******** [step = 600] loss: 3.087, acc: 0.460
******** [step = 650] loss: 3.083, acc: 0.461
******** [step = 700] loss: 3.077, acc: 0.462
******** [step = 750] loss: 3.073, acc: 0.462
******** [step = 800] loss: 3.068, acc: 0.463
******** [step = 850] loss: 3.059, acc: 0.464
EPOCH = 3 loss: 3.059, acc: 0.464, val_loss: 2.880, val_acc: 0.488

================================================================================2025-08_10 17:41:30
******** [step = 50] loss: 2.904, acc: 0.477
******** [step = 100] loss: 2.888, acc: 0.479
******** [step = 150] loss: 2.871, acc: 0.482
******** [step = 200] loss: 2.871, acc: 0.481
******** [step = 250] loss: 2.872, acc: 0.481
******** [step = 300] loss: 2.866, acc: 0.482
******** [step = 350] loss: 2.865, acc: 0.482
******** [step = 400] loss: 2.859, acc: 0.483
******** [step = 450] loss: 2.855, acc: 0.484
******** [step = 500] loss: 2.849, acc: 0.485
******** [step = 550] loss: 2.846, acc: 0.486
******** [step = 600] loss: 2.845, acc: 0.486
******** [step = 650] loss: 2.840, acc: 0.486
******** [step = 700] loss: 2.837, acc: 0.487
******** [step = 750] loss: 2.834, acc: 0.487
******** [step = 800] loss: 2.830, acc: 0.488
******** [step = 850] loss: 2.826, acc: 0.489
EPOCH = 4 loss: 2.826, acc: 0.489, val_loss: 2.718, val_acc: 0.511

================================================================================2025-08_10 17:42:50
******** [step = 50] loss: 2.713, acc: 0.498
******** [step = 100] loss: 2.682, acc: 0.502
******** [step = 150] loss: 2.682, acc: 0.501
******** [step = 200] loss: 2.683, acc: 0.501
******** [step = 250] loss: 2.679, acc: 0.502
******** [step = 300] loss: 2.680, acc: 0.502
******** [step = 350] loss: 2.678, acc: 0.503
******** [step = 400] loss: 2.673, acc: 0.504
******** [step = 450] loss: 2.674, acc: 0.504
******** [step = 500] loss: 2.672, acc: 0.504
******** [step = 550] loss: 2.669, acc: 0.505
******** [step = 600] loss: 2.665, acc: 0.505
******** [step = 650] loss: 2.663, acc: 0.506
******** [step = 700] loss: 2.661, acc: 0.506
******** [step = 750] loss: 2.660, acc: 0.507
******** [step = 800] loss: 2.655, acc: 0.508
******** [step = 850] loss: 2.653, acc: 0.509
EPOCH = 5 loss: 2.653, acc: 0.509, val_loss: 2.547, val_acc: 0.530

================================================================================2025-08_10 17:44:10
******** [step = 50] loss: 2.516, acc: 0.523
******** [step = 100] loss: 2.503, acc: 0.525
******** [step = 150] loss: 2.492, acc: 0.527
******** [step = 200] loss: 2.499, acc: 0.526
******** [step = 250] loss: 2.499, acc: 0.525
******** [step = 300] loss: 2.492, acc: 0.527
******** [step = 350] loss: 2.491, acc: 0.527
******** [step = 400] loss: 2.489, acc: 0.528
******** [step = 450] loss: 2.487, acc: 0.528
******** [step = 500] loss: 2.487, acc: 0.528
******** [step = 550] loss: 2.482, acc: 0.529
******** [step = 600] loss: 2.480, acc: 0.530
******** [step = 650] loss: 2.474, acc: 0.531
******** [step = 700] loss: 2.470, acc: 0.531
******** [step = 750] loss: 2.467, acc: 0.532
******** [step = 800] loss: 2.464, acc: 0.533
******** [step = 850] loss: 2.460, acc: 0.533
EPOCH = 6 loss: 2.460, acc: 0.533, val_loss: 2.360, val_acc: 0.559

================================================================================2025-08_10 17:45:36
******** [step = 50] loss: 2.321, acc: 0.545
******** [step = 100] loss: 2.312, acc: 0.547
******** [step = 150] loss: 2.297, acc: 0.551
******** [step = 200] loss: 2.296, acc: 0.552
******** [step = 250] loss: 2.293, acc: 0.553
******** [step = 300] loss: 2.292, acc: 0.553
******** [step = 350] loss: 2.291, acc: 0.554
******** [step = 400] loss: 2.293, acc: 0.554
******** [step = 450] loss: 2.295, acc: 0.554
******** [step = 500] loss: 2.295, acc: 0.555
******** [step = 550] loss: 2.295, acc: 0.555
******** [step = 600] loss: 2.294, acc: 0.556
******** [step = 650] loss: 2.294, acc: 0.556
******** [step = 700] loss: 2.294, acc: 0.556
******** [step = 750] loss: 2.293, acc: 0.557
******** [step = 800] loss: 2.292, acc: 0.557
******** [step = 850] loss: 2.290, acc: 0.557
EPOCH = 7 loss: 2.290, acc: 0.557, val_loss: 2.228, val_acc: 0.578

================================================================================2025-08_10 17:46:58
******** [step = 50] loss: 2.151, acc: 0.572
******** [step = 100] loss: 2.161, acc: 0.570
******** [step = 150] loss: 2.159, acc: 0.571
******** [step = 200] loss: 2.160, acc: 0.571
******** [step = 250] loss: 2.164, acc: 0.571
******** [step = 300] loss: 2.161, acc: 0.572
******** [step = 350] loss: 2.160, acc: 0.573
******** [step = 400] loss: 2.161, acc: 0.573
******** [step = 450] loss: 2.161, acc: 0.573
******** [step = 500] loss: 2.159, acc: 0.574
******** [step = 550] loss: 2.159, acc: 0.574
******** [step = 600] loss: 2.160, acc: 0.574
******** [step = 650] loss: 2.159, acc: 0.575
******** [step = 700] loss: 2.159, acc: 0.575
******** [step = 750] loss: 2.159, acc: 0.575
******** [step = 800] loss: 2.160, acc: 0.575
******** [step = 850] loss: 2.157, acc: 0.575
EPOCH = 8 loss: 2.157, acc: 0.575, val_loss: 2.121, val_acc: 0.598

================================================================================2025-08_10 17:48:18
******** [step = 50] loss: 2.053, acc: 0.586
******** [step = 100] loss: 2.039, acc: 0.588
******** [step = 150] loss: 2.037, acc: 0.588
******** [step = 200] loss: 2.041, acc: 0.588
******** [step = 250] loss: 2.043, acc: 0.588
******** [step = 300] loss: 2.042, acc: 0.589
******** [step = 350] loss: 2.040, acc: 0.590
******** [step = 400] loss: 2.041, acc: 0.590
******** [step = 450] loss: 2.044, acc: 0.590
******** [step = 500] loss: 2.045, acc: 0.590
******** [step = 550] loss: 2.045, acc: 0.591
******** [step = 600] loss: 2.046, acc: 0.591
******** [step = 650] loss: 2.048, acc: 0.591
******** [step = 700] loss: 2.050, acc: 0.591
******** [step = 750] loss: 2.051, acc: 0.591
******** [step = 800] loss: 2.051, acc: 0.591
******** [step = 850] loss: 2.050, acc: 0.592
EPOCH = 9 loss: 2.050, acc: 0.592, val_loss: 2.065, val_acc: 0.605

================================================================================2025-08_10 17:49:43
******** [step = 50] loss: 1.948, acc: 0.600
******** [step = 100] loss: 1.920, acc: 0.606
******** [step = 150] loss: 1.924, acc: 0.607
******** [step = 200] loss: 1.931, acc: 0.606
******** [step = 250] loss: 1.933, acc: 0.606
******** [step = 300] loss: 1.936, acc: 0.606
******** [step = 350] loss: 1.938, acc: 0.606
******** [step = 400] loss: 1.941, acc: 0.606
******** [step = 450] loss: 1.942, acc: 0.606
******** [step = 500] loss: 1.945, acc: 0.606
******** [step = 550] loss: 1.947, acc: 0.606
******** [step = 600] loss: 1.951, acc: 0.606
******** [step = 650] loss: 1.954, acc: 0.606
******** [step = 700] loss: 1.955, acc: 0.606
******** [step = 750] loss: 1.957, acc: 0.606
******** [step = 800] loss: 1.959, acc: 0.606
******** [step = 850] loss: 1.962, acc: 0.606
EPOCH = 10 loss: 1.962, acc: 0.606, val_loss: 2.002, val_acc: 0.620

================================================================================2025-08_10 17:51:03
******** [step = 50] loss: 1.854, acc: 0.617
******** [step = 100] loss: 1.850, acc: 0.619
******** [step = 150] loss: 1.850, acc: 0.620
******** [step = 200] loss: 1.858, acc: 0.620
******** [step = 250] loss: 1.864, acc: 0.619
******** [step = 300] loss: 1.868, acc: 0.618
******** [step = 350] loss: 1.872, acc: 0.618
******** [step = 400] loss: 1.874, acc: 0.618
******** [step = 450] loss: 1.875, acc: 0.617
******** [step = 500] loss: 1.877, acc: 0.618
******** [step = 550] loss: 1.881, acc: 0.617
******** [step = 600] loss: 1.882, acc: 0.617
******** [step = 650] loss: 1.883, acc: 0.618
******** [step = 700] loss: 1.886, acc: 0.617
******** [step = 750] loss: 1.887, acc: 0.617
******** [step = 800] loss: 1.889, acc: 0.617
******** [step = 850] loss: 1.890, acc: 0.617
EPOCH = 11 loss: 1.890, acc: 0.617, val_loss: 1.979, val_acc: 0.622

================================================================================2025-08_10 17:52:23
******** [step = 50] loss: 1.770, acc: 0.630
******** [step = 100] loss: 1.774, acc: 0.630
******** [step = 150] loss: 1.779, acc: 0.630
******** [step = 200] loss: 1.794, acc: 0.628
******** [step = 250] loss: 1.796, acc: 0.629
******** [step = 300] loss: 1.799, acc: 0.628
******** [step = 350] loss: 1.807, acc: 0.627
******** [step = 400] loss: 1.813, acc: 0.627
******** [step = 450] loss: 1.818, acc: 0.627
******** [step = 500] loss: 1.819, acc: 0.627
******** [step = 550] loss: 1.820, acc: 0.627
******** [step = 600] loss: 1.822, acc: 0.627
******** [step = 650] loss: 1.824, acc: 0.627
******** [step = 700] loss: 1.825, acc: 0.627
******** [step = 750] loss: 1.826, acc: 0.627
******** [step = 800] loss: 1.827, acc: 0.627
******** [step = 850] loss: 1.830, acc: 0.627
EPOCH = 12 loss: 1.830, acc: 0.627, val_loss: 1.922, val_acc: 0.637

================================================================================2025-08_10 17:53:52
******** [step = 50] loss: 1.744, acc: 0.635
******** [step = 100] loss: 1.743, acc: 0.636
******** [step = 150] loss: 1.741, acc: 0.638
******** [step = 200] loss: 1.750, acc: 0.636
******** [step = 250] loss: 1.749, acc: 0.637
******** [step = 300] loss: 1.751, acc: 0.637
******** [step = 350] loss: 1.749, acc: 0.637
******** [step = 400] loss: 1.751, acc: 0.637
******** [step = 450] loss: 1.755, acc: 0.637
******** [step = 500] loss: 1.761, acc: 0.636
******** [step = 550] loss: 1.762, acc: 0.636
******** [step = 600] loss: 1.767, acc: 0.636
******** [step = 650] loss: 1.771, acc: 0.636
******** [step = 700] loss: 1.773, acc: 0.636
******** [step = 750] loss: 1.776, acc: 0.635
******** [step = 800] loss: 1.778, acc: 0.635
******** [step = 850] loss: 1.782, acc: 0.635
EPOCH = 13 loss: 1.782, acc: 0.635, val_loss: 1.889, val_acc: 0.642

================================================================================2025-08_10 17:55:21
******** [step = 50] loss: 1.697, acc: 0.643
******** [step = 100] loss: 1.687, acc: 0.645
******** [step = 150] loss: 1.685, acc: 0.646
******** [step = 200] loss: 1.691, acc: 0.646
******** [step = 250] loss: 1.694, acc: 0.646
******** [step = 300] loss: 1.698, acc: 0.645
******** [step = 350] loss: 1.701, acc: 0.645
******** [step = 400] loss: 1.704, acc: 0.645
******** [step = 450] loss: 1.708, acc: 0.644
******** [step = 500] loss: 1.714, acc: 0.644
******** [step = 550] loss: 1.718, acc: 0.643
******** [step = 600] loss: 1.721, acc: 0.643
******** [step = 650] loss: 1.724, acc: 0.643
******** [step = 700] loss: 1.724, acc: 0.644
******** [step = 750] loss: 1.728, acc: 0.643
******** [step = 800] loss: 1.730, acc: 0.643
******** [step = 850] loss: 1.732, acc: 0.643
EPOCH = 14 loss: 1.732, acc: 0.643, val_loss: 1.859, val_acc: 0.648

================================================================================2025-08_10 17:56:49
******** [step = 50] loss: 1.653, acc: 0.651
******** [step = 100] loss: 1.647, acc: 0.653
******** [step = 150] loss: 1.644, acc: 0.653
******** [step = 200] loss: 1.642, acc: 0.653
******** [step = 250] loss: 1.651, acc: 0.652
******** [step = 300] loss: 1.654, acc: 0.652
******** [step = 350] loss: 1.657, acc: 0.652
******** [step = 400] loss: 1.659, acc: 0.652
******** [step = 450] loss: 1.664, acc: 0.652
******** [step = 500] loss: 1.667, acc: 0.652
******** [step = 550] loss: 1.670, acc: 0.651
******** [step = 600] loss: 1.674, acc: 0.651
******** [step = 650] loss: 1.677, acc: 0.651
******** [step = 700] loss: 1.679, acc: 0.651
******** [step = 750] loss: 1.682, acc: 0.651
******** [step = 800] loss: 1.686, acc: 0.651
******** [step = 850] loss: 1.689, acc: 0.650
EPOCH = 15 loss: 1.689, acc: 0.650, val_loss: 1.826, val_acc: 0.655

================================================================================2025-08_10 17:58:09
******** [step = 50] loss: 1.602, acc: 0.659
******** [step = 100] loss: 1.599, acc: 0.660
******** [step = 150] loss: 1.602, acc: 0.661
******** [step = 200] loss: 1.608, acc: 0.660
******** [step = 250] loss: 1.610, acc: 0.660
******** [step = 300] loss: 1.615, acc: 0.660
******** [step = 350] loss: 1.616, acc: 0.660
******** [step = 400] loss: 1.621, acc: 0.660
******** [step = 450] loss: 1.624, acc: 0.659
******** [step = 500] loss: 1.628, acc: 0.659
******** [step = 550] loss: 1.631, acc: 0.658
******** [step = 600] loss: 1.635, acc: 0.658
******** [step = 650] loss: 1.639, acc: 0.658
******** [step = 700] loss: 1.642, acc: 0.658
******** [step = 750] loss: 1.645, acc: 0.657
******** [step = 800] loss: 1.647, acc: 0.657
******** [step = 850] loss: 1.647, acc: 0.657
EPOCH = 16 loss: 1.647, acc: 0.657, val_loss: 1.807, val_acc: 0.660

================================================================================2025-08_10 17:59:31
******** [step = 50] loss: 1.567, acc: 0.666
******** [step = 100] loss: 1.558, acc: 0.668
******** [step = 150] loss: 1.562, acc: 0.668
******** [step = 200] loss: 1.568, acc: 0.666
******** [step = 250] loss: 1.568, acc: 0.666
******** [step = 300] loss: 1.575, acc: 0.666
******** [step = 350] loss: 1.580, acc: 0.665
******** [step = 400] loss: 1.584, acc: 0.665
******** [step = 450] loss: 1.586, acc: 0.664
******** [step = 500] loss: 1.590, acc: 0.664
******** [step = 550] loss: 1.594, acc: 0.664
******** [step = 600] loss: 1.594, acc: 0.664
******** [step = 650] loss: 1.598, acc: 0.663
******** [step = 700] loss: 1.602, acc: 0.663
******** [step = 750] loss: 1.606, acc: 0.663
******** [step = 800] loss: 1.608, acc: 0.663
******** [step = 850] loss: 1.610, acc: 0.663
EPOCH = 17 loss: 1.610, acc: 0.663, val_loss: 1.783, val_acc: 0.665

================================================================================2025-08_10 18:01:02
******** [step = 50] loss: 1.512, acc: 0.676
******** [step = 100] loss: 1.510, acc: 0.675
******** [step = 150] loss: 1.519, acc: 0.674
******** [step = 200] loss: 1.526, acc: 0.673
******** [step = 250] loss: 1.533, acc: 0.673
******** [step = 300] loss: 1.538, acc: 0.672
******** [step = 350] loss: 1.542, acc: 0.672
******** [step = 400] loss: 1.546, acc: 0.671
******** [step = 450] loss: 1.551, acc: 0.671
******** [step = 500] loss: 1.556, acc: 0.670
******** [step = 550] loss: 1.559, acc: 0.670
******** [step = 600] loss: 1.560, acc: 0.670
******** [step = 650] loss: 1.563, acc: 0.670
******** [step = 700] loss: 1.565, acc: 0.670
******** [step = 750] loss: 1.569, acc: 0.669
******** [step = 800] loss: 1.572, acc: 0.669
******** [step = 850] loss: 1.575, acc: 0.669
EPOCH = 18 loss: 1.575, acc: 0.669, val_loss: 1.754, val_acc: 0.668

================================================================================2025-08_10 18:02:34
******** [step = 50] loss: 1.480, acc: 0.679
******** [step = 100] loss: 1.489, acc: 0.680
******** [step = 150] loss: 1.492, acc: 0.680
******** [step = 200] loss: 1.491, acc: 0.680
******** [step = 250] loss: 1.495, acc: 0.679
******** [step = 300] loss: 1.506, acc: 0.678
******** [step = 350] loss: 1.511, acc: 0.677
******** [step = 400] loss: 1.516, acc: 0.676
******** [step = 450] loss: 1.523, acc: 0.675
******** [step = 500] loss: 1.528, acc: 0.674
******** [step = 550] loss: 1.531, acc: 0.674
******** [step = 600] loss: 1.533, acc: 0.674
******** [step = 650] loss: 1.535, acc: 0.674
******** [step = 700] loss: 1.538, acc: 0.674
******** [step = 750] loss: 1.540, acc: 0.674
******** [step = 800] loss: 1.542, acc: 0.674
******** [step = 850] loss: 1.543, acc: 0.674
EPOCH = 19 loss: 1.543, acc: 0.674, val_loss: 1.745, val_acc: 0.673

================================================================================2025-08_10 18:03:54
******** [step = 50] loss: 1.458, acc: 0.686
******** [step = 100] loss: 1.456, acc: 0.686
******** [step = 150] loss: 1.468, acc: 0.683
******** [step = 200] loss: 1.473, acc: 0.683
******** [step = 250] loss: 1.475, acc: 0.683
******** [step = 300] loss: 1.482, acc: 0.682
******** [step = 350] loss: 1.485, acc: 0.681
******** [step = 400] loss: 1.489, acc: 0.681
******** [step = 450] loss: 1.490, acc: 0.681
******** [step = 500] loss: 1.493, acc: 0.680
******** [step = 550] loss: 1.497, acc: 0.680
******** [step = 600] loss: 1.498, acc: 0.680
******** [step = 650] loss: 1.502, acc: 0.680
******** [step = 700] loss: 1.507, acc: 0.680
******** [step = 750] loss: 1.511, acc: 0.679
******** [step = 800] loss: 1.512, acc: 0.679
******** [step = 850] loss: 1.516, acc: 0.679
EPOCH = 20 loss: 1.516, acc: 0.679, val_loss: 1.731, val_acc: 0.676

================================================================================2025-08_10 18:05:14
******** [step = 50] loss: 1.435, acc: 0.687
******** [step = 100] loss: 1.429, acc: 0.689
******** [step = 150] loss: 1.432, acc: 0.689
******** [step = 200] loss: 1.436, acc: 0.689
******** [step = 250] loss: 1.438, acc: 0.688
******** [step = 300] loss: 1.444, acc: 0.687
******** [step = 350] loss: 1.450, acc: 0.686
******** [step = 400] loss: 1.456, acc: 0.686
******** [step = 450] loss: 1.462, acc: 0.685
******** [step = 500] loss: 1.468, acc: 0.685
******** [step = 550] loss: 1.470, acc: 0.685
******** [step = 600] loss: 1.474, acc: 0.684
******** [step = 650] loss: 1.477, acc: 0.684
******** [step = 700] loss: 1.480, acc: 0.684
******** [step = 750] loss: 1.483, acc: 0.684
******** [step = 800] loss: 1.485, acc: 0.684
******** [step = 850] loss: 1.489, acc: 0.684
EPOCH = 21 loss: 1.489, acc: 0.684, val_loss: 1.714, val_acc: 0.679

================================================================================2025-08_10 18:06:33
******** [step = 50] loss: 1.388, acc: 0.697
******** [step = 100] loss: 1.399, acc: 0.696
******** [step = 150] loss: 1.400, acc: 0.695
******** [step = 200] loss: 1.408, acc: 0.694
******** [step = 250] loss: 1.414, acc: 0.693
******** [step = 300] loss: 1.421, acc: 0.692
******** [step = 350] loss: 1.427, acc: 0.691
******** [step = 400] loss: 1.430, acc: 0.691
******** [step = 450] loss: 1.436, acc: 0.691
******** [step = 500] loss: 1.442, acc: 0.690
******** [step = 550] loss: 1.444, acc: 0.689
******** [step = 600] loss: 1.447, acc: 0.689
******** [step = 650] loss: 1.450, acc: 0.689
******** [step = 700] loss: 1.453, acc: 0.688
******** [step = 750] loss: 1.457, acc: 0.688
******** [step = 800] loss: 1.460, acc: 0.688
******** [step = 850] loss: 1.462, acc: 0.688
EPOCH = 22 loss: 1.462, acc: 0.688, val_loss: 1.706, val_acc: 0.680

================================================================================2025-08_10 18:07:54
******** [step = 50] loss: 1.351, acc: 0.704
******** [step = 100] loss: 1.362, acc: 0.702
******** [step = 150] loss: 1.373, acc: 0.700
******** [step = 200] loss: 1.383, acc: 0.699
******** [step = 250] loss: 1.388, acc: 0.698
******** [step = 300] loss: 1.393, acc: 0.697
******** [step = 350] loss: 1.397, acc: 0.697
******** [step = 400] loss: 1.401, acc: 0.696
******** [step = 450] loss: 1.410, acc: 0.695
******** [step = 500] loss: 1.415, acc: 0.694
******** [step = 550] loss: 1.420, acc: 0.694
******** [step = 600] loss: 1.425, acc: 0.693
******** [step = 650] loss: 1.429, acc: 0.693
******** [step = 700] loss: 1.431, acc: 0.693
******** [step = 750] loss: 1.434, acc: 0.692
******** [step = 800] loss: 1.438, acc: 0.692
******** [step = 850] loss: 1.440, acc: 0.692
EPOCH = 23 loss: 1.440, acc: 0.692, val_loss: 1.689, val_acc: 0.683

================================================================================2025-08_10 18:09:14
******** [step = 50] loss: 1.358, acc: 0.702
******** [step = 100] loss: 1.348, acc: 0.703
******** [step = 150] loss: 1.359, acc: 0.702
******** [step = 200] loss: 1.369, acc: 0.700
******** [step = 250] loss: 1.374, acc: 0.700
******** [step = 300] loss: 1.375, acc: 0.700
******** [step = 350] loss: 1.381, acc: 0.699
******** [step = 400] loss: 1.384, acc: 0.699
******** [step = 450] loss: 1.388, acc: 0.698
******** [step = 500] loss: 1.394, acc: 0.698
******** [step = 550] loss: 1.399, acc: 0.697
******** [step = 600] loss: 1.402, acc: 0.697
******** [step = 650] loss: 1.407, acc: 0.697
******** [step = 700] loss: 1.411, acc: 0.696
******** [step = 750] loss: 1.415, acc: 0.696
******** [step = 800] loss: 1.417, acc: 0.696
******** [step = 850] loss: 1.418, acc: 0.696
EPOCH = 24 loss: 1.418, acc: 0.696, val_loss: 1.676, val_acc: 0.687

================================================================================2025-08_10 18:10:34
******** [step = 50] loss: 1.338, acc: 0.705
******** [step = 100] loss: 1.336, acc: 0.706
******** [step = 150] loss: 1.336, acc: 0.706
******** [step = 200] loss: 1.342, acc: 0.706
******** [step = 250] loss: 1.348, acc: 0.704
******** [step = 300] loss: 1.358, acc: 0.703
******** [step = 350] loss: 1.361, acc: 0.702
******** [step = 400] loss: 1.363, acc: 0.702
******** [step = 450] loss: 1.367, acc: 0.702
******** [step = 500] loss: 1.372, acc: 0.701
******** [step = 550] loss: 1.377, acc: 0.701
******** [step = 600] loss: 1.379, acc: 0.701
******** [step = 650] loss: 1.383, acc: 0.700
******** [step = 700] loss: 1.387, acc: 0.700
******** [step = 750] loss: 1.391, acc: 0.700
******** [step = 800] loss: 1.395, acc: 0.699
******** [step = 850] loss: 1.399, acc: 0.699
EPOCH = 25 loss: 1.399, acc: 0.699, val_loss: 1.668, val_acc: 0.688

================================================================================2025-08_10 18:12:05
******** [step = 50] loss: 1.312, acc: 0.710
******** [step = 100] loss: 1.317, acc: 0.710
******** [step = 150] loss: 1.316, acc: 0.710
******** [step = 200] loss: 1.325, acc: 0.709
******** [step = 250] loss: 1.333, acc: 0.707
******** [step = 300] loss: 1.339, acc: 0.706
******** [step = 350] loss: 1.344, acc: 0.705
******** [step = 400] loss: 1.347, acc: 0.706
******** [step = 450] loss: 1.351, acc: 0.705
******** [step = 500] loss: 1.355, acc: 0.705
******** [step = 550] loss: 1.358, acc: 0.704
******** [step = 600] loss: 1.363, acc: 0.704
******** [step = 650] loss: 1.367, acc: 0.703
******** [step = 700] loss: 1.371, acc: 0.703
******** [step = 750] loss: 1.376, acc: 0.702
******** [step = 800] loss: 1.378, acc: 0.702
******** [step = 850] loss: 1.379, acc: 0.702
EPOCH = 26 loss: 1.379, acc: 0.702, val_loss: 1.657, val_acc: 0.690

================================================================================2025-08_10 18:13:26
******** [step = 50] loss: 1.282, acc: 0.716
******** [step = 100] loss: 1.296, acc: 0.714
******** [step = 150] loss: 1.301, acc: 0.713
******** [step = 200] loss: 1.313, acc: 0.710
******** [step = 250] loss: 1.316, acc: 0.710
******** [step = 300] loss: 1.321, acc: 0.709
******** [step = 350] loss: 1.327, acc: 0.709
******** [step = 400] loss: 1.334, acc: 0.707
******** [step = 450] loss: 1.337, acc: 0.707
******** [step = 500] loss: 1.338, acc: 0.707
******** [step = 550] loss: 1.342, acc: 0.707
******** [step = 600] loss: 1.344, acc: 0.706
******** [step = 650] loss: 1.346, acc: 0.706
******** [step = 700] loss: 1.350, acc: 0.706
******** [step = 750] loss: 1.355, acc: 0.705
******** [step = 800] loss: 1.358, acc: 0.705
******** [step = 850] loss: 1.360, acc: 0.705
EPOCH = 27 loss: 1.360, acc: 0.705, val_loss: 1.641, val_acc: 0.694

================================================================================2025-08_10 18:14:47
******** [step = 50] loss: 1.272, acc: 0.717
******** [step = 100] loss: 1.267, acc: 0.718
******** [step = 150] loss: 1.272, acc: 0.717
******** [step = 200] loss: 1.286, acc: 0.714
******** [step = 250] loss: 1.291, acc: 0.714
******** [step = 300] loss: 1.298, acc: 0.713
******** [step = 350] loss: 1.303, acc: 0.712
******** [step = 400] loss: 1.308, acc: 0.712
******** [step = 450] loss: 1.314, acc: 0.711
******** [step = 500] loss: 1.319, acc: 0.711
******** [step = 550] loss: 1.322, acc: 0.710
******** [step = 600] loss: 1.326, acc: 0.710
******** [step = 650] loss: 1.329, acc: 0.710
******** [step = 700] loss: 1.334, acc: 0.709
******** [step = 750] loss: 1.338, acc: 0.708
******** [step = 800] loss: 1.341, acc: 0.708
******** [step = 850] loss: 1.346, acc: 0.708
EPOCH = 28 loss: 1.346, acc: 0.708, val_loss: 1.643, val_acc: 0.693

================================================================================2025-08_10 18:16:09
******** [step = 50] loss: 1.266, acc: 0.718
******** [step = 100] loss: 1.259, acc: 0.719
******** [step = 150] loss: 1.264, acc: 0.719
******** [step = 200] loss: 1.265, acc: 0.719
******** [step = 250] loss: 1.273, acc: 0.717
******** [step = 300] loss: 1.278, acc: 0.717
******** [step = 350] loss: 1.286, acc: 0.715
******** [step = 400] loss: 1.293, acc: 0.715
******** [step = 450] loss: 1.300, acc: 0.714
******** [step = 500] loss: 1.305, acc: 0.713
******** [step = 550] loss: 1.312, acc: 0.712
******** [step = 600] loss: 1.315, acc: 0.712
******** [step = 650] loss: 1.317, acc: 0.712
******** [step = 700] loss: 1.319, acc: 0.712
******** [step = 750] loss: 1.323, acc: 0.711
******** [step = 800] loss: 1.326, acc: 0.711
******** [step = 850] loss: 1.329, acc: 0.711
EPOCH = 29 loss: 1.329, acc: 0.711, val_loss: 1.627, val_acc: 0.697

================================================================================2025-08_10 18:17:29
******** [step = 50] loss: 1.253, acc: 0.718
******** [step = 100] loss: 1.250, acc: 0.719
******** [step = 150] loss: 1.255, acc: 0.720
******** [step = 200] loss: 1.260, acc: 0.719
******** [step = 250] loss: 1.263, acc: 0.719
******** [step = 300] loss: 1.266, acc: 0.719
******** [step = 350] loss: 1.270, acc: 0.719
******** [step = 400] loss: 1.277, acc: 0.718
******** [step = 450] loss: 1.283, acc: 0.717
******** [step = 500] loss: 1.289, acc: 0.716
******** [step = 550] loss: 1.294, acc: 0.716
******** [step = 600] loss: 1.297, acc: 0.715
******** [step = 650] loss: 1.301, acc: 0.715
******** [step = 700] loss: 1.304, acc: 0.714
******** [step = 750] loss: 1.309, acc: 0.714
******** [step = 800] loss: 1.311, acc: 0.714
******** [step = 850] loss: 1.314, acc: 0.713
EPOCH = 30 loss: 1.314, acc: 0.713, val_loss: 1.621, val_acc: 0.699

================================================================================2025-08_10 18:18:48
******** [step = 50] loss: 1.248, acc: 0.721
******** [step = 100] loss: 1.246, acc: 0.723
******** [step = 150] loss: 1.250, acc: 0.721
******** [step = 200] loss: 1.253, acc: 0.721
******** [step = 250] loss: 1.255, acc: 0.720
******** [step = 300] loss: 1.256, acc: 0.720
******** [step = 350] loss: 1.261, acc: 0.720
******** [step = 400] loss: 1.267, acc: 0.719
******** [step = 450] loss: 1.275, acc: 0.718
******** [step = 500] loss: 1.281, acc: 0.717
******** [step = 550] loss: 1.283, acc: 0.717
******** [step = 600] loss: 1.284, acc: 0.717
******** [step = 650] loss: 1.288, acc: 0.717
******** [step = 700] loss: 1.291, acc: 0.717
******** [step = 750] loss: 1.294, acc: 0.716
******** [step = 800] loss: 1.297, acc: 0.716
******** [step = 850] loss: 1.301, acc: 0.715
EPOCH = 31 loss: 1.301, acc: 0.715, val_loss: 1.611, val_acc: 0.701

================================================================================2025-08_10 18:20:14
******** [step = 50] loss: 1.224, acc: 0.726
******** [step = 100] loss: 1.214, acc: 0.728
******** [step = 150] loss: 1.222, acc: 0.726
******** [step = 200] loss: 1.229, acc: 0.725
******** [step = 250] loss: 1.234, acc: 0.724
******** [step = 300] loss: 1.238, acc: 0.724
******** [step = 350] loss: 1.243, acc: 0.723
******** [step = 400] loss: 1.250, acc: 0.722
******** [step = 450] loss: 1.256, acc: 0.722
******** [step = 500] loss: 1.261, acc: 0.721
******** [step = 550] loss: 1.266, acc: 0.721
******** [step = 600] loss: 1.269, acc: 0.720
******** [step = 650] loss: 1.273, acc: 0.720
******** [step = 700] loss: 1.276, acc: 0.719
******** [step = 750] loss: 1.280, acc: 0.719
******** [step = 800] loss: 1.282, acc: 0.719
******** [step = 850] loss: 1.290, acc: 0.718
EPOCH = 32 loss: 1.290, acc: 0.718, val_loss: 1.611, val_acc: 0.701

================================================================================2025-08_10 18:21:39
******** [step = 50] loss: 1.207, acc: 0.728
******** [step = 100] loss: 1.215, acc: 0.728
******** [step = 150] loss: 1.219, acc: 0.727
******** [step = 200] loss: 1.215, acc: 0.728
******** [step = 250] loss: 1.219, acc: 0.728
******** [step = 300] loss: 1.225, acc: 0.727
******** [step = 350] loss: 1.233, acc: 0.725
******** [step = 400] loss: 1.237, acc: 0.725
******** [step = 450] loss: 1.241, acc: 0.724
******** [step = 500] loss: 1.246, acc: 0.724
******** [step = 550] loss: 1.249, acc: 0.724
******** [step = 600] loss: 1.255, acc: 0.723
******** [step = 650] loss: 1.258, acc: 0.723
******** [step = 700] loss: 1.262, acc: 0.722
******** [step = 750] loss: 1.266, acc: 0.722
******** [step = 800] loss: 1.269, acc: 0.721
******** [step = 850] loss: 1.272, acc: 0.721
EPOCH = 33 loss: 1.272, acc: 0.721, val_loss: 1.600, val_acc: 0.703

================================================================================2025-08_10 18:23:02
******** [step = 50] loss: 1.190, acc: 0.730
******** [step = 100] loss: 1.202, acc: 0.728
******** [step = 150] loss: 1.204, acc: 0.729
******** [step = 200] loss: 1.210, acc: 0.728
******** [step = 250] loss: 1.216, acc: 0.727
******** [step = 300] loss: 1.216, acc: 0.727
******** [step = 350] loss: 1.222, acc: 0.726
******** [step = 400] loss: 1.225, acc: 0.726
******** [step = 450] loss: 1.229, acc: 0.726
******** [step = 500] loss: 1.234, acc: 0.725
******** [step = 550] loss: 1.237, acc: 0.725
******** [step = 600] loss: 1.242, acc: 0.724
******** [step = 650] loss: 1.246, acc: 0.724
******** [step = 700] loss: 1.251, acc: 0.723
******** [step = 750] loss: 1.253, acc: 0.723
******** [step = 800] loss: 1.258, acc: 0.722
******** [step = 850] loss: 1.261, acc: 0.722
EPOCH = 34 loss: 1.261, acc: 0.722, val_loss: 1.590, val_acc: 0.705

================================================================================2025-08_10 18:24:36
******** [step = 50] loss: 1.152, acc: 0.739
******** [step = 100] loss: 1.161, acc: 0.736
******** [step = 150] loss: 1.175, acc: 0.734
******** [step = 200] loss: 1.184, acc: 0.733
******** [step = 250] loss: 1.190, acc: 0.732
******** [step = 300] loss: 1.199, acc: 0.731
******** [step = 350] loss: 1.205, acc: 0.730
******** [step = 400] loss: 1.208, acc: 0.730
******** [step = 450] loss: 1.214, acc: 0.729
******** [step = 500] loss: 1.220, acc: 0.728
******** [step = 550] loss: 1.222, acc: 0.728
******** [step = 600] loss: 1.229, acc: 0.727
******** [step = 650] loss: 1.232, acc: 0.727
******** [step = 700] loss: 1.236, acc: 0.726
******** [step = 750] loss: 1.241, acc: 0.726
******** [step = 800] loss: 1.244, acc: 0.726
******** [step = 850] loss: 1.249, acc: 0.725
EPOCH = 35 loss: 1.249, acc: 0.725, val_loss: 1.588, val_acc: 0.707

================================================================================2025-08_10 18:25:56
******** [step = 50] loss: 1.163, acc: 0.738
******** [step = 100] loss: 1.166, acc: 0.737
******** [step = 150] loss: 1.169, acc: 0.736
******** [step = 200] loss: 1.179, acc: 0.735
******** [step = 250] loss: 1.186, acc: 0.734
******** [step = 300] loss: 1.190, acc: 0.733
******** [step = 350] loss: 1.195, acc: 0.732
******** [step = 400] loss: 1.200, acc: 0.731
******** [step = 450] loss: 1.203, acc: 0.731
******** [step = 500] loss: 1.210, acc: 0.730
******** [step = 550] loss: 1.217, acc: 0.729
******** [step = 600] loss: 1.222, acc: 0.728
******** [step = 650] loss: 1.225, acc: 0.728
******** [step = 700] loss: 1.229, acc: 0.728
******** [step = 750] loss: 1.233, acc: 0.728
******** [step = 800] loss: 1.236, acc: 0.727
******** [step = 850] loss: 1.239, acc: 0.727
EPOCH = 36 loss: 1.239, acc: 0.727, val_loss: 1.576, val_acc: 0.708

================================================================================2025-08_10 18:27:16
******** [step = 50] loss: 1.154, acc: 0.739
******** [step = 100] loss: 1.158, acc: 0.737
******** [step = 150] loss: 1.161, acc: 0.736
******** [step = 200] loss: 1.171, acc: 0.735
******** [step = 250] loss: 1.179, acc: 0.734
******** [step = 300] loss: 1.183, acc: 0.733
******** [step = 350] loss: 1.186, acc: 0.733
******** [step = 400] loss: 1.191, acc: 0.733
******** [step = 450] loss: 1.196, acc: 0.732
******** [step = 500] loss: 1.201, acc: 0.732
******** [step = 550] loss: 1.204, acc: 0.731
******** [step = 600] loss: 1.208, acc: 0.731
******** [step = 650] loss: 1.213, acc: 0.730
******** [step = 700] loss: 1.219, acc: 0.729
******** [step = 750] loss: 1.221, acc: 0.729
******** [step = 800] loss: 1.225, acc: 0.729
******** [step = 850] loss: 1.231, acc: 0.728
EPOCH = 37 loss: 1.231, acc: 0.728, val_loss: 1.579, val_acc: 0.708

================================================================================2025-08_10 18:28:36
******** [step = 50] loss: 1.144, acc: 0.740
******** [step = 100] loss: 1.146, acc: 0.739
******** [step = 150] loss: 1.150, acc: 0.739
******** [step = 200] loss: 1.156, acc: 0.738
******** [step = 250] loss: 1.171, acc: 0.736
******** [step = 300] loss: 1.173, acc: 0.736
******** [step = 350] loss: 1.178, acc: 0.735
******** [step = 400] loss: 1.182, acc: 0.735
******** [step = 450] loss: 1.185, acc: 0.735
******** [step = 500] loss: 1.187, acc: 0.735
******** [step = 550] loss: 1.193, acc: 0.734
******** [step = 600] loss: 1.197, acc: 0.733
******** [step = 650] loss: 1.202, acc: 0.733
******** [step = 700] loss: 1.206, acc: 0.732
******** [step = 750] loss: 1.209, acc: 0.732
******** [step = 800] loss: 1.213, acc: 0.731
******** [step = 850] loss: 1.217, acc: 0.731
EPOCH = 38 loss: 1.217, acc: 0.731, val_loss: 1.571, val_acc: 0.710

================================================================================2025-08_10 18:30:01
******** [step = 50] loss: 1.132, acc: 0.742
******** [step = 100] loss: 1.137, acc: 0.742
******** [step = 150] loss: 1.141, acc: 0.741
******** [step = 200] loss: 1.152, acc: 0.738
******** [step = 250] loss: 1.159, acc: 0.738
******** [step = 300] loss: 1.161, acc: 0.738
******** [step = 350] loss: 1.169, acc: 0.737
******** [step = 400] loss: 1.171, acc: 0.737
******** [step = 450] loss: 1.174, acc: 0.736
******** [step = 500] loss: 1.178, acc: 0.736
******** [step = 550] loss: 1.183, acc: 0.735
******** [step = 600] loss: 1.188, acc: 0.735
******** [step = 650] loss: 1.192, acc: 0.734
******** [step = 700] loss: 1.196, acc: 0.734
******** [step = 750] loss: 1.200, acc: 0.733
******** [step = 800] loss: 1.204, acc: 0.733
******** [step = 850] loss: 1.209, acc: 0.732
EPOCH = 39 loss: 1.209, acc: 0.732, val_loss: 1.577, val_acc: 0.707

================================================================================2025-08_10 18:31:21
******** [step = 50] loss: 1.126, acc: 0.742
******** [step = 100] loss: 1.122, acc: 0.744
******** [step = 150] loss: 1.134, acc: 0.742
******** [step = 200] loss: 1.145, acc: 0.740
******** [step = 250] loss: 1.149, acc: 0.740
******** [step = 300] loss: 1.154, acc: 0.739
******** [step = 350] loss: 1.160, acc: 0.738
******** [step = 400] loss: 1.166, acc: 0.738
******** [step = 450] loss: 1.170, acc: 0.738
******** [step = 500] loss: 1.174, acc: 0.737
******** [step = 550] loss: 1.177, acc: 0.737
******** [step = 600] loss: 1.182, acc: 0.736
******** [step = 650] loss: 1.185, acc: 0.736
******** [step = 700] loss: 1.189, acc: 0.735
******** [step = 750] loss: 1.192, acc: 0.735
******** [step = 800] loss: 1.197, acc: 0.734
******** [step = 850] loss: 1.199, acc: 0.734
EPOCH = 40 loss: 1.199, acc: 0.734, val_loss: 1.565, val_acc: 0.711

================================================================================2025-08_10 18:32:41
******** [step = 50] loss: 1.138, acc: 0.742
******** [step = 100] loss: 1.132, acc: 0.744
******** [step = 150] loss: 1.133, acc: 0.744
******** [step = 200] loss: 1.139, acc: 0.743
******** [step = 250] loss: 1.148, acc: 0.741
******** [step = 300] loss: 1.150, acc: 0.741
******** [step = 350] loss: 1.156, acc: 0.740
******** [step = 400] loss: 1.158, acc: 0.740
******** [step = 450] loss: 1.161, acc: 0.740
******** [step = 500] loss: 1.165, acc: 0.739
******** [step = 550] loss: 1.169, acc: 0.738
******** [step = 600] loss: 1.174, acc: 0.738
******** [step = 650] loss: 1.176, acc: 0.737
******** [step = 700] loss: 1.181, acc: 0.737
******** [step = 750] loss: 1.186, acc: 0.736
******** [step = 800] loss: 1.189, acc: 0.736
******** [step = 850] loss: 1.191, acc: 0.736
EPOCH = 41 loss: 1.191, acc: 0.736, val_loss: 1.563, val_acc: 0.713

================================================================================2025-08_10 18:34:02
******** [step = 50] loss: 1.108, acc: 0.744
******** [step = 100] loss: 1.111, acc: 0.746
******** [step = 150] loss: 1.111, acc: 0.746
******** [step = 200] loss: 1.121, acc: 0.745
******** [step = 250] loss: 1.125, acc: 0.745
******** [step = 300] loss: 1.131, acc: 0.744
******** [step = 350] loss: 1.137, acc: 0.743
******** [step = 400] loss: 1.142, acc: 0.742
******** [step = 450] loss: 1.148, acc: 0.741
******** [step = 500] loss: 1.154, acc: 0.741
******** [step = 550] loss: 1.158, acc: 0.740
******** [step = 600] loss: 1.164, acc: 0.739
******** [step = 650] loss: 1.168, acc: 0.739
******** [step = 700] loss: 1.171, acc: 0.738
******** [step = 750] loss: 1.175, acc: 0.738
******** [step = 800] loss: 1.179, acc: 0.738
******** [step = 850] loss: 1.182, acc: 0.738
EPOCH = 42 loss: 1.182, acc: 0.738, val_loss: 1.556, val_acc: 0.711

================================================================================2025-08_10 18:35:26
******** [step = 50] loss: 1.092, acc: 0.748
******** [step = 100] loss: 1.096, acc: 0.748
******** [step = 150] loss: 1.106, acc: 0.747
******** [step = 200] loss: 1.116, acc: 0.746
******** [step = 250] loss: 1.124, acc: 0.744
******** [step = 300] loss: 1.127, acc: 0.745
******** [step = 350] loss: 1.131, acc: 0.744
******** [step = 400] loss: 1.136, acc: 0.743
******** [step = 450] loss: 1.140, acc: 0.743
******** [step = 500] loss: 1.146, acc: 0.742
******** [step = 550] loss: 1.151, acc: 0.741
******** [step = 600] loss: 1.157, acc: 0.740
******** [step = 650] loss: 1.162, acc: 0.740
******** [step = 700] loss: 1.163, acc: 0.740
******** [step = 750] loss: 1.167, acc: 0.740
******** [step = 800] loss: 1.169, acc: 0.740
******** [step = 850] loss: 1.172, acc: 0.740
EPOCH = 43 loss: 1.172, acc: 0.740, val_loss: 1.552, val_acc: 0.716

================================================================================2025-08_10 18:36:52
******** [step = 50] loss: 1.087, acc: 0.750
******** [step = 100] loss: 1.083, acc: 0.751
******** [step = 150] loss: 1.098, acc: 0.749
******** [step = 200] loss: 1.104, acc: 0.748
******** [step = 250] loss: 1.116, acc: 0.746
******** [step = 300] loss: 1.118, acc: 0.746
******** [step = 350] loss: 1.122, acc: 0.746
******** [step = 400] loss: 1.129, acc: 0.745
******** [step = 450] loss: 1.132, acc: 0.744
******** [step = 500] loss: 1.136, acc: 0.744
******** [step = 550] loss: 1.141, acc: 0.743
******** [step = 600] loss: 1.147, acc: 0.743
******** [step = 650] loss: 1.150, acc: 0.742
******** [step = 700] loss: 1.154, acc: 0.742
******** [step = 750] loss: 1.159, acc: 0.741
******** [step = 800] loss: 1.161, acc: 0.741
******** [step = 850] loss: 1.167, acc: 0.740
EPOCH = 44 loss: 1.167, acc: 0.740, val_loss: 1.550, val_acc: 0.715

================================================================================2025-08_10 18:38:18
******** [step = 50] loss: 1.098, acc: 0.748
******** [step = 100] loss: 1.085, acc: 0.752
******** [step = 150] loss: 1.093, acc: 0.750
******** [step = 200] loss: 1.097, acc: 0.749
******** [step = 250] loss: 1.100, acc: 0.749
******** [step = 300] loss: 1.104, acc: 0.748
******** [step = 350] loss: 1.108, acc: 0.748
******** [step = 400] loss: 1.113, acc: 0.747
******** [step = 450] loss: 1.118, acc: 0.747
******** [step = 500] loss: 1.125, acc: 0.746
******** [step = 550] loss: 1.132, acc: 0.745
******** [step = 600] loss: 1.136, acc: 0.744
******** [step = 650] loss: 1.140, acc: 0.744
******** [step = 700] loss: 1.143, acc: 0.743
******** [step = 750] loss: 1.147, acc: 0.743
******** [step = 800] loss: 1.151, acc: 0.743
******** [step = 850] loss: 1.158, acc: 0.742
EPOCH = 45 loss: 1.158, acc: 0.742, val_loss: 1.547, val_acc: 0.716

================================================================================2025-08_10 18:39:41
******** [step = 50] loss: 1.080, acc: 0.751
******** [step = 100] loss: 1.078, acc: 0.752
******** [step = 150] loss: 1.086, acc: 0.751
******** [step = 200] loss: 1.091, acc: 0.750
******** [step = 250] loss: 1.094, acc: 0.750
******** [step = 300] loss: 1.101, acc: 0.749
******** [step = 350] loss: 1.106, acc: 0.748
******** [step = 400] loss: 1.113, acc: 0.747
******** [step = 450] loss: 1.119, acc: 0.747
******** [step = 500] loss: 1.124, acc: 0.746
******** [step = 550] loss: 1.127, acc: 0.746
******** [step = 600] loss: 1.130, acc: 0.746
******** [step = 650] loss: 1.135, acc: 0.745
******** [step = 700] loss: 1.138, acc: 0.745
******** [step = 750] loss: 1.142, acc: 0.744
******** [step = 800] loss: 1.148, acc: 0.743
******** [step = 850] loss: 1.152, acc: 0.743
EPOCH = 46 loss: 1.152, acc: 0.743, val_loss: 1.541, val_acc: 0.717

================================================================================2025-08_10 18:41:06
******** [step = 50] loss: 1.068, acc: 0.757
******** [step = 100] loss: 1.080, acc: 0.753
******** [step = 150] loss: 1.089, acc: 0.751
******** [step = 200] loss: 1.091, acc: 0.751
******** [step = 250] loss: 1.093, acc: 0.751
******** [step = 300] loss: 1.097, acc: 0.750
******** [step = 350] loss: 1.101, acc: 0.750
******** [step = 400] loss: 1.108, acc: 0.749
******** [step = 450] loss: 1.112, acc: 0.748
******** [step = 500] loss: 1.119, acc: 0.747
******** [step = 550] loss: 1.123, acc: 0.747
******** [step = 600] loss: 1.127, acc: 0.746
******** [step = 650] loss: 1.131, acc: 0.746
******** [step = 700] loss: 1.134, acc: 0.746
******** [step = 750] loss: 1.139, acc: 0.745
******** [step = 800] loss: 1.142, acc: 0.745
******** [step = 850] loss: 1.144, acc: 0.745
EPOCH = 47 loss: 1.144, acc: 0.745, val_loss: 1.540, val_acc: 0.718

================================================================================2025-08_10 18:42:35
******** [step = 50] loss: 1.061, acc: 0.758
******** [step = 100] loss: 1.066, acc: 0.756
******** [step = 150] loss: 1.073, acc: 0.756
******** [step = 200] loss: 1.077, acc: 0.755
******** [step = 250] loss: 1.085, acc: 0.753
******** [step = 300] loss: 1.090, acc: 0.752
******** [step = 350] loss: 1.098, acc: 0.751
******** [step = 400] loss: 1.104, acc: 0.750
******** [step = 450] loss: 1.109, acc: 0.749
******** [step = 500] loss: 1.113, acc: 0.749
******** [step = 550] loss: 1.116, acc: 0.749
******** [step = 600] loss: 1.120, acc: 0.748
******** [step = 650] loss: 1.123, acc: 0.748
******** [step = 700] loss: 1.127, acc: 0.747
******** [step = 750] loss: 1.130, acc: 0.747
******** [step = 800] loss: 1.134, acc: 0.746
******** [step = 850] loss: 1.137, acc: 0.746
EPOCH = 48 loss: 1.137, acc: 0.746, val_loss: 1.538, val_acc: 0.718

================================================================================2025-08_10 18:43:59
******** [step = 50] loss: 1.064, acc: 0.758
******** [step = 100] loss: 1.059, acc: 0.758
******** [step = 150] loss: 1.064, acc: 0.757
******** [step = 200] loss: 1.070, acc: 0.756
******** [step = 250] loss: 1.074, acc: 0.755
******** [step = 300] loss: 1.079, acc: 0.754
******** [step = 350] loss: 1.085, acc: 0.753
******** [step = 400] loss: 1.089, acc: 0.752
******** [step = 450] loss: 1.094, acc: 0.752
******** [step = 500] loss: 1.099, acc: 0.751
******** [step = 550] loss: 1.106, acc: 0.750
******** [step = 600] loss: 1.112, acc: 0.749
******** [step = 650] loss: 1.118, acc: 0.749
******** [step = 700] loss: 1.123, acc: 0.748
******** [step = 750] loss: 1.125, acc: 0.748
******** [step = 800] loss: 1.128, acc: 0.747
******** [step = 850] loss: 1.131, acc: 0.747
EPOCH = 49 loss: 1.131, acc: 0.747, val_loss: 1.527, val_acc: 0.720

================================================================================2025-08_10 18:45:24
******** [step = 50] loss: 1.050, acc: 0.758
******** [step = 100] loss: 1.054, acc: 0.758
******** [step = 150] loss: 1.063, acc: 0.757
******** [step = 200] loss: 1.067, acc: 0.756
******** [step = 250] loss: 1.064, acc: 0.757
******** [step = 300] loss: 1.072, acc: 0.755
******** [step = 350] loss: 1.076, acc: 0.755
******** [step = 400] loss: 1.083, acc: 0.754
******** [step = 450] loss: 1.088, acc: 0.753
******** [step = 500] loss: 1.092, acc: 0.752
******** [step = 550] loss: 1.097, acc: 0.751
******** [step = 600] loss: 1.101, acc: 0.751
******** [step = 650] loss: 1.107, acc: 0.750
******** [step = 700] loss: 1.112, acc: 0.750
******** [step = 750] loss: 1.116, acc: 0.749
******** [step = 800] loss: 1.119, acc: 0.749
******** [step = 850] loss: 1.122, acc: 0.749
EPOCH = 50 loss: 1.122, acc: 0.749, val_loss: 1.532, val_acc: 0.719

================================================================================2025-08_10 18:46:46
******** [step = 50] loss: 1.047, acc: 0.758
******** [step = 100] loss: 1.054, acc: 0.757
******** [step = 150] loss: 1.053, acc: 0.757
******** [step = 200] loss: 1.061, acc: 0.756
******** [step = 250] loss: 1.066, acc: 0.756
******** [step = 300] loss: 1.074, acc: 0.754
******** [step = 350] loss: 1.078, acc: 0.754
******** [step = 400] loss: 1.083, acc: 0.754
******** [step = 450] loss: 1.086, acc: 0.753
******** [step = 500] loss: 1.090, acc: 0.753
******** [step = 550] loss: 1.096, acc: 0.752
******** [step = 600] loss: 1.100, acc: 0.752
******** [step = 650] loss: 1.104, acc: 0.751
******** [step = 700] loss: 1.109, acc: 0.751
******** [step = 750] loss: 1.112, acc: 0.751
******** [step = 800] loss: 1.115, acc: 0.750
******** [step = 850] loss: 1.119, acc: 0.750
EPOCH = 51 loss: 1.119, acc: 0.750, val_loss: 1.524, val_acc: 0.720

================================================================================2025-08_10 18:48:11
******** [step = 50] loss: 1.039, acc: 0.761
******** [step = 100] loss: 1.052, acc: 0.757
******** [step = 150] loss: 1.053, acc: 0.758
******** [step = 200] loss: 1.057, acc: 0.758
******** [step = 250] loss: 1.063, acc: 0.757
******** [step = 300] loss: 1.067, acc: 0.756
******** [step = 350] loss: 1.070, acc: 0.756
******** [step = 400] loss: 1.076, acc: 0.755
******** [step = 450] loss: 1.079, acc: 0.754
******** [step = 500] loss: 1.083, acc: 0.754
******** [step = 550] loss: 1.087, acc: 0.753
******** [step = 600] loss: 1.092, acc: 0.753
******** [step = 650] loss: 1.096, acc: 0.752
******** [step = 700] loss: 1.099, acc: 0.752
******** [step = 750] loss: 1.104, acc: 0.751
******** [step = 800] loss: 1.108, acc: 0.751
******** [step = 850] loss: 1.112, acc: 0.751
EPOCH = 52 loss: 1.112, acc: 0.751, val_loss: 1.520, val_acc: 0.722

================================================================================2025-08_10 18:49:30
******** [step = 50] loss: 1.023, acc: 0.761
******** [step = 100] loss: 1.038, acc: 0.761
******** [step = 150] loss: 1.044, acc: 0.760
******** [step = 200] loss: 1.051, acc: 0.759
******** [step = 250] loss: 1.056, acc: 0.758
******** [step = 300] loss: 1.062, acc: 0.758
******** [step = 350] loss: 1.064, acc: 0.757
******** [step = 400] loss: 1.068, acc: 0.757
******** [step = 450] loss: 1.072, acc: 0.756
******** [step = 500] loss: 1.075, acc: 0.756
******** [step = 550] loss: 1.078, acc: 0.756
******** [step = 600] loss: 1.082, acc: 0.755
******** [step = 650] loss: 1.087, acc: 0.755
******** [step = 700] loss: 1.090, acc: 0.754
******** [step = 750] loss: 1.096, acc: 0.753
******** [step = 800] loss: 1.100, acc: 0.753
******** [step = 850] loss: 1.103, acc: 0.753
EPOCH = 53 loss: 1.103, acc: 0.753, val_loss: 1.519, val_acc: 0.723

================================================================================2025-08_10 18:50:52
******** [step = 50] loss: 1.017, acc: 0.764
******** [step = 100] loss: 1.033, acc: 0.762
******** [step = 150] loss: 1.036, acc: 0.762
******** [step = 200] loss: 1.045, acc: 0.760
******** [step = 250] loss: 1.049, acc: 0.759
******** [step = 300] loss: 1.055, acc: 0.758
******** [step = 350] loss: 1.059, acc: 0.758
******** [step = 400] loss: 1.065, acc: 0.757
******** [step = 450] loss: 1.070, acc: 0.756
******** [step = 500] loss: 1.073, acc: 0.756
******** [step = 550] loss: 1.075, acc: 0.756
******** [step = 600] loss: 1.079, acc: 0.755
******** [step = 650] loss: 1.084, acc: 0.755
******** [step = 700] loss: 1.088, acc: 0.754
******** [step = 750] loss: 1.093, acc: 0.754
******** [step = 800] loss: 1.096, acc: 0.754
******** [step = 850] loss: 1.099, acc: 0.754
EPOCH = 54 loss: 1.099, acc: 0.754, val_loss: 1.522, val_acc: 0.722

================================================================================2025-08_10 18:52:15
******** [step = 50] loss: 1.027, acc: 0.765
******** [step = 100] loss: 1.032, acc: 0.763
******** [step = 150] loss: 1.034, acc: 0.762
******** [step = 200] loss: 1.038, acc: 0.762
******** [step = 250] loss: 1.042, acc: 0.761
******** [step = 300] loss: 1.050, acc: 0.760
******** [step = 350] loss: 1.054, acc: 0.759
******** [step = 400] loss: 1.060, acc: 0.758
******** [step = 450] loss: 1.064, acc: 0.758
******** [step = 500] loss: 1.067, acc: 0.757
******** [step = 550] loss: 1.072, acc: 0.757
******** [step = 600] loss: 1.076, acc: 0.756
******** [step = 650] loss: 1.081, acc: 0.755
******** [step = 700] loss: 1.085, acc: 0.755
******** [step = 750] loss: 1.088, acc: 0.754
******** [step = 800] loss: 1.092, acc: 0.754
******** [step = 850] loss: 1.095, acc: 0.753
EPOCH = 55 loss: 1.095, acc: 0.753, val_loss: 1.516, val_acc: 0.724

================================================================================2025-08_10 18:53:42
******** [step = 50] loss: 1.005, acc: 0.769
******** [step = 100] loss: 1.022, acc: 0.765
******** [step = 150] loss: 1.026, acc: 0.764
******** [step = 200] loss: 1.033, acc: 0.762
******** [step = 250] loss: 1.032, acc: 0.763
******** [step = 300] loss: 1.039, acc: 0.762
******** [step = 350] loss: 1.044, acc: 0.761
******** [step = 400] loss: 1.051, acc: 0.760
******** [step = 450] loss: 1.056, acc: 0.759
******** [step = 500] loss: 1.059, acc: 0.759
******** [step = 550] loss: 1.064, acc: 0.758
******** [step = 600] loss: 1.069, acc: 0.757
******** [step = 650] loss: 1.073, acc: 0.757
******** [step = 700] loss: 1.075, acc: 0.757
******** [step = 750] loss: 1.080, acc: 0.756
******** [step = 800] loss: 1.085, acc: 0.756
******** [step = 850] loss: 1.094, acc: 0.755
EPOCH = 56 loss: 1.094, acc: 0.755, val_loss: 1.514, val_acc: 0.724

================================================================================2025-08_10 18:55:10
******** [step = 50] loss: 1.003, acc: 0.766
******** [step = 100] loss: 1.009, acc: 0.766
******** [step = 150] loss: 1.014, acc: 0.766
******** [step = 200] loss: 1.020, acc: 0.765
******** [step = 250] loss: 1.027, acc: 0.764
******** [step = 300] loss: 1.031, acc: 0.763
******** [step = 350] loss: 1.035, acc: 0.762
******** [step = 400] loss: 1.042, acc: 0.761
******** [step = 450] loss: 1.048, acc: 0.760
******** [step = 500] loss: 1.054, acc: 0.759
******** [step = 550] loss: 1.059, acc: 0.759
******** [step = 600] loss: 1.063, acc: 0.758
******** [step = 650] loss: 1.067, acc: 0.758
******** [step = 700] loss: 1.073, acc: 0.757
******** [step = 750] loss: 1.077, acc: 0.757
******** [step = 800] loss: 1.081, acc: 0.756
******** [step = 850] loss: 1.084, acc: 0.756
EPOCH = 57 loss: 1.084, acc: 0.756, val_loss: 1.516, val_acc: 0.722

================================================================================2025-08_10 18:56:38
******** [step = 50] loss: 1.000, acc: 0.770
******** [step = 100] loss: 1.006, acc: 0.768
******** [step = 150] loss: 1.014, acc: 0.766
******** [step = 200] loss: 1.019, acc: 0.765
******** [step = 250] loss: 1.026, acc: 0.764
******** [step = 300] loss: 1.030, acc: 0.763
******** [step = 350] loss: 1.034, acc: 0.763
******** [step = 400] loss: 1.040, acc: 0.762
******** [step = 450] loss: 1.042, acc: 0.761
******** [step = 500] loss: 1.047, acc: 0.761
******** [step = 550] loss: 1.052, acc: 0.760
******** [step = 600] loss: 1.058, acc: 0.759
******** [step = 650] loss: 1.062, acc: 0.759
******** [step = 700] loss: 1.067, acc: 0.758
******** [step = 750] loss: 1.071, acc: 0.758
******** [step = 800] loss: 1.074, acc: 0.757
******** [step = 850] loss: 1.078, acc: 0.757
EPOCH = 58 loss: 1.078, acc: 0.757, val_loss: 1.512, val_acc: 0.725

================================================================================2025-08_10 18:57:59
******** [step = 50] loss: 1.015, acc: 0.765
******** [step = 100] loss: 1.003, acc: 0.767
******** [step = 150] loss: 1.014, acc: 0.765
******** [step = 200] loss: 1.018, acc: 0.765
******** [step = 250] loss: 1.021, acc: 0.765
******** [step = 300] loss: 1.028, acc: 0.764
******** [step = 350] loss: 1.036, acc: 0.762
******** [step = 400] loss: 1.039, acc: 0.762
******** [step = 450] loss: 1.043, acc: 0.762
******** [step = 500] loss: 1.046, acc: 0.761
******** [step = 550] loss: 1.051, acc: 0.761
******** [step = 600] loss: 1.057, acc: 0.760
******** [step = 650] loss: 1.060, acc: 0.760
******** [step = 700] loss: 1.065, acc: 0.759
******** [step = 750] loss: 1.068, acc: 0.759
******** [step = 800] loss: 1.070, acc: 0.759
******** [step = 850] loss: 1.073, acc: 0.758
EPOCH = 59 loss: 1.073, acc: 0.758, val_loss: 1.514, val_acc: 0.725

================================================================================2025-08_10 18:59:19
******** [step = 50] loss: 1.001, acc: 0.768
******** [step = 100] loss: 0.996, acc: 0.769
******** [step = 150] loss: 0.998, acc: 0.768
******** [step = 200] loss: 1.010, acc: 0.766
******** [step = 250] loss: 1.015, acc: 0.765
******** [step = 300] loss: 1.021, acc: 0.764
******** [step = 350] loss: 1.026, acc: 0.764
******** [step = 400] loss: 1.033, acc: 0.762
******** [step = 450] loss: 1.035, acc: 0.762
******** [step = 500] loss: 1.039, acc: 0.762
******** [step = 550] loss: 1.042, acc: 0.762
******** [step = 600] loss: 1.046, acc: 0.761
******** [step = 650] loss: 1.051, acc: 0.761
******** [step = 700] loss: 1.058, acc: 0.760
******** [step = 750] loss: 1.062, acc: 0.759
******** [step = 800] loss: 1.065, acc: 0.759
******** [step = 850] loss: 1.067, acc: 0.759
EPOCH = 60 loss: 1.067, acc: 0.759, val_loss: 1.511, val_acc: 0.724

================================================================================2025-08_10 19:00:39
******** [step = 50] loss: 1.006, acc: 0.768
******** [step = 100] loss: 0.998, acc: 0.769
******** [step = 150] loss: 1.001, acc: 0.769
******** [step = 200] loss: 1.001, acc: 0.768
******** [step = 250] loss: 1.007, acc: 0.767
******** [step = 300] loss: 1.013, acc: 0.766
******** [step = 350] loss: 1.017, acc: 0.765
******** [step = 400] loss: 1.023, acc: 0.765
******** [step = 450] loss: 1.028, acc: 0.764
******** [step = 500] loss: 1.032, acc: 0.764
******** [step = 550] loss: 1.037, acc: 0.763
******** [step = 600] loss: 1.041, acc: 0.763
******** [step = 650] loss: 1.045, acc: 0.762
******** [step = 700] loss: 1.051, acc: 0.762
******** [step = 750] loss: 1.054, acc: 0.761
******** [step = 800] loss: 1.058, acc: 0.761
******** [step = 850] loss: 1.063, acc: 0.760
EPOCH = 61 loss: 1.063, acc: 0.760, val_loss: 1.503, val_acc: 0.727

================================================================================2025-08_10 19:01:59
******** [step = 50] loss: 0.985, acc: 0.770
******** [step = 100] loss: 0.987, acc: 0.769
******** [step = 150] loss: 0.989, acc: 0.769
******** [step = 200] loss: 0.994, acc: 0.769
******** [step = 250] loss: 1.002, acc: 0.767
******** [step = 300] loss: 1.010, acc: 0.766
******** [step = 350] loss: 1.013, acc: 0.766
******** [step = 400] loss: 1.019, acc: 0.765
******** [step = 450] loss: 1.023, acc: 0.764
******** [step = 500] loss: 1.028, acc: 0.764
******** [step = 550] loss: 1.033, acc: 0.763
******** [step = 600] loss: 1.038, acc: 0.763
******** [step = 650] loss: 1.042, acc: 0.763
******** [step = 700] loss: 1.045, acc: 0.762
******** [step = 750] loss: 1.050, acc: 0.762
******** [step = 800] loss: 1.053, acc: 0.761
******** [step = 850] loss: 1.057, acc: 0.761
EPOCH = 62 loss: 1.057, acc: 0.761, val_loss: 1.508, val_acc: 0.725

================================================================================2025-08_10 19:03:20
******** [step = 50] loss: 0.981, acc: 0.771
******** [step = 100] loss: 0.986, acc: 0.772
******** [step = 150] loss: 0.987, acc: 0.771
******** [step = 200] loss: 0.991, acc: 0.771
******** [step = 250] loss: 1.000, acc: 0.769
******** [step = 300] loss: 1.004, acc: 0.769
******** [step = 350] loss: 1.007, acc: 0.768
******** [step = 400] loss: 1.014, acc: 0.768
******** [step = 450] loss: 1.019, acc: 0.767
******** [step = 500] loss: 1.023, acc: 0.767
******** [step = 550] loss: 1.029, acc: 0.766
******** [step = 600] loss: 1.033, acc: 0.765
******** [step = 650] loss: 1.037, acc: 0.765
******** [step = 700] loss: 1.042, acc: 0.764
******** [step = 750] loss: 1.046, acc: 0.763
******** [step = 800] loss: 1.050, acc: 0.763
******** [step = 850] loss: 1.056, acc: 0.762
EPOCH = 63 loss: 1.056, acc: 0.762, val_loss: 1.504, val_acc: 0.727

================================================================================2025-08_10 19:04:40
******** [step = 50] loss: 0.977, acc: 0.772
******** [step = 100] loss: 0.984, acc: 0.771
******** [step = 150] loss: 0.990, acc: 0.770
******** [step = 200] loss: 1.001, acc: 0.769
******** [step = 250] loss: 1.007, acc: 0.768
******** [step = 300] loss: 1.009, acc: 0.767
******** [step = 350] loss: 1.016, acc: 0.766
******** [step = 400] loss: 1.017, acc: 0.766
******** [step = 450] loss: 1.018, acc: 0.766
******** [step = 500] loss: 1.021, acc: 0.766
******** [step = 550] loss: 1.025, acc: 0.765
******** [step = 600] loss: 1.028, acc: 0.765
******** [step = 650] loss: 1.034, acc: 0.764
******** [step = 700] loss: 1.038, acc: 0.764
******** [step = 750] loss: 1.041, acc: 0.764
******** [step = 800] loss: 1.045, acc: 0.763
******** [step = 850] loss: 1.048, acc: 0.763
EPOCH = 64 loss: 1.048, acc: 0.763, val_loss: 1.498, val_acc: 0.728

================================================================================2025-08_10 19:06:00
******** [step = 50] loss: 0.959, acc: 0.775
******** [step = 100] loss: 0.960, acc: 0.775
******** [step = 150] loss: 0.962, acc: 0.775
******** [step = 200] loss: 0.971, acc: 0.773
******** [step = 250] loss: 0.981, acc: 0.772
******** [step = 300] loss: 0.989, acc: 0.770
******** [step = 350] loss: 0.995, acc: 0.769
******** [step = 400] loss: 1.000, acc: 0.769
******** [step = 450] loss: 1.007, acc: 0.768
******** [step = 500] loss: 1.011, acc: 0.767
******** [step = 550] loss: 1.017, acc: 0.766
******** [step = 600] loss: 1.022, acc: 0.766
******** [step = 650] loss: 1.027, acc: 0.765
******** [step = 700] loss: 1.031, acc: 0.765
******** [step = 750] loss: 1.036, acc: 0.764
******** [step = 800] loss: 1.040, acc: 0.764
******** [step = 850] loss: 1.045, acc: 0.763
EPOCH = 65 loss: 1.045, acc: 0.763, val_loss: 1.501, val_acc: 0.728

================================================================================2025-08_10 19:07:20
******** [step = 50] loss: 0.958, acc: 0.775
******** [step = 100] loss: 0.958, acc: 0.775
******** [step = 150] loss: 0.969, acc: 0.773
******** [step = 200] loss: 0.976, acc: 0.772
******** [step = 250] loss: 0.982, acc: 0.772
******** [step = 300] loss: 0.989, acc: 0.770
******** [step = 350] loss: 0.995, acc: 0.769
******** [step = 400] loss: 1.001, acc: 0.769
******** [step = 450] loss: 1.004, acc: 0.768
******** [step = 500] loss: 1.012, acc: 0.767
******** [step = 550] loss: 1.018, acc: 0.767
******** [step = 600] loss: 1.022, acc: 0.766
******** [step = 650] loss: 1.027, acc: 0.766
******** [step = 700] loss: 1.030, acc: 0.766
******** [step = 750] loss: 1.034, acc: 0.765
******** [step = 800] loss: 1.037, acc: 0.765
******** [step = 850] loss: 1.040, acc: 0.765
EPOCH = 66 loss: 1.040, acc: 0.765, val_loss: 1.495, val_acc: 0.730

================================================================================2025-08_10 19:08:40
******** [step = 50] loss: 0.958, acc: 0.777
******** [step = 100] loss: 0.957, acc: 0.776
******** [step = 150] loss: 0.970, acc: 0.774
******** [step = 200] loss: 0.979, acc: 0.772
******** [step = 250] loss: 0.982, acc: 0.772
******** [step = 300] loss: 0.989, acc: 0.771
******** [step = 350] loss: 0.995, acc: 0.770
******** [step = 400] loss: 1.001, acc: 0.769
******** [step = 450] loss: 1.005, acc: 0.768
******** [step = 500] loss: 1.008, acc: 0.768
******** [step = 550] loss: 1.013, acc: 0.768
******** [step = 600] loss: 1.016, acc: 0.767
******** [step = 650] loss: 1.018, acc: 0.767
******** [step = 700] loss: 1.023, acc: 0.767
******** [step = 750] loss: 1.028, acc: 0.766
******** [step = 800] loss: 1.032, acc: 0.766
******** [step = 850] loss: 1.034, acc: 0.765
EPOCH = 67 loss: 1.034, acc: 0.765, val_loss: 1.494, val_acc: 0.729

================================================================================2025-08_10 19:10:01
******** [step = 50] loss: 0.965, acc: 0.775
******** [step = 100] loss: 0.960, acc: 0.776
******** [step = 150] loss: 0.964, acc: 0.775
******** [step = 200] loss: 0.966, acc: 0.775
******** [step = 250] loss: 0.975, acc: 0.773
******** [step = 300] loss: 0.982, acc: 0.772
******** [step = 350] loss: 0.987, acc: 0.771
******** [step = 400] loss: 0.992, acc: 0.771
******** [step = 450] loss: 0.995, acc: 0.770
******** [step = 500] loss: 1.000, acc: 0.770
******** [step = 550] loss: 1.006, acc: 0.769
******** [step = 600] loss: 1.009, acc: 0.769
******** [step = 650] loss: 1.013, acc: 0.768
******** [step = 700] loss: 1.019, acc: 0.768
******** [step = 750] loss: 1.023, acc: 0.767
******** [step = 800] loss: 1.027, acc: 0.767
******** [step = 850] loss: 1.030, acc: 0.767
EPOCH = 68 loss: 1.030, acc: 0.767, val_loss: 1.493, val_acc: 0.731

================================================================================2025-08_10 19:11:21
******** [step = 50] loss: 0.935, acc: 0.779
******** [step = 100] loss: 0.952, acc: 0.777
******** [step = 150] loss: 0.960, acc: 0.776
******** [step = 200] loss: 0.964, acc: 0.775
******** [step = 250] loss: 0.970, acc: 0.774
******** [step = 300] loss: 0.976, acc: 0.774
******** [step = 350] loss: 0.982, acc: 0.773
******** [step = 400] loss: 0.988, acc: 0.772
******** [step = 450] loss: 0.994, acc: 0.771
******** [step = 500] loss: 0.997, acc: 0.771
******** [step = 550] loss: 1.002, acc: 0.770
******** [step = 600] loss: 1.006, acc: 0.769
******** [step = 650] loss: 1.010, acc: 0.769
******** [step = 700] loss: 1.014, acc: 0.768
******** [step = 750] loss: 1.018, acc: 0.768
******** [step = 800] loss: 1.023, acc: 0.767
******** [step = 850] loss: 1.028, acc: 0.767
EPOCH = 69 loss: 1.028, acc: 0.767, val_loss: 1.493, val_acc: 0.731

================================================================================2025-08_10 19:12:41
******** [step = 50] loss: 0.949, acc: 0.776
******** [step = 100] loss: 0.951, acc: 0.777
******** [step = 150] loss: 0.950, acc: 0.778
******** [step = 200] loss: 0.958, acc: 0.776
******** [step = 250] loss: 0.971, acc: 0.774
******** [step = 300] loss: 0.976, acc: 0.774
******** [step = 350] loss: 0.982, acc: 0.773
******** [step = 400] loss: 0.985, acc: 0.773
******** [step = 450] loss: 0.990, acc: 0.772
******** [step = 500] loss: 0.994, acc: 0.771
******** [step = 550] loss: 0.999, acc: 0.770
******** [step = 600] loss: 1.003, acc: 0.770
******** [step = 650] loss: 1.009, acc: 0.769
******** [step = 700] loss: 1.012, acc: 0.769
******** [step = 750] loss: 1.015, acc: 0.769
******** [step = 800] loss: 1.020, acc: 0.768
******** [step = 850] loss: 1.022, acc: 0.768
EPOCH = 70 loss: 1.022, acc: 0.768, val_loss: 1.492, val_acc: 0.732

================================================================================2025-08_10 19:14:01
******** [step = 50] loss: 0.947, acc: 0.779
******** [step = 100] loss: 0.953, acc: 0.779
******** [step = 150] loss: 0.956, acc: 0.777
******** [step = 200] loss: 0.962, acc: 0.776
******** [step = 250] loss: 0.965, acc: 0.776
******** [step = 300] loss: 0.972, acc: 0.775
******** [step = 350] loss: 0.976, acc: 0.774
******** [step = 400] loss: 0.978, acc: 0.774
******** [step = 450] loss: 0.983, acc: 0.773
******** [step = 500] loss: 0.988, acc: 0.773
******** [step = 550] loss: 0.994, acc: 0.772
******** [step = 600] loss: 0.998, acc: 0.771
******** [step = 650] loss: 1.004, acc: 0.770
******** [step = 700] loss: 1.009, acc: 0.770
******** [step = 750] loss: 1.013, acc: 0.769
******** [step = 800] loss: 1.016, acc: 0.769
******** [step = 850] loss: 1.017, acc: 0.769
EPOCH = 71 loss: 1.017, acc: 0.769, val_loss: 1.490, val_acc: 0.732

================================================================================2025-08_10 19:15:23
******** [step = 50] loss: 0.930, acc: 0.783
******** [step = 100] loss: 0.939, acc: 0.781
******** [step = 150] loss: 0.945, acc: 0.780
******** [step = 200] loss: 0.949, acc: 0.779
******** [step = 250] loss: 0.957, acc: 0.778
******** [step = 300] loss: 0.964, acc: 0.777
******** [step = 350] loss: 0.969, acc: 0.776
******** [step = 400] loss: 0.974, acc: 0.775
******** [step = 450] loss: 0.978, acc: 0.774
******** [step = 500] loss: 0.982, acc: 0.774
******** [step = 550] loss: 0.988, acc: 0.773
******** [step = 600] loss: 0.993, acc: 0.772
******** [step = 650] loss: 0.996, acc: 0.772
******** [step = 700] loss: 1.000, acc: 0.771
******** [step = 750] loss: 1.004, acc: 0.771
******** [step = 800] loss: 1.009, acc: 0.770
******** [step = 850] loss: 1.015, acc: 0.769
EPOCH = 72 loss: 1.015, acc: 0.769, val_loss: 1.487, val_acc: 0.733

================================================================================2025-08_10 19:16:44
******** [step = 50] loss: 0.940, acc: 0.780
******** [step = 100] loss: 0.938, acc: 0.778
******** [step = 150] loss: 0.948, acc: 0.777
******** [step = 200] loss: 0.954, acc: 0.777
******** [step = 250] loss: 0.959, acc: 0.776
******** [step = 300] loss: 0.965, acc: 0.775
******** [step = 350] loss: 0.968, acc: 0.775
******** [step = 400] loss: 0.973, acc: 0.775
******** [step = 450] loss: 0.976, acc: 0.774
******** [step = 500] loss: 0.982, acc: 0.773
******** [step = 550] loss: 0.987, acc: 0.773
******** [step = 600] loss: 0.990, acc: 0.772
******** [step = 650] loss: 0.995, acc: 0.772
******** [step = 700] loss: 0.999, acc: 0.771
******** [step = 750] loss: 1.004, acc: 0.771
******** [step = 800] loss: 1.006, acc: 0.771
******** [step = 850] loss: 1.011, acc: 0.770
EPOCH = 73 loss: 1.011, acc: 0.770, val_loss: 1.488, val_acc: 0.733

================================================================================2025-08_10 19:18:06
******** [step = 50] loss: 0.939, acc: 0.778
******** [step = 100] loss: 0.936, acc: 0.780
******** [step = 150] loss: 0.946, acc: 0.778
******** [step = 200] loss: 0.947, acc: 0.779
******** [step = 250] loss: 0.952, acc: 0.778
******** [step = 300] loss: 0.960, acc: 0.776
******** [step = 350] loss: 0.967, acc: 0.775
******** [step = 400] loss: 0.973, acc: 0.775
******** [step = 450] loss: 0.978, acc: 0.774
******** [step = 500] loss: 0.983, acc: 0.773
******** [step = 550] loss: 0.987, acc: 0.773
******** [step = 600] loss: 0.991, acc: 0.772
******** [step = 650] loss: 0.993, acc: 0.772
******** [step = 700] loss: 0.998, acc: 0.772
******** [step = 750] loss: 1.001, acc: 0.771
******** [step = 800] loss: 1.005, acc: 0.771
******** [step = 850] loss: 1.007, acc: 0.771
EPOCH = 74 loss: 1.007, acc: 0.771, val_loss: 1.483, val_acc: 0.733

================================================================================2025-08_10 19:19:26
******** [step = 50] loss: 0.913, acc: 0.784
******** [step = 100] loss: 0.928, acc: 0.782
******** [step = 150] loss: 0.932, acc: 0.781
******** [step = 200] loss: 0.939, acc: 0.780
******** [step = 250] loss: 0.946, acc: 0.779
******** [step = 300] loss: 0.950, acc: 0.778
******** [step = 350] loss: 0.958, acc: 0.777
******** [step = 400] loss: 0.966, acc: 0.776
******** [step = 450] loss: 0.972, acc: 0.775
******** [step = 500] loss: 0.976, acc: 0.775
******** [step = 550] loss: 0.981, acc: 0.774
******** [step = 600] loss: 0.986, acc: 0.773
******** [step = 650] loss: 0.990, acc: 0.773
******** [step = 700] loss: 0.995, acc: 0.772
******** [step = 750] loss: 0.997, acc: 0.772
******** [step = 800] loss: 1.001, acc: 0.772
******** [step = 850] loss: 1.007, acc: 0.771
EPOCH = 75 loss: 1.007, acc: 0.771, val_loss: 1.483, val_acc: 0.733

================================================================================2025-08_10 19:20:47
******** [step = 50] loss: 0.938, acc: 0.781
******** [step = 100] loss: 0.939, acc: 0.780
******** [step = 150] loss: 0.937, acc: 0.780
******** [step = 200] loss: 0.943, acc: 0.780
******** [step = 250] loss: 0.951, acc: 0.778
******** [step = 300] loss: 0.954, acc: 0.778
******** [step = 350] loss: 0.959, acc: 0.778
******** [step = 400] loss: 0.962, acc: 0.777
******** [step = 450] loss: 0.966, acc: 0.776
******** [step = 500] loss: 0.971, acc: 0.776
******** [step = 550] loss: 0.975, acc: 0.775
******** [step = 600] loss: 0.979, acc: 0.775
******** [step = 650] loss: 0.983, acc: 0.774
******** [step = 700] loss: 0.988, acc: 0.774
******** [step = 750] loss: 0.993, acc: 0.773
******** [step = 800] loss: 0.997, acc: 0.773
******** [step = 850] loss: 1.003, acc: 0.772
EPOCH = 76 loss: 1.003, acc: 0.772, val_loss: 1.483, val_acc: 0.734

================================================================================2025-08_10 19:22:07
******** [step = 50] loss: 0.926, acc: 0.785
******** [step = 100] loss: 0.927, acc: 0.783
******** [step = 150] loss: 0.933, acc: 0.782
******** [step = 200] loss: 0.935, acc: 0.782
******** [step = 250] loss: 0.941, acc: 0.781
******** [step = 300] loss: 0.948, acc: 0.780
******** [step = 350] loss: 0.954, acc: 0.779
******** [step = 400] loss: 0.959, acc: 0.778
******** [step = 450] loss: 0.964, acc: 0.777
******** [step = 500] loss: 0.968, acc: 0.777
******** [step = 550] loss: 0.972, acc: 0.776
******** [step = 600] loss: 0.977, acc: 0.775
******** [step = 650] loss: 0.980, acc: 0.775
******** [step = 700] loss: 0.985, acc: 0.774
******** [step = 750] loss: 0.989, acc: 0.774
******** [step = 800] loss: 0.993, acc: 0.773
******** [step = 850] loss: 0.996, acc: 0.773
EPOCH = 77 loss: 0.996, acc: 0.773, val_loss: 1.483, val_acc: 0.733

================================================================================2025-08_10 19:23:27
******** [step = 50] loss: 0.923, acc: 0.783
******** [step = 100] loss: 0.925, acc: 0.782
******** [step = 150] loss: 0.931, acc: 0.781
******** [step = 200] loss: 0.933, acc: 0.781
******** [step = 250] loss: 0.941, acc: 0.780
******** [step = 300] loss: 0.944, acc: 0.779
******** [step = 350] loss: 0.951, acc: 0.778
******** [step = 400] loss: 0.955, acc: 0.778
******** [step = 450] loss: 0.961, acc: 0.777
******** [step = 500] loss: 0.966, acc: 0.777
******** [step = 550] loss: 0.970, acc: 0.776
******** [step = 600] loss: 0.975, acc: 0.776
******** [step = 650] loss: 0.979, acc: 0.775
******** [step = 700] loss: 0.983, acc: 0.775
******** [step = 750] loss: 0.987, acc: 0.774
******** [step = 800] loss: 0.992, acc: 0.774
******** [step = 850] loss: 0.997, acc: 0.773
EPOCH = 78 loss: 0.997, acc: 0.773, val_loss: 1.482, val_acc: 0.733

================================================================================2025-08_10 19:24:53
******** [step = 50] loss: 0.925, acc: 0.782
******** [step = 100] loss: 0.919, acc: 0.784
******** [step = 150] loss: 0.927, acc: 0.783
******** [step = 200] loss: 0.935, acc: 0.781
******** [step = 250] loss: 0.939, acc: 0.780
******** [step = 300] loss: 0.943, acc: 0.780
******** [step = 350] loss: 0.949, acc: 0.779
******** [step = 400] loss: 0.955, acc: 0.778
******** [step = 450] loss: 0.958, acc: 0.778
******** [step = 500] loss: 0.961, acc: 0.777
******** [step = 550] loss: 0.965, acc: 0.777
******** [step = 600] loss: 0.970, acc: 0.776
******** [step = 650] loss: 0.973, acc: 0.776
******** [step = 700] loss: 0.979, acc: 0.776
******** [step = 750] loss: 0.983, acc: 0.775
******** [step = 800] loss: 0.986, acc: 0.775
******** [step = 850] loss: 0.990, acc: 0.774
EPOCH = 79 loss: 0.990, acc: 0.774, val_loss: 1.478, val_acc: 0.735

================================================================================2025-08_10 19:26:18
******** [step = 50] loss: 0.920, acc: 0.784
******** [step = 100] loss: 0.918, acc: 0.784
******** [step = 150] loss: 0.928, acc: 0.783
******** [step = 200] loss: 0.932, acc: 0.782
******** [step = 250] loss: 0.938, acc: 0.781
******** [step = 300] loss: 0.940, acc: 0.781
******** [step = 350] loss: 0.945, acc: 0.780
******** [step = 400] loss: 0.950, acc: 0.779
******** [step = 450] loss: 0.956, acc: 0.778
******** [step = 500] loss: 0.960, acc: 0.778
******** [step = 550] loss: 0.964, acc: 0.777
******** [step = 600] loss: 0.967, acc: 0.777
******** [step = 650] loss: 0.970, acc: 0.777
******** [step = 700] loss: 0.973, acc: 0.776
******** [step = 750] loss: 0.977, acc: 0.776
******** [step = 800] loss: 0.981, acc: 0.776
******** [step = 850] loss: 0.985, acc: 0.775
EPOCH = 80 loss: 0.985, acc: 0.775, val_loss: 1.478, val_acc: 0.734

================================================================================2025-08_10 19:27:45
finishing training...
Training complete in 110m 43s
    epoch  ...   val_acc
0     1.0  ...  0.403407
1     2.0  ...  0.461784
2     3.0  ...  0.487666
3     4.0  ...  0.511194
4     5.0  ...  0.529565
..    ...  ...       ...
75   76.0  ...  0.734215
76   77.0  ...  0.732827
77   78.0  ...  0.732912
78   79.0  ...  0.735126
79   80.0  ...  0.734250

[80 rows x 5 columns]
== Done ==
Sun Aug 10 07:28:14 PM EDT 2025
---------------------------------------
Begin Slurm Epilog: Aug-10-2025 19:28:15
Job ID:        6783673
User ID:       xchen920
Account:       gts-apm7
Job name:      channel_trans
Resources:     cpu=4,gres/gpu:v100=1,mem=16G,node=1
Rsrc Used:     cput=07:35:40,vmem=0,walltime=01:53:55,mem=35084K,energy_used=0
Partition:     gpu-v100
QOS:           inferno
Nodes:         atl1-1-01-003-33-0
---------------------------------------
