---------------------------------------
Begin Slurm Prolog: Aug-11-2025 23:42:11
Job ID:    6939685
User ID:   xchen920
Account:   gts-apm7
Job name:  channel_trans
Partition: gpu-v100
QOS:       inferno
---------------------------------------
== Job info ==
Mon Aug 11 11:42:11 PM EDT 2025
atl1-1-02-011-33-0.pace.gatech.edu
/usr/local/pace-apps/lmod/lmod/init/bash: line 200: conda: command not found
== GPU check ==
Mon Aug 11 23:42:20 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-16GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   47C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
== Launch ==
/storage/scratch1/4/xchen920/project
0.10.0
device= cuda:0
  0%|          | 0/135842 [00:00<?, ?it/s] 12%|█▏        | 16831/135842 [00:00<00:01, 107044.80it/s] 28%|██▊       | 38264/135842 [00:00<00:00, 158113.55it/s] 41%|████      | 55279/135842 [00:00<00:00, 120271.13it/s] 51%|█████     | 69378/135842 [00:00<00:00, 94934.14it/s]  66%|██████▌   | 89135/135842 [00:00<00:00, 119857.59it/s] 79%|███████▉  | 107136/135842 [00:01<00:00, 90986.17it/s] 92%|█████████▏| 125292/135842 [00:01<00:00, 108945.69it/s]100%|██████████| 135842/135842 [00:01<00:00, 112140.69it/s]
  0%|          | 0/108673 [00:00<?, ?it/s] 16%|█▌        | 17366/108673 [00:00<00:00, 173648.16it/s] 32%|███▏      | 34731/108673 [00:00<00:01, 68339.13it/s]  48%|████▊     | 52545/108673 [00:00<00:00, 95624.40it/s] 65%|██████▍   | 70292/108673 [00:00<00:00, 117064.68it/s] 79%|███████▊  | 85500/108673 [00:01<00:00, 66660.96it/s]  95%|█████████▌| 103290/108673 [00:01<00:00, 85573.92it/s]100%|██████████| 108673/108673 [00:01<00:00, 88949.66it/s]
  0%|          | 0/27169 [00:00<?, ?it/s] 66%|██████▌   | 17885/27169 [00:00<00:00, 178840.36it/s]100%|██████████| 27169/27169 [00:00<00:00, 180542.29it/s]
tensor([    3,    56,   159,    38, 14948,    45,    57,    35,    12,    21,
            6,    83,    77,  1302,    40,    22,   359,     7,    14,  1489,
            4,     2,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,
            1,     1])
torch.Size([52, 128]) torch.Size([52, 128])
++++++++++++++++ 213
len(train_dataloader): 850
torch.Size([128, 52]) torch.Size([128, 52])
tensor([   3,    5,   15,  362,   83,   28,  744,  177, 2754,  102,   16,   74,
           7,   42,   41,  225,   65,   26,   41,  260,  256,    6,   20,   13,
          19,   41,  743,   47,  573,    4,    2,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1]) torch.int64
tensor([   3,    5,   99,   84,   10,  714,  224, 5466,    5,   62,   55,    7,
          49,   52,   56,  184, 1347,    5,   62,  210,  175,   21,   13,    4,
           2,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,
           1,    1,    1,    1]) torch.int64
*************************** start training...

================================================================================2025-08_11 23:45:26
******** [step = 50] loss: 9.391, acc: 0.004
******** [step = 100] loss: 8.944, acc: 0.088
******** [step = 150] loss: 8.576, acc: 0.126
******** [step = 200] loss: 8.241, acc: 0.155
******** [step = 250] loss: 7.925, acc: 0.173
******** [step = 300] loss: 7.620, acc: 0.186
******** [step = 350] loss: 7.328, acc: 0.197
******** [step = 400] loss: 7.054, acc: 0.207
******** [step = 450] loss: 6.802, acc: 0.218
******** [step = 500] loss: 6.582, acc: 0.229
******** [step = 550] loss: 6.388, acc: 0.239
******** [step = 600] loss: 6.215, acc: 0.248
******** [step = 650] loss: 6.061, acc: 0.257
******** [step = 700] loss: 5.924, acc: 0.264
******** [step = 750] loss: 5.798, acc: 0.271
******** [step = 800] loss: 5.684, acc: 0.277
******** [step = 850] loss: 5.579, acc: 0.283
EPOCH = 1 loss: 5.579, acc: 0.283, val_loss: 3.774, val_acc: 0.393

================================================================================2025-08_11 23:47:35
******** [step = 50] loss: 3.836, acc: 0.376
******** [step = 100] loss: 3.804, acc: 0.380
******** [step = 150] loss: 3.791, acc: 0.382
******** [step = 200] loss: 3.766, acc: 0.383
******** [step = 250] loss: 3.740, acc: 0.386
******** [step = 300] loss: 3.721, acc: 0.387
******** [step = 350] loss: 3.702, acc: 0.389
******** [step = 400] loss: 3.687, acc: 0.391
******** [step = 450] loss: 3.670, acc: 0.392
******** [step = 500] loss: 3.655, acc: 0.393
******** [step = 550] loss: 3.640, acc: 0.395
******** [step = 600] loss: 3.624, acc: 0.396
******** [step = 650] loss: 3.610, acc: 0.398
******** [step = 700] loss: 3.598, acc: 0.399
******** [step = 750] loss: 3.585, acc: 0.400
******** [step = 800] loss: 3.572, acc: 0.401
******** [step = 850] loss: 3.560, acc: 0.403
EPOCH = 2 loss: 3.560, acc: 0.403, val_loss: 3.271, val_acc: 0.434

================================================================================2025-08_11 23:49:39
******** [step = 50] loss: 3.309, acc: 0.422
******** [step = 100] loss: 3.300, acc: 0.423
******** [step = 150] loss: 3.282, acc: 0.425
******** [step = 200] loss: 3.280, acc: 0.425
******** [step = 250] loss: 3.271, acc: 0.426
******** [step = 300] loss: 3.263, acc: 0.427
******** [step = 350] loss: 3.255, acc: 0.428
******** [step = 400] loss: 3.246, acc: 0.429
******** [step = 450] loss: 3.241, acc: 0.430
******** [step = 500] loss: 3.236, acc: 0.431
******** [step = 550] loss: 3.229, acc: 0.432
******** [step = 600] loss: 3.223, acc: 0.432
******** [step = 650] loss: 3.220, acc: 0.433
******** [step = 700] loss: 3.214, acc: 0.434
******** [step = 750] loss: 3.208, acc: 0.435
******** [step = 800] loss: 3.204, acc: 0.435
******** [step = 850] loss: 3.199, acc: 0.436
EPOCH = 3 loss: 3.199, acc: 0.436, val_loss: 3.063, val_acc: 0.454

================================================================================2025-08_11 23:51:41
******** [step = 50] loss: 3.083, acc: 0.443
******** [step = 100] loss: 3.053, acc: 0.448
******** [step = 150] loss: 3.044, acc: 0.450
******** [step = 200] loss: 3.039, acc: 0.451
******** [step = 250] loss: 3.032, acc: 0.452
******** [step = 300] loss: 3.025, acc: 0.453
******** [step = 350] loss: 3.023, acc: 0.453
******** [step = 400] loss: 3.018, acc: 0.454
******** [step = 450] loss: 3.018, acc: 0.454
******** [step = 500] loss: 3.014, acc: 0.455
******** [step = 550] loss: 3.010, acc: 0.455
******** [step = 600] loss: 3.007, acc: 0.456
******** [step = 650] loss: 3.004, acc: 0.456
******** [step = 700] loss: 3.001, acc: 0.456
******** [step = 750] loss: 2.998, acc: 0.457
******** [step = 800] loss: 2.996, acc: 0.457
******** [step = 850] loss: 2.994, acc: 0.457
EPOCH = 4 loss: 2.994, acc: 0.457, val_loss: 2.911, val_acc: 0.471

================================================================================2025-08_11 23:53:44
******** [step = 50] loss: 2.916, acc: 0.459
******** [step = 100] loss: 2.890, acc: 0.464
******** [step = 150] loss: 2.882, acc: 0.465
******** [step = 200] loss: 2.884, acc: 0.466
******** [step = 250] loss: 2.883, acc: 0.467
******** [step = 300] loss: 2.881, acc: 0.467
******** [step = 350] loss: 2.883, acc: 0.467
******** [step = 400] loss: 2.879, acc: 0.468
******** [step = 450] loss: 2.880, acc: 0.468
******** [step = 500] loss: 2.876, acc: 0.469
******** [step = 550] loss: 2.875, acc: 0.469
******** [step = 600] loss: 2.874, acc: 0.469
******** [step = 650] loss: 2.871, acc: 0.470
******** [step = 700] loss: 2.870, acc: 0.470
******** [step = 750] loss: 2.870, acc: 0.471
******** [step = 800] loss: 2.868, acc: 0.471
******** [step = 850] loss: 2.864, acc: 0.472
EPOCH = 5 loss: 2.864, acc: 0.472, val_loss: 2.776, val_acc: 0.496

================================================================================2025-08_11 23:55:47
******** [step = 50] loss: 2.762, acc: 0.481
******** [step = 100] loss: 2.743, acc: 0.483
******** [step = 150] loss: 2.730, acc: 0.485
******** [step = 200] loss: 2.724, acc: 0.486
******** [step = 250] loss: 2.726, acc: 0.486
******** [step = 300] loss: 2.727, acc: 0.487
******** [step = 350] loss: 2.726, acc: 0.487
******** [step = 400] loss: 2.727, acc: 0.487
******** [step = 450] loss: 2.729, acc: 0.487
******** [step = 500] loss: 2.727, acc: 0.488
******** [step = 550] loss: 2.727, acc: 0.488
******** [step = 600] loss: 2.725, acc: 0.488
******** [step = 650] loss: 2.724, acc: 0.489
******** [step = 700] loss: 2.721, acc: 0.489
******** [step = 750] loss: 2.720, acc: 0.489
******** [step = 800] loss: 2.720, acc: 0.490
******** [step = 850] loss: 2.717, acc: 0.490
EPOCH = 6 loss: 2.717, acc: 0.490, val_loss: 2.666, val_acc: 0.504

================================================================================2025-08_11 23:57:49
******** [step = 50] loss: 2.635, acc: 0.493
******** [step = 100] loss: 2.602, acc: 0.499
******** [step = 150] loss: 2.591, acc: 0.502
******** [step = 200] loss: 2.584, acc: 0.503
******** [step = 250] loss: 2.582, acc: 0.503
******** [step = 300] loss: 2.585, acc: 0.503
******** [step = 350] loss: 2.584, acc: 0.504
******** [step = 400] loss: 2.585, acc: 0.504
******** [step = 450] loss: 2.585, acc: 0.504
******** [step = 500] loss: 2.582, acc: 0.505
******** [step = 550] loss: 2.583, acc: 0.505
******** [step = 600] loss: 2.582, acc: 0.506
******** [step = 650] loss: 2.583, acc: 0.506
******** [step = 700] loss: 2.584, acc: 0.506
******** [step = 750] loss: 2.584, acc: 0.506
******** [step = 800] loss: 2.583, acc: 0.506
******** [step = 850] loss: 2.584, acc: 0.506
EPOCH = 7 loss: 2.584, acc: 0.506, val_loss: 2.532, val_acc: 0.527

================================================================================2025-08_11 23:59:51
******** [step = 50] loss: 2.460, acc: 0.518
******** [step = 100] loss: 2.445, acc: 0.520
******** [step = 150] loss: 2.439, acc: 0.521
******** [step = 200] loss: 2.444, acc: 0.521
******** [step = 250] loss: 2.450, acc: 0.521
******** [step = 300] loss: 2.450, acc: 0.522
******** [step = 350] loss: 2.456, acc: 0.521
******** [step = 400] loss: 2.461, acc: 0.521
******** [step = 450] loss: 2.462, acc: 0.521
******** [step = 500] loss: 2.463, acc: 0.521
******** [step = 550] loss: 2.465, acc: 0.521
******** [step = 600] loss: 2.467, acc: 0.521
******** [step = 650] loss: 2.470, acc: 0.521
******** [step = 700] loss: 2.470, acc: 0.521
******** [step = 750] loss: 2.471, acc: 0.521
******** [step = 800] loss: 2.470, acc: 0.521
******** [step = 850] loss: 2.471, acc: 0.521
EPOCH = 8 loss: 2.471, acc: 0.521, val_loss: 2.453, val_acc: 0.539

================================================================================2025-08_12 00:01:55
******** [step = 50] loss: 2.361, acc: 0.532
******** [step = 100] loss: 2.348, acc: 0.534
******** [step = 150] loss: 2.349, acc: 0.534
******** [step = 200] loss: 2.351, acc: 0.535
******** [step = 250] loss: 2.355, acc: 0.534
******** [step = 300] loss: 2.361, acc: 0.534
******** [step = 350] loss: 2.366, acc: 0.534
******** [step = 400] loss: 2.371, acc: 0.534
******** [step = 450] loss: 2.371, acc: 0.534
******** [step = 500] loss: 2.371, acc: 0.534
******** [step = 550] loss: 2.374, acc: 0.534
******** [step = 600] loss: 2.374, acc: 0.534
******** [step = 650] loss: 2.374, acc: 0.534
******** [step = 700] loss: 2.376, acc: 0.534
******** [step = 750] loss: 2.378, acc: 0.534
******** [step = 800] loss: 2.379, acc: 0.534
******** [step = 850] loss: 2.380, acc: 0.534
EPOCH = 9 loss: 2.380, acc: 0.534, val_loss: 2.393, val_acc: 0.550

================================================================================2025-08_12 00:03:59
******** [step = 50] loss: 2.281, acc: 0.542
******** [step = 100] loss: 2.264, acc: 0.547
******** [step = 150] loss: 2.273, acc: 0.545
******** [step = 200] loss: 2.277, acc: 0.545
******** [step = 250] loss: 2.283, acc: 0.545
******** [step = 300] loss: 2.287, acc: 0.545
******** [step = 350] loss: 2.293, acc: 0.545
******** [step = 400] loss: 2.293, acc: 0.545
******** [step = 450] loss: 2.293, acc: 0.545
******** [step = 500] loss: 2.296, acc: 0.545
******** [step = 550] loss: 2.296, acc: 0.545
******** [step = 600] loss: 2.298, acc: 0.545
******** [step = 650] loss: 2.300, acc: 0.545
******** [step = 700] loss: 2.299, acc: 0.545
******** [step = 750] loss: 2.303, acc: 0.545
******** [step = 800] loss: 2.304, acc: 0.545
******** [step = 850] loss: 2.304, acc: 0.545
EPOCH = 10 loss: 2.304, acc: 0.545, val_loss: 2.336, val_acc: 0.561

================================================================================2025-08_12 00:06:04
******** [step = 50] loss: 2.205, acc: 0.554
******** [step = 100] loss: 2.211, acc: 0.555
******** [step = 150] loss: 2.204, acc: 0.557
******** [step = 200] loss: 2.203, acc: 0.557
******** [step = 250] loss: 2.206, acc: 0.557
******** [step = 300] loss: 2.211, acc: 0.557
******** [step = 350] loss: 2.212, acc: 0.557
******** [step = 400] loss: 2.219, acc: 0.556
******** [step = 450] loss: 2.221, acc: 0.556
******** [step = 500] loss: 2.223, acc: 0.556
******** [step = 550] loss: 2.224, acc: 0.556
******** [step = 600] loss: 2.226, acc: 0.556
******** [step = 650] loss: 2.229, acc: 0.556
******** [step = 700] loss: 2.231, acc: 0.556
******** [step = 750] loss: 2.232, acc: 0.556
******** [step = 800] loss: 2.233, acc: 0.556
******** [step = 850] loss: 2.233, acc: 0.557
EPOCH = 11 loss: 2.233, acc: 0.557, val_loss: 2.289, val_acc: 0.571

================================================================================2025-08_12 00:08:08
******** [step = 50] loss: 2.152, acc: 0.562
******** [step = 100] loss: 2.142, acc: 0.566
******** [step = 150] loss: 2.146, acc: 0.566
******** [step = 200] loss: 2.154, acc: 0.566
******** [step = 250] loss: 2.156, acc: 0.566
******** [step = 300] loss: 2.157, acc: 0.566
******** [step = 350] loss: 2.159, acc: 0.566
******** [step = 400] loss: 2.161, acc: 0.566
******** [step = 450] loss: 2.163, acc: 0.566
******** [step = 500] loss: 2.165, acc: 0.566
******** [step = 550] loss: 2.165, acc: 0.566
******** [step = 600] loss: 2.168, acc: 0.566
******** [step = 650] loss: 2.169, acc: 0.566
******** [step = 700] loss: 2.168, acc: 0.567
******** [step = 750] loss: 2.169, acc: 0.567
******** [step = 800] loss: 2.172, acc: 0.566
******** [step = 850] loss: 2.170, acc: 0.567
EPOCH = 12 loss: 2.170, acc: 0.567, val_loss: 2.246, val_acc: 0.580

================================================================================2025-08_12 00:10:11
******** [step = 50] loss: 2.099, acc: 0.573
******** [step = 100] loss: 2.102, acc: 0.573
******** [step = 150] loss: 2.093, acc: 0.574
******** [step = 200] loss: 2.096, acc: 0.574
******** [step = 250] loss: 2.099, acc: 0.574
******** [step = 300] loss: 2.101, acc: 0.574
******** [step = 350] loss: 2.099, acc: 0.575
******** [step = 400] loss: 2.102, acc: 0.575
******** [step = 450] loss: 2.104, acc: 0.575
******** [step = 500] loss: 2.106, acc: 0.575
******** [step = 550] loss: 2.106, acc: 0.575
******** [step = 600] loss: 2.107, acc: 0.575
******** [step = 650] loss: 2.109, acc: 0.575
******** [step = 700] loss: 2.112, acc: 0.575
******** [step = 750] loss: 2.113, acc: 0.575
******** [step = 800] loss: 2.114, acc: 0.575
******** [step = 850] loss: 2.114, acc: 0.575
EPOCH = 13 loss: 2.114, acc: 0.575, val_loss: 2.220, val_acc: 0.582

================================================================================2025-08_12 00:12:13
******** [step = 50] loss: 2.028, acc: 0.582
******** [step = 100] loss: 2.017, acc: 0.585
******** [step = 150] loss: 2.020, acc: 0.585
******** [step = 200] loss: 2.021, acc: 0.585
******** [step = 250] loss: 2.033, acc: 0.584
******** [step = 300] loss: 2.042, acc: 0.584
******** [step = 350] loss: 2.042, acc: 0.584
******** [step = 400] loss: 2.043, acc: 0.584
******** [step = 450] loss: 2.046, acc: 0.584
******** [step = 500] loss: 2.048, acc: 0.584
******** [step = 550] loss: 2.051, acc: 0.584
******** [step = 600] loss: 2.052, acc: 0.584
******** [step = 650] loss: 2.055, acc: 0.584
******** [step = 700] loss: 2.058, acc: 0.584
******** [step = 750] loss: 2.060, acc: 0.584
******** [step = 800] loss: 2.061, acc: 0.583
******** [step = 850] loss: 2.064, acc: 0.583
EPOCH = 14 loss: 2.064, acc: 0.583, val_loss: 2.181, val_acc: 0.590

================================================================================2025-08_12 00:14:16
******** [step = 50] loss: 1.979, acc: 0.593
******** [step = 100] loss: 1.969, acc: 0.596
******** [step = 150] loss: 1.970, acc: 0.595
******** [step = 200] loss: 1.975, acc: 0.594
******** [step = 250] loss: 1.977, acc: 0.594
******** [step = 300] loss: 1.980, acc: 0.594
******** [step = 350] loss: 1.983, acc: 0.593
******** [step = 400] loss: 1.984, acc: 0.593
******** [step = 450] loss: 1.989, acc: 0.593
******** [step = 500] loss: 1.991, acc: 0.593
******** [step = 550] loss: 1.995, acc: 0.593
******** [step = 600] loss: 1.999, acc: 0.592
******** [step = 650] loss: 2.002, acc: 0.592
******** [step = 700] loss: 2.005, acc: 0.592
******** [step = 750] loss: 2.007, acc: 0.592
******** [step = 800] loss: 2.009, acc: 0.592
******** [step = 850] loss: 2.012, acc: 0.592
EPOCH = 15 loss: 2.012, acc: 0.592, val_loss: 2.124, val_acc: 0.602

================================================================================2025-08_12 00:16:20
******** [step = 50] loss: 1.906, acc: 0.604
******** [step = 100] loss: 1.916, acc: 0.603
******** [step = 150] loss: 1.920, acc: 0.603
******** [step = 200] loss: 1.920, acc: 0.604
******** [step = 250] loss: 1.924, acc: 0.603
******** [step = 300] loss: 1.926, acc: 0.603
******** [step = 350] loss: 1.931, acc: 0.603
******** [step = 400] loss: 1.936, acc: 0.602
******** [step = 450] loss: 1.937, acc: 0.602
******** [step = 500] loss: 1.940, acc: 0.602
******** [step = 550] loss: 1.945, acc: 0.601
******** [step = 600] loss: 1.948, acc: 0.601
******** [step = 650] loss: 1.952, acc: 0.601
******** [step = 700] loss: 1.954, acc: 0.601
******** [step = 750] loss: 1.957, acc: 0.601
******** [step = 800] loss: 1.961, acc: 0.600
******** [step = 850] loss: 1.961, acc: 0.601
EPOCH = 16 loss: 1.961, acc: 0.601, val_loss: 2.091, val_acc: 0.608

================================================================================2025-08_12 00:18:22
******** [step = 50] loss: 1.859, acc: 0.613
******** [step = 100] loss: 1.857, acc: 0.612
******** [step = 150] loss: 1.864, acc: 0.612
******** [step = 200] loss: 1.874, acc: 0.611
******** [step = 250] loss: 1.881, acc: 0.611
******** [step = 300] loss: 1.885, acc: 0.610
******** [step = 350] loss: 1.889, acc: 0.610
******** [step = 400] loss: 1.887, acc: 0.611
******** [step = 450] loss: 1.889, acc: 0.610
******** [step = 500] loss: 1.891, acc: 0.610
******** [step = 550] loss: 1.893, acc: 0.610
******** [step = 600] loss: 1.893, acc: 0.611
******** [step = 650] loss: 1.898, acc: 0.610
******** [step = 700] loss: 1.900, acc: 0.610
******** [step = 750] loss: 1.902, acc: 0.610
******** [step = 800] loss: 1.904, acc: 0.610
******** [step = 850] loss: 1.911, acc: 0.610
EPOCH = 17 loss: 1.911, acc: 0.610, val_loss: 2.057, val_acc: 0.616

================================================================================2025-08_12 00:20:24
******** [step = 50] loss: 1.782, acc: 0.625
******** [step = 100] loss: 1.802, acc: 0.623
******** [step = 150] loss: 1.807, acc: 0.622
******** [step = 200] loss: 1.818, acc: 0.622
******** [step = 250] loss: 1.822, acc: 0.622
******** [step = 300] loss: 1.823, acc: 0.622
******** [step = 350] loss: 1.829, acc: 0.622
******** [step = 400] loss: 1.834, acc: 0.622
******** [step = 450] loss: 1.835, acc: 0.622
******** [step = 500] loss: 1.838, acc: 0.622
******** [step = 550] loss: 1.844, acc: 0.621
******** [step = 600] loss: 1.847, acc: 0.621
******** [step = 650] loss: 1.849, acc: 0.621
******** [step = 700] loss: 1.851, acc: 0.621
******** [step = 750] loss: 1.852, acc: 0.621
******** [step = 800] loss: 1.853, acc: 0.621
******** [step = 850] loss: 1.852, acc: 0.621
EPOCH = 18 loss: 1.852, acc: 0.621, val_loss: 1.993, val_acc: 0.629

================================================================================2025-08_12 00:22:28
******** [step = 50] loss: 1.748, acc: 0.634
******** [step = 100] loss: 1.752, acc: 0.632
******** [step = 150] loss: 1.759, acc: 0.631
******** [step = 200] loss: 1.758, acc: 0.632
******** [step = 250] loss: 1.764, acc: 0.632
******** [step = 300] loss: 1.769, acc: 0.631
******** [step = 350] loss: 1.771, acc: 0.631
******** [step = 400] loss: 1.773, acc: 0.631
******** [step = 450] loss: 1.779, acc: 0.630
******** [step = 500] loss: 1.780, acc: 0.631
******** [step = 550] loss: 1.785, acc: 0.630
******** [step = 600] loss: 1.788, acc: 0.630
******** [step = 650] loss: 1.788, acc: 0.630
******** [step = 700] loss: 1.793, acc: 0.630
******** [step = 750] loss: 1.794, acc: 0.630
******** [step = 800] loss: 1.796, acc: 0.630
******** [step = 850] loss: 1.799, acc: 0.630
EPOCH = 19 loss: 1.799, acc: 0.630, val_loss: 1.952, val_acc: 0.637

================================================================================2025-08_12 00:24:30
******** [step = 50] loss: 1.712, acc: 0.640
******** [step = 100] loss: 1.686, acc: 0.644
******** [step = 150] loss: 1.691, acc: 0.644
******** [step = 200] loss: 1.700, acc: 0.643
******** [step = 250] loss: 1.706, acc: 0.643
******** [step = 300] loss: 1.714, acc: 0.642
******** [step = 350] loss: 1.718, acc: 0.641
******** [step = 400] loss: 1.725, acc: 0.641
******** [step = 450] loss: 1.727, acc: 0.641
******** [step = 500] loss: 1.731, acc: 0.640
******** [step = 550] loss: 1.731, acc: 0.640
******** [step = 600] loss: 1.734, acc: 0.640
******** [step = 650] loss: 1.737, acc: 0.640
******** [step = 700] loss: 1.741, acc: 0.640
******** [step = 750] loss: 1.742, acc: 0.640
******** [step = 800] loss: 1.744, acc: 0.640
******** [step = 850] loss: 1.747, acc: 0.640
EPOCH = 20 loss: 1.747, acc: 0.640, val_loss: 1.906, val_acc: 0.645

================================================================================2025-08_12 00:26:32
******** [step = 50] loss: 1.655, acc: 0.648
******** [step = 100] loss: 1.658, acc: 0.650
******** [step = 150] loss: 1.660, acc: 0.650
******** [step = 200] loss: 1.660, acc: 0.650
******** [step = 250] loss: 1.668, acc: 0.649
******** [step = 300] loss: 1.668, acc: 0.650
******** [step = 350] loss: 1.671, acc: 0.649
******** [step = 400] loss: 1.676, acc: 0.649
******** [step = 450] loss: 1.679, acc: 0.648
******** [step = 500] loss: 1.683, acc: 0.648
******** [step = 550] loss: 1.686, acc: 0.648
******** [step = 600] loss: 1.688, acc: 0.648
******** [step = 650] loss: 1.691, acc: 0.648
******** [step = 700] loss: 1.695, acc: 0.648
******** [step = 750] loss: 1.697, acc: 0.648
******** [step = 800] loss: 1.699, acc: 0.647
******** [step = 850] loss: 1.701, acc: 0.648
EPOCH = 21 loss: 1.701, acc: 0.648, val_loss: 1.870, val_acc: 0.653

================================================================================2025-08_12 00:28:34
******** [step = 50] loss: 1.604, acc: 0.661
******** [step = 100] loss: 1.596, acc: 0.661
******** [step = 150] loss: 1.607, acc: 0.660
******** [step = 200] loss: 1.609, acc: 0.660
******** [step = 250] loss: 1.616, acc: 0.659
******** [step = 300] loss: 1.622, acc: 0.658
******** [step = 350] loss: 1.625, acc: 0.658
******** [step = 400] loss: 1.631, acc: 0.657
******** [step = 450] loss: 1.633, acc: 0.657
******** [step = 500] loss: 1.636, acc: 0.657
******** [step = 550] loss: 1.641, acc: 0.656
******** [step = 600] loss: 1.644, acc: 0.656
******** [step = 650] loss: 1.646, acc: 0.656
******** [step = 700] loss: 1.647, acc: 0.656
******** [step = 750] loss: 1.651, acc: 0.656
******** [step = 800] loss: 1.652, acc: 0.656
******** [step = 850] loss: 1.655, acc: 0.656
EPOCH = 22 loss: 1.655, acc: 0.656, val_loss: 1.830, val_acc: 0.659

================================================================================2025-08_12 00:30:37
******** [step = 50] loss: 1.556, acc: 0.667
******** [step = 100] loss: 1.561, acc: 0.667
******** [step = 150] loss: 1.574, acc: 0.665
******** [step = 200] loss: 1.572, acc: 0.666
******** [step = 250] loss: 1.577, acc: 0.666
******** [step = 300] loss: 1.583, acc: 0.665
******** [step = 350] loss: 1.586, acc: 0.665
******** [step = 400] loss: 1.590, acc: 0.664
******** [step = 450] loss: 1.592, acc: 0.664
******** [step = 500] loss: 1.594, acc: 0.664
******** [step = 550] loss: 1.598, acc: 0.664
******** [step = 600] loss: 1.602, acc: 0.663
******** [step = 650] loss: 1.603, acc: 0.663
******** [step = 700] loss: 1.607, acc: 0.663
******** [step = 750] loss: 1.611, acc: 0.663
******** [step = 800] loss: 1.613, acc: 0.663
******** [step = 850] loss: 1.615, acc: 0.663
EPOCH = 23 loss: 1.615, acc: 0.663, val_loss: 1.802, val_acc: 0.666

================================================================================2025-08_12 00:32:41
******** [step = 50] loss: 1.526, acc: 0.676
******** [step = 100] loss: 1.530, acc: 0.675
******** [step = 150] loss: 1.533, acc: 0.675
******** [step = 200] loss: 1.532, acc: 0.676
******** [step = 250] loss: 1.536, acc: 0.675
******** [step = 300] loss: 1.542, acc: 0.673
******** [step = 350] loss: 1.546, acc: 0.672
******** [step = 400] loss: 1.548, acc: 0.672
******** [step = 450] loss: 1.549, acc: 0.672
******** [step = 500] loss: 1.553, acc: 0.672
******** [step = 550] loss: 1.556, acc: 0.672
******** [step = 600] loss: 1.559, acc: 0.671
******** [step = 650] loss: 1.563, acc: 0.671
******** [step = 700] loss: 1.567, acc: 0.671
******** [step = 750] loss: 1.569, acc: 0.671
******** [step = 800] loss: 1.572, acc: 0.671
******** [step = 850] loss: 1.574, acc: 0.670
EPOCH = 24 loss: 1.574, acc: 0.670, val_loss: 1.780, val_acc: 0.670

================================================================================2025-08_12 00:34:45
******** [step = 50] loss: 1.490, acc: 0.679
******** [step = 100] loss: 1.491, acc: 0.680
******** [step = 150] loss: 1.490, acc: 0.681
******** [step = 200] loss: 1.500, acc: 0.680
******** [step = 250] loss: 1.504, acc: 0.679
******** [step = 300] loss: 1.508, acc: 0.678
******** [step = 350] loss: 1.510, acc: 0.678
******** [step = 400] loss: 1.513, acc: 0.678
******** [step = 450] loss: 1.516, acc: 0.678
******** [step = 500] loss: 1.521, acc: 0.677
******** [step = 550] loss: 1.525, acc: 0.677
******** [step = 600] loss: 1.528, acc: 0.677
******** [step = 650] loss: 1.530, acc: 0.677
******** [step = 700] loss: 1.534, acc: 0.676
******** [step = 750] loss: 1.534, acc: 0.677
******** [step = 800] loss: 1.536, acc: 0.677
******** [step = 850] loss: 1.543, acc: 0.676
EPOCH = 25 loss: 1.543, acc: 0.676, val_loss: 1.751, val_acc: 0.677

================================================================================2025-08_12 00:36:48
******** [step = 50] loss: 1.463, acc: 0.683
******** [step = 100] loss: 1.463, acc: 0.685
******** [step = 150] loss: 1.459, acc: 0.685
******** [step = 200] loss: 1.468, acc: 0.685
******** [step = 250] loss: 1.471, acc: 0.685
******** [step = 300] loss: 1.479, acc: 0.683
******** [step = 350] loss: 1.479, acc: 0.684
******** [step = 400] loss: 1.480, acc: 0.684
******** [step = 450] loss: 1.482, acc: 0.684
******** [step = 500] loss: 1.487, acc: 0.683
******** [step = 550] loss: 1.489, acc: 0.683
******** [step = 600] loss: 1.493, acc: 0.683
******** [step = 650] loss: 1.496, acc: 0.683
******** [step = 700] loss: 1.500, acc: 0.682
******** [step = 750] loss: 1.502, acc: 0.682
******** [step = 800] loss: 1.506, acc: 0.682
******** [step = 850] loss: 1.509, acc: 0.682
EPOCH = 26 loss: 1.509, acc: 0.682, val_loss: 1.730, val_acc: 0.681

================================================================================2025-08_12 00:38:51
******** [step = 50] loss: 1.424, acc: 0.690
******** [step = 100] loss: 1.430, acc: 0.691
******** [step = 150] loss: 1.428, acc: 0.692
******** [step = 200] loss: 1.431, acc: 0.692
******** [step = 250] loss: 1.439, acc: 0.692
******** [step = 300] loss: 1.446, acc: 0.691
******** [step = 350] loss: 1.449, acc: 0.690
******** [step = 400] loss: 1.453, acc: 0.690
******** [step = 450] loss: 1.457, acc: 0.689
******** [step = 500] loss: 1.461, acc: 0.689
******** [step = 550] loss: 1.466, acc: 0.688
******** [step = 600] loss: 1.466, acc: 0.688
******** [step = 650] loss: 1.470, acc: 0.688
******** [step = 700] loss: 1.473, acc: 0.688
******** [step = 750] loss: 1.476, acc: 0.688
******** [step = 800] loss: 1.479, acc: 0.687
******** [step = 850] loss: 1.480, acc: 0.688
EPOCH = 27 loss: 1.480, acc: 0.688, val_loss: 1.697, val_acc: 0.687

================================================================================2025-08_12 00:40:52
******** [step = 50] loss: 1.402, acc: 0.698
******** [step = 100] loss: 1.390, acc: 0.700
******** [step = 150] loss: 1.396, acc: 0.698
******** [step = 200] loss: 1.399, acc: 0.697
******** [step = 250] loss: 1.406, acc: 0.697
******** [step = 300] loss: 1.411, acc: 0.696
******** [step = 350] loss: 1.416, acc: 0.696
******** [step = 400] loss: 1.421, acc: 0.695
******** [step = 450] loss: 1.425, acc: 0.695
******** [step = 500] loss: 1.430, acc: 0.694
******** [step = 550] loss: 1.433, acc: 0.694
******** [step = 600] loss: 1.440, acc: 0.693
******** [step = 650] loss: 1.443, acc: 0.693
******** [step = 700] loss: 1.445, acc: 0.693
******** [step = 750] loss: 1.448, acc: 0.692
******** [step = 800] loss: 1.451, acc: 0.692
******** [step = 850] loss: 1.457, acc: 0.692
EPOCH = 28 loss: 1.457, acc: 0.692, val_loss: 1.688, val_acc: 0.688

================================================================================2025-08_12 00:42:56
******** [step = 50] loss: 1.382, acc: 0.699
******** [step = 100] loss: 1.380, acc: 0.700
******** [step = 150] loss: 1.379, acc: 0.700
******** [step = 200] loss: 1.379, acc: 0.702
******** [step = 250] loss: 1.382, acc: 0.701
******** [step = 300] loss: 1.388, acc: 0.700
******** [step = 350] loss: 1.392, acc: 0.700
******** [step = 400] loss: 1.396, acc: 0.699
******** [step = 450] loss: 1.398, acc: 0.699
******** [step = 500] loss: 1.403, acc: 0.699
******** [step = 550] loss: 1.408, acc: 0.698
******** [step = 600] loss: 1.412, acc: 0.698
******** [step = 650] loss: 1.414, acc: 0.698
******** [step = 700] loss: 1.417, acc: 0.698
******** [step = 750] loss: 1.422, acc: 0.697
******** [step = 800] loss: 1.424, acc: 0.697
******** [step = 850] loss: 1.430, acc: 0.696
EPOCH = 29 loss: 1.430, acc: 0.696, val_loss: 1.667, val_acc: 0.691

================================================================================2025-08_12 00:44:58
******** [step = 50] loss: 1.333, acc: 0.707
******** [step = 100] loss: 1.339, acc: 0.707
******** [step = 150] loss: 1.348, acc: 0.706
******** [step = 200] loss: 1.348, acc: 0.706
******** [step = 250] loss: 1.351, acc: 0.706
******** [step = 300] loss: 1.357, acc: 0.705
******** [step = 350] loss: 1.362, acc: 0.705
******** [step = 400] loss: 1.367, acc: 0.704
******** [step = 450] loss: 1.371, acc: 0.704
******** [step = 500] loss: 1.376, acc: 0.704
******** [step = 550] loss: 1.384, acc: 0.703
******** [step = 600] loss: 1.388, acc: 0.702
******** [step = 650] loss: 1.393, acc: 0.702
******** [step = 700] loss: 1.394, acc: 0.702
******** [step = 750] loss: 1.397, acc: 0.702
******** [step = 800] loss: 1.400, acc: 0.701
******** [step = 850] loss: 1.403, acc: 0.701
EPOCH = 30 loss: 1.403, acc: 0.701, val_loss: 1.655, val_acc: 0.694

================================================================================2025-08_12 00:47:00
******** [step = 50] loss: 1.319, acc: 0.708
******** [step = 100] loss: 1.319, acc: 0.709
******** [step = 150] loss: 1.323, acc: 0.710
******** [step = 200] loss: 1.324, acc: 0.710
******** [step = 250] loss: 1.329, acc: 0.710
******** [step = 300] loss: 1.335, acc: 0.710
******** [step = 350] loss: 1.338, acc: 0.709
******** [step = 400] loss: 1.342, acc: 0.709
******** [step = 450] loss: 1.347, acc: 0.708
******** [step = 500] loss: 1.354, acc: 0.708
******** [step = 550] loss: 1.359, acc: 0.707
******** [step = 600] loss: 1.362, acc: 0.707
******** [step = 650] loss: 1.367, acc: 0.706
******** [step = 700] loss: 1.371, acc: 0.706
******** [step = 750] loss: 1.373, acc: 0.706
******** [step = 800] loss: 1.376, acc: 0.706
******** [step = 850] loss: 1.379, acc: 0.706
EPOCH = 31 loss: 1.379, acc: 0.706, val_loss: 1.635, val_acc: 0.698

================================================================================2025-08_12 00:49:01
******** [step = 50] loss: 1.301, acc: 0.715
******** [step = 100] loss: 1.307, acc: 0.714
******** [step = 150] loss: 1.310, acc: 0.714
******** [step = 200] loss: 1.314, acc: 0.714
******** [step = 250] loss: 1.322, acc: 0.713
******** [step = 300] loss: 1.329, acc: 0.712
******** [step = 350] loss: 1.334, acc: 0.712
******** [step = 400] loss: 1.333, acc: 0.712
******** [step = 450] loss: 1.335, acc: 0.712
******** [step = 500] loss: 1.340, acc: 0.711
******** [step = 550] loss: 1.342, acc: 0.711
******** [step = 600] loss: 1.346, acc: 0.711
******** [step = 650] loss: 1.348, acc: 0.710
******** [step = 700] loss: 1.350, acc: 0.710
******** [step = 750] loss: 1.353, acc: 0.710
******** [step = 800] loss: 1.357, acc: 0.710
******** [step = 850] loss: 1.359, acc: 0.710
EPOCH = 32 loss: 1.359, acc: 0.710, val_loss: 1.620, val_acc: 0.701

================================================================================2025-08_12 00:51:07
******** [step = 50] loss: 1.289, acc: 0.719
******** [step = 100] loss: 1.282, acc: 0.720
******** [step = 150] loss: 1.280, acc: 0.720
******** [step = 200] loss: 1.285, acc: 0.719
******** [step = 250] loss: 1.295, acc: 0.717
******** [step = 300] loss: 1.298, acc: 0.717
******** [step = 350] loss: 1.302, acc: 0.717
******** [step = 400] loss: 1.307, acc: 0.716
******** [step = 450] loss: 1.313, acc: 0.715
******** [step = 500] loss: 1.317, acc: 0.715
******** [step = 550] loss: 1.319, acc: 0.715
******** [step = 600] loss: 1.322, acc: 0.714
******** [step = 650] loss: 1.326, acc: 0.714
******** [step = 700] loss: 1.329, acc: 0.714
******** [step = 750] loss: 1.333, acc: 0.713
******** [step = 800] loss: 1.335, acc: 0.713
******** [step = 850] loss: 1.339, acc: 0.713
EPOCH = 33 loss: 1.339, acc: 0.713, val_loss: 1.603, val_acc: 0.705

================================================================================2025-08_12 00:53:09
******** [step = 50] loss: 1.256, acc: 0.722
******** [step = 100] loss: 1.270, acc: 0.721
******** [step = 150] loss: 1.269, acc: 0.722
******** [step = 200] loss: 1.277, acc: 0.720
******** [step = 250] loss: 1.280, acc: 0.720
******** [step = 300] loss: 1.283, acc: 0.719
******** [step = 350] loss: 1.287, acc: 0.719
******** [step = 400] loss: 1.292, acc: 0.718
******** [step = 450] loss: 1.295, acc: 0.718
******** [step = 500] loss: 1.299, acc: 0.718
******** [step = 550] loss: 1.301, acc: 0.718
******** [step = 600] loss: 1.306, acc: 0.717
******** [step = 650] loss: 1.309, acc: 0.717
******** [step = 700] loss: 1.312, acc: 0.717
******** [step = 750] loss: 1.315, acc: 0.716
******** [step = 800] loss: 1.318, acc: 0.716
******** [step = 850] loss: 1.321, acc: 0.716
EPOCH = 34 loss: 1.321, acc: 0.716, val_loss: 1.590, val_acc: 0.707

================================================================================2025-08_12 00:55:10
******** [step = 50] loss: 1.251, acc: 0.723
******** [step = 100] loss: 1.239, acc: 0.727
******** [step = 150] loss: 1.238, acc: 0.727
******** [step = 200] loss: 1.243, acc: 0.727
******** [step = 250] loss: 1.245, acc: 0.727
******** [step = 300] loss: 1.250, acc: 0.726
******** [step = 350] loss: 1.254, acc: 0.725
******** [step = 400] loss: 1.263, acc: 0.724
******** [step = 450] loss: 1.265, acc: 0.724
******** [step = 500] loss: 1.270, acc: 0.723
******** [step = 550] loss: 1.274, acc: 0.723
******** [step = 600] loss: 1.279, acc: 0.722
******** [step = 650] loss: 1.285, acc: 0.721
******** [step = 700] loss: 1.289, acc: 0.721
******** [step = 750] loss: 1.293, acc: 0.720
******** [step = 800] loss: 1.298, acc: 0.720
******** [step = 850] loss: 1.301, acc: 0.720
EPOCH = 35 loss: 1.301, acc: 0.720, val_loss: 1.583, val_acc: 0.709

================================================================================2025-08_12 00:57:12
******** [step = 50] loss: 1.253, acc: 0.725
******** [step = 100] loss: 1.230, acc: 0.729
******** [step = 150] loss: 1.228, acc: 0.729
******** [step = 200] loss: 1.231, acc: 0.729
******** [step = 250] loss: 1.234, acc: 0.728
******** [step = 300] loss: 1.240, acc: 0.727
******** [step = 350] loss: 1.247, acc: 0.726
******** [step = 400] loss: 1.250, acc: 0.726
******** [step = 450] loss: 1.256, acc: 0.725
******** [step = 500] loss: 1.260, acc: 0.725
******** [step = 550] loss: 1.263, acc: 0.724
******** [step = 600] loss: 1.265, acc: 0.724
******** [step = 650] loss: 1.268, acc: 0.724
******** [step = 700] loss: 1.275, acc: 0.723
******** [step = 750] loss: 1.278, acc: 0.723
******** [step = 800] loss: 1.281, acc: 0.723
******** [step = 850] loss: 1.284, acc: 0.723
EPOCH = 36 loss: 1.284, acc: 0.723, val_loss: 1.562, val_acc: 0.713

================================================================================2025-08_12 00:59:14
******** [step = 50] loss: 1.214, acc: 0.731
******** [step = 100] loss: 1.200, acc: 0.733
******** [step = 150] loss: 1.208, acc: 0.732
******** [step = 200] loss: 1.212, acc: 0.732
******** [step = 250] loss: 1.219, acc: 0.731
******** [step = 300] loss: 1.221, acc: 0.731
******** [step = 350] loss: 1.228, acc: 0.730
******** [step = 400] loss: 1.234, acc: 0.729
******** [step = 450] loss: 1.240, acc: 0.728
******** [step = 500] loss: 1.243, acc: 0.728
******** [step = 550] loss: 1.247, acc: 0.728
******** [step = 600] loss: 1.252, acc: 0.727
******** [step = 650] loss: 1.257, acc: 0.727
******** [step = 700] loss: 1.261, acc: 0.726
******** [step = 750] loss: 1.262, acc: 0.726
******** [step = 800] loss: 1.266, acc: 0.726
******** [step = 850] loss: 1.268, acc: 0.726
EPOCH = 37 loss: 1.268, acc: 0.726, val_loss: 1.558, val_acc: 0.714

================================================================================2025-08_12 01:01:16
******** [step = 50] loss: 1.176, acc: 0.738
******** [step = 100] loss: 1.186, acc: 0.737
******** [step = 150] loss: 1.193, acc: 0.736
******** [step = 200] loss: 1.200, acc: 0.734
******** [step = 250] loss: 1.205, acc: 0.733
******** [step = 300] loss: 1.213, acc: 0.733
******** [step = 350] loss: 1.216, acc: 0.732
******** [step = 400] loss: 1.218, acc: 0.732
******** [step = 450] loss: 1.225, acc: 0.731
******** [step = 500] loss: 1.228, acc: 0.731
******** [step = 550] loss: 1.234, acc: 0.730
******** [step = 600] loss: 1.236, acc: 0.730
******** [step = 650] loss: 1.239, acc: 0.730
******** [step = 700] loss: 1.243, acc: 0.729
******** [step = 750] loss: 1.247, acc: 0.729
******** [step = 800] loss: 1.249, acc: 0.729
******** [step = 850] loss: 1.253, acc: 0.728
EPOCH = 38 loss: 1.253, acc: 0.728, val_loss: 1.545, val_acc: 0.716

================================================================================2025-08_12 01:03:17
******** [step = 50] loss: 1.194, acc: 0.738
******** [step = 100] loss: 1.186, acc: 0.738
******** [step = 150] loss: 1.197, acc: 0.737
******** [step = 200] loss: 1.198, acc: 0.736
******** [step = 250] loss: 1.198, acc: 0.736
******** [step = 300] loss: 1.198, acc: 0.736
******** [step = 350] loss: 1.200, acc: 0.736
******** [step = 400] loss: 1.207, acc: 0.735
******** [step = 450] loss: 1.212, acc: 0.734
******** [step = 500] loss: 1.215, acc: 0.733
******** [step = 550] loss: 1.218, acc: 0.733
******** [step = 600] loss: 1.222, acc: 0.733
******** [step = 650] loss: 1.225, acc: 0.733
******** [step = 700] loss: 1.229, acc: 0.732
******** [step = 750] loss: 1.234, acc: 0.732
******** [step = 800] loss: 1.237, acc: 0.731
******** [step = 850] loss: 1.239, acc: 0.731
EPOCH = 39 loss: 1.239, acc: 0.731, val_loss: 1.539, val_acc: 0.717

================================================================================2025-08_12 01:05:19
******** [step = 50] loss: 1.182, acc: 0.737
******** [step = 100] loss: 1.174, acc: 0.739
******** [step = 150] loss: 1.172, acc: 0.739
******** [step = 200] loss: 1.176, acc: 0.739
******** [step = 250] loss: 1.188, acc: 0.737
******** [step = 300] loss: 1.188, acc: 0.738
******** [step = 350] loss: 1.193, acc: 0.737
******** [step = 400] loss: 1.197, acc: 0.736
******** [step = 450] loss: 1.202, acc: 0.736
******** [step = 500] loss: 1.203, acc: 0.736
******** [step = 550] loss: 1.209, acc: 0.735
******** [step = 600] loss: 1.212, acc: 0.735
******** [step = 650] loss: 1.214, acc: 0.734
******** [step = 700] loss: 1.216, acc: 0.734
******** [step = 750] loss: 1.221, acc: 0.734
******** [step = 800] loss: 1.224, acc: 0.733
******** [step = 850] loss: 1.227, acc: 0.733
EPOCH = 40 loss: 1.227, acc: 0.733, val_loss: 1.524, val_acc: 0.721

================================================================================2025-08_12 01:07:21
******** [step = 50] loss: 1.147, acc: 0.747
******** [step = 100] loss: 1.157, acc: 0.745
******** [step = 150] loss: 1.161, acc: 0.743
******** [step = 200] loss: 1.166, acc: 0.742
******** [step = 250] loss: 1.168, acc: 0.741
******** [step = 300] loss: 1.172, acc: 0.741
******** [step = 350] loss: 1.176, acc: 0.740
******** [step = 400] loss: 1.184, acc: 0.739
******** [step = 450] loss: 1.188, acc: 0.738
******** [step = 500] loss: 1.191, acc: 0.738
******** [step = 550] loss: 1.193, acc: 0.738
******** [step = 600] loss: 1.195, acc: 0.738
******** [step = 650] loss: 1.199, acc: 0.738
******** [step = 700] loss: 1.203, acc: 0.737
******** [step = 750] loss: 1.207, acc: 0.737
******** [step = 800] loss: 1.209, acc: 0.737
******** [step = 850] loss: 1.217, acc: 0.736
EPOCH = 41 loss: 1.217, acc: 0.736, val_loss: 1.516, val_acc: 0.722

================================================================================2025-08_12 01:09:22
******** [step = 50] loss: 1.136, acc: 0.746
******** [step = 100] loss: 1.141, acc: 0.745
******** [step = 150] loss: 1.146, acc: 0.745
******** [step = 200] loss: 1.149, acc: 0.745
******** [step = 250] loss: 1.154, acc: 0.744
******** [step = 300] loss: 1.157, acc: 0.743
******** [step = 350] loss: 1.162, acc: 0.743
******** [step = 400] loss: 1.167, acc: 0.742
******** [step = 450] loss: 1.173, acc: 0.741
******** [step = 500] loss: 1.176, acc: 0.741
******** [step = 550] loss: 1.182, acc: 0.740
******** [step = 600] loss: 1.185, acc: 0.740
******** [step = 650] loss: 1.189, acc: 0.740
******** [step = 700] loss: 1.192, acc: 0.740
******** [step = 750] loss: 1.194, acc: 0.739
******** [step = 800] loss: 1.196, acc: 0.739
******** [step = 850] loss: 1.198, acc: 0.739
EPOCH = 42 loss: 1.198, acc: 0.739, val_loss: 1.504, val_acc: 0.724

================================================================================2025-08_12 01:11:24
******** [step = 50] loss: 1.121, acc: 0.749
******** [step = 100] loss: 1.127, acc: 0.749
******** [step = 150] loss: 1.131, acc: 0.748
******** [step = 200] loss: 1.142, acc: 0.746
******** [step = 250] loss: 1.148, acc: 0.745
******** [step = 300] loss: 1.151, acc: 0.745
******** [step = 350] loss: 1.158, acc: 0.744
******** [step = 400] loss: 1.159, acc: 0.744
******** [step = 450] loss: 1.165, acc: 0.743
******** [step = 500] loss: 1.167, acc: 0.743
******** [step = 550] loss: 1.168, acc: 0.743
******** [step = 600] loss: 1.171, acc: 0.743
******** [step = 650] loss: 1.174, acc: 0.742
******** [step = 700] loss: 1.178, acc: 0.742
******** [step = 750] loss: 1.182, acc: 0.741
******** [step = 800] loss: 1.186, acc: 0.741
******** [step = 850] loss: 1.190, acc: 0.741
EPOCH = 43 loss: 1.190, acc: 0.741, val_loss: 1.498, val_acc: 0.725

================================================================================2025-08_12 01:13:25
******** [step = 50] loss: 1.103, acc: 0.750
******** [step = 100] loss: 1.111, acc: 0.751
******** [step = 150] loss: 1.122, acc: 0.749
******** [step = 200] loss: 1.130, acc: 0.748
******** [step = 250] loss: 1.136, acc: 0.748
******** [step = 300] loss: 1.139, acc: 0.747
******** [step = 350] loss: 1.144, acc: 0.746
******** [step = 400] loss: 1.149, acc: 0.745
******** [step = 450] loss: 1.153, acc: 0.745
******** [step = 500] loss: 1.157, acc: 0.745
******** [step = 550] loss: 1.161, acc: 0.744
******** [step = 600] loss: 1.163, acc: 0.744
******** [step = 650] loss: 1.165, acc: 0.744
******** [step = 700] loss: 1.169, acc: 0.744
******** [step = 750] loss: 1.172, acc: 0.743
******** [step = 800] loss: 1.175, acc: 0.743
******** [step = 850] loss: 1.178, acc: 0.743
EPOCH = 44 loss: 1.178, acc: 0.743, val_loss: 1.493, val_acc: 0.728

================================================================================2025-08_12 01:15:28
******** [step = 50] loss: 1.097, acc: 0.753
******** [step = 100] loss: 1.108, acc: 0.752
******** [step = 150] loss: 1.116, acc: 0.750
******** [step = 200] loss: 1.117, acc: 0.750
******** [step = 250] loss: 1.120, acc: 0.750
******** [step = 300] loss: 1.123, acc: 0.749
******** [step = 350] loss: 1.128, acc: 0.749
******** [step = 400] loss: 1.132, acc: 0.748
******** [step = 450] loss: 1.137, acc: 0.748
******** [step = 500] loss: 1.140, acc: 0.748
******** [step = 550] loss: 1.146, acc: 0.747
******** [step = 600] loss: 1.148, acc: 0.747
******** [step = 650] loss: 1.150, acc: 0.747
******** [step = 700] loss: 1.155, acc: 0.746
******** [step = 750] loss: 1.159, acc: 0.746
******** [step = 800] loss: 1.163, acc: 0.745
******** [step = 850] loss: 1.166, acc: 0.745
EPOCH = 45 loss: 1.166, acc: 0.745, val_loss: 1.487, val_acc: 0.729

================================================================================2025-08_12 01:17:31
******** [step = 50] loss: 1.082, acc: 0.757
******** [step = 100] loss: 1.092, acc: 0.756
******** [step = 150] loss: 1.096, acc: 0.754
******** [step = 200] loss: 1.102, acc: 0.753
******** [step = 250] loss: 1.102, acc: 0.753
******** [step = 300] loss: 1.109, acc: 0.752
******** [step = 350] loss: 1.118, acc: 0.751
******** [step = 400] loss: 1.123, acc: 0.750
******** [step = 450] loss: 1.127, acc: 0.749
******** [step = 500] loss: 1.133, acc: 0.748
******** [step = 550] loss: 1.135, acc: 0.748
******** [step = 600] loss: 1.138, acc: 0.748
******** [step = 650] loss: 1.142, acc: 0.747
******** [step = 700] loss: 1.145, acc: 0.747
******** [step = 750] loss: 1.150, acc: 0.747
******** [step = 800] loss: 1.152, acc: 0.747
******** [step = 850] loss: 1.156, acc: 0.746
EPOCH = 46 loss: 1.156, acc: 0.746, val_loss: 1.474, val_acc: 0.730

================================================================================2025-08_12 01:19:35
******** [step = 50] loss: 1.079, acc: 0.757
******** [step = 100] loss: 1.093, acc: 0.755
******** [step = 150] loss: 1.095, acc: 0.755
******** [step = 200] loss: 1.105, acc: 0.754
******** [step = 250] loss: 1.103, acc: 0.754
******** [step = 300] loss: 1.108, acc: 0.753
******** [step = 350] loss: 1.111, acc: 0.752
******** [step = 400] loss: 1.115, acc: 0.752
******** [step = 450] loss: 1.118, acc: 0.752
******** [step = 500] loss: 1.120, acc: 0.752
******** [step = 550] loss: 1.124, acc: 0.751
******** [step = 600] loss: 1.128, acc: 0.751
******** [step = 650] loss: 1.132, acc: 0.750
******** [step = 700] loss: 1.136, acc: 0.750
******** [step = 750] loss: 1.139, acc: 0.750
******** [step = 800] loss: 1.143, acc: 0.749
******** [step = 850] loss: 1.145, acc: 0.749
EPOCH = 47 loss: 1.145, acc: 0.749, val_loss: 1.474, val_acc: 0.730

================================================================================2025-08_12 01:21:37
******** [step = 50] loss: 1.058, acc: 0.760
******** [step = 100] loss: 1.059, acc: 0.760
******** [step = 150] loss: 1.068, acc: 0.759
******** [step = 200] loss: 1.072, acc: 0.759
******** [step = 250] loss: 1.080, acc: 0.758
******** [step = 300] loss: 1.089, acc: 0.757
******** [step = 350] loss: 1.095, acc: 0.756
******** [step = 400] loss: 1.098, acc: 0.756
******** [step = 450] loss: 1.102, acc: 0.755
******** [step = 500] loss: 1.105, acc: 0.755
******** [step = 550] loss: 1.111, acc: 0.754
******** [step = 600] loss: 1.116, acc: 0.753
******** [step = 650] loss: 1.120, acc: 0.753
******** [step = 700] loss: 1.124, acc: 0.752
******** [step = 750] loss: 1.129, acc: 0.752
******** [step = 800] loss: 1.133, acc: 0.751
******** [step = 850] loss: 1.137, acc: 0.751
EPOCH = 48 loss: 1.137, acc: 0.751, val_loss: 1.465, val_acc: 0.732

================================================================================2025-08_12 01:23:38
******** [step = 50] loss: 1.069, acc: 0.759
******** [step = 100] loss: 1.066, acc: 0.759
******** [step = 150] loss: 1.066, acc: 0.760
******** [step = 200] loss: 1.071, acc: 0.759
******** [step = 250] loss: 1.074, acc: 0.758
******** [step = 300] loss: 1.080, acc: 0.757
******** [step = 350] loss: 1.087, acc: 0.757
******** [step = 400] loss: 1.087, acc: 0.757
******** [step = 450] loss: 1.093, acc: 0.756
******** [step = 500] loss: 1.098, acc: 0.755
******** [step = 550] loss: 1.101, acc: 0.755
******** [step = 600] loss: 1.106, acc: 0.755
******** [step = 650] loss: 1.110, acc: 0.754
******** [step = 700] loss: 1.115, acc: 0.754
******** [step = 750] loss: 1.120, acc: 0.753
******** [step = 800] loss: 1.125, acc: 0.752
******** [step = 850] loss: 1.129, acc: 0.752
EPOCH = 49 loss: 1.129, acc: 0.752, val_loss: 1.455, val_acc: 0.733

================================================================================2025-08_12 01:25:42
******** [step = 50] loss: 1.054, acc: 0.761
******** [step = 100] loss: 1.056, acc: 0.761
******** [step = 150] loss: 1.053, acc: 0.762
******** [step = 200] loss: 1.060, acc: 0.761
******** [step = 250] loss: 1.064, acc: 0.760
******** [step = 300] loss: 1.071, acc: 0.759
******** [step = 350] loss: 1.073, acc: 0.759
******** [step = 400] loss: 1.081, acc: 0.758
******** [step = 450] loss: 1.084, acc: 0.758
******** [step = 500] loss: 1.090, acc: 0.757
******** [step = 550] loss: 1.094, acc: 0.757
******** [step = 600] loss: 1.097, acc: 0.756
******** [step = 650] loss: 1.101, acc: 0.756
******** [step = 700] loss: 1.105, acc: 0.756
******** [step = 750] loss: 1.111, acc: 0.755
******** [step = 800] loss: 1.115, acc: 0.755
******** [step = 850] loss: 1.119, acc: 0.754
EPOCH = 50 loss: 1.119, acc: 0.754, val_loss: 1.451, val_acc: 0.735

================================================================================2025-08_12 01:27:43
******** [step = 50] loss: 1.061, acc: 0.760
******** [step = 100] loss: 1.055, acc: 0.762
******** [step = 150] loss: 1.051, acc: 0.763
******** [step = 200] loss: 1.052, acc: 0.764
******** [step = 250] loss: 1.055, acc: 0.763
******** [step = 300] loss: 1.058, acc: 0.763
******** [step = 350] loss: 1.065, acc: 0.762
******** [step = 400] loss: 1.071, acc: 0.761
******** [step = 450] loss: 1.076, acc: 0.760
******** [step = 500] loss: 1.082, acc: 0.759
******** [step = 550] loss: 1.086, acc: 0.759
******** [step = 600] loss: 1.090, acc: 0.758
******** [step = 650] loss: 1.096, acc: 0.758
******** [step = 700] loss: 1.100, acc: 0.757
******** [step = 750] loss: 1.102, acc: 0.757
******** [step = 800] loss: 1.105, acc: 0.756
******** [step = 850] loss: 1.110, acc: 0.756
EPOCH = 51 loss: 1.110, acc: 0.756, val_loss: 1.451, val_acc: 0.737

================================================================================2025-08_12 01:29:45
******** [step = 50] loss: 1.035, acc: 0.766
******** [step = 100] loss: 1.031, acc: 0.766
******** [step = 150] loss: 1.035, acc: 0.765
******** [step = 200] loss: 1.039, acc: 0.765
******** [step = 250] loss: 1.045, acc: 0.764
******** [step = 300] loss: 1.050, acc: 0.764
******** [step = 350] loss: 1.056, acc: 0.763
******** [step = 400] loss: 1.062, acc: 0.762
******** [step = 450] loss: 1.067, acc: 0.761
******** [step = 500] loss: 1.073, acc: 0.760
******** [step = 550] loss: 1.078, acc: 0.760
******** [step = 600] loss: 1.082, acc: 0.759
******** [step = 650] loss: 1.086, acc: 0.759
******** [step = 700] loss: 1.091, acc: 0.758
******** [step = 750] loss: 1.094, acc: 0.758
******** [step = 800] loss: 1.097, acc: 0.758
******** [step = 850] loss: 1.100, acc: 0.758
EPOCH = 52 loss: 1.100, acc: 0.758, val_loss: 1.444, val_acc: 0.738

================================================================================2025-08_12 01:31:48
******** [step = 50] loss: 1.023, acc: 0.766
******** [step = 100] loss: 1.025, acc: 0.767
******** [step = 150] loss: 1.033, acc: 0.765
******** [step = 200] loss: 1.041, acc: 0.765
******** [step = 250] loss: 1.044, acc: 0.764
******** [step = 300] loss: 1.048, acc: 0.764
******** [step = 350] loss: 1.051, acc: 0.763
******** [step = 400] loss: 1.054, acc: 0.763
******** [step = 450] loss: 1.059, acc: 0.763
******** [step = 500] loss: 1.062, acc: 0.763
******** [step = 550] loss: 1.067, acc: 0.762
******** [step = 600] loss: 1.070, acc: 0.761
******** [step = 650] loss: 1.074, acc: 0.761
******** [step = 700] loss: 1.079, acc: 0.760
******** [step = 750] loss: 1.085, acc: 0.760
******** [step = 800] loss: 1.088, acc: 0.759
******** [step = 850] loss: 1.096, acc: 0.758
EPOCH = 53 loss: 1.096, acc: 0.758, val_loss: 1.436, val_acc: 0.738

================================================================================2025-08_12 01:33:51
******** [step = 50] loss: 1.009, acc: 0.769
******** [step = 100] loss: 0.999, acc: 0.771
******** [step = 150] loss: 1.008, acc: 0.770
******** [step = 200] loss: 1.018, acc: 0.769
******** [step = 250] loss: 1.026, acc: 0.767
******** [step = 300] loss: 1.029, acc: 0.767
******** [step = 350] loss: 1.039, acc: 0.765
******** [step = 400] loss: 1.045, acc: 0.764
******** [step = 450] loss: 1.049, acc: 0.764
******** [step = 500] loss: 1.054, acc: 0.763
******** [step = 550] loss: 1.059, acc: 0.763
******** [step = 600] loss: 1.064, acc: 0.762
******** [step = 650] loss: 1.067, acc: 0.762
******** [step = 700] loss: 1.072, acc: 0.762
******** [step = 750] loss: 1.076, acc: 0.761
******** [step = 800] loss: 1.081, acc: 0.761
******** [step = 850] loss: 1.085, acc: 0.761
EPOCH = 54 loss: 1.085, acc: 0.761, val_loss: 1.435, val_acc: 0.739

================================================================================2025-08_12 01:35:53
******** [step = 50] loss: 1.008, acc: 0.770
******** [step = 100] loss: 1.010, acc: 0.770
******** [step = 150] loss: 1.020, acc: 0.768
******** [step = 200] loss: 1.022, acc: 0.768
******** [step = 250] loss: 1.028, acc: 0.767
******** [step = 300] loss: 1.036, acc: 0.766
******** [step = 350] loss: 1.041, acc: 0.766
******** [step = 400] loss: 1.048, acc: 0.765
******** [step = 450] loss: 1.050, acc: 0.765
******** [step = 500] loss: 1.054, acc: 0.764
******** [step = 550] loss: 1.058, acc: 0.763
******** [step = 600] loss: 1.061, acc: 0.763
******** [step = 650] loss: 1.064, acc: 0.763
******** [step = 700] loss: 1.069, acc: 0.762
******** [step = 750] loss: 1.072, acc: 0.762
******** [step = 800] loss: 1.074, acc: 0.762
******** [step = 850] loss: 1.078, acc: 0.762
EPOCH = 55 loss: 1.078, acc: 0.762, val_loss: 1.427, val_acc: 0.740

================================================================================2025-08_12 01:37:55
******** [step = 50] loss: 0.988, acc: 0.775
******** [step = 100] loss: 1.001, acc: 0.772
******** [step = 150] loss: 1.008, acc: 0.771
******** [step = 200] loss: 1.014, acc: 0.770
******** [step = 250] loss: 1.013, acc: 0.770
******** [step = 300] loss: 1.020, acc: 0.769
******** [step = 350] loss: 1.024, acc: 0.769
******** [step = 400] loss: 1.030, acc: 0.768
******** [step = 450] loss: 1.036, acc: 0.767
******** [step = 500] loss: 1.042, acc: 0.766
******** [step = 550] loss: 1.045, acc: 0.766
******** [step = 600] loss: 1.047, acc: 0.766
******** [step = 650] loss: 1.052, acc: 0.765
******** [step = 700] loss: 1.057, acc: 0.765
******** [step = 750] loss: 1.061, acc: 0.764
******** [step = 800] loss: 1.066, acc: 0.764
******** [step = 850] loss: 1.068, acc: 0.764
EPOCH = 56 loss: 1.068, acc: 0.764, val_loss: 1.419, val_acc: 0.741

================================================================================2025-08_12 01:39:56
******** [step = 50] loss: 1.001, acc: 0.772
******** [step = 100] loss: 0.994, acc: 0.772
******** [step = 150] loss: 0.999, acc: 0.772
******** [step = 200] loss: 1.005, acc: 0.771
******** [step = 250] loss: 1.006, acc: 0.771
******** [step = 300] loss: 1.012, acc: 0.771
******** [step = 350] loss: 1.018, acc: 0.770
******** [step = 400] loss: 1.024, acc: 0.769
******** [step = 450] loss: 1.031, acc: 0.768
******** [step = 500] loss: 1.034, acc: 0.768
******** [step = 550] loss: 1.038, acc: 0.767
******** [step = 600] loss: 1.042, acc: 0.767
******** [step = 650] loss: 1.046, acc: 0.766
******** [step = 700] loss: 1.051, acc: 0.766
******** [step = 750] loss: 1.054, acc: 0.765
******** [step = 800] loss: 1.058, acc: 0.765
******** [step = 850] loss: 1.061, acc: 0.764
EPOCH = 57 loss: 1.061, acc: 0.764, val_loss: 1.415, val_acc: 0.741

================================================================================2025-08_12 01:41:59
******** [step = 50] loss: 0.982, acc: 0.775
******** [step = 100] loss: 0.986, acc: 0.774
******** [step = 150] loss: 0.988, acc: 0.774
******** [step = 200] loss: 0.998, acc: 0.773
******** [step = 250] loss: 1.005, acc: 0.773
******** [step = 300] loss: 1.010, acc: 0.772
******** [step = 350] loss: 1.017, acc: 0.771
******** [step = 400] loss: 1.021, acc: 0.770
******** [step = 450] loss: 1.022, acc: 0.770
******** [step = 500] loss: 1.028, acc: 0.769
******** [step = 550] loss: 1.033, acc: 0.769
******** [step = 600] loss: 1.035, acc: 0.768
******** [step = 650] loss: 1.038, acc: 0.768
******** [step = 700] loss: 1.043, acc: 0.767
******** [step = 750] loss: 1.047, acc: 0.767
******** [step = 800] loss: 1.052, acc: 0.766
******** [step = 850] loss: 1.055, acc: 0.766
EPOCH = 58 loss: 1.055, acc: 0.766, val_loss: 1.413, val_acc: 0.744

================================================================================2025-08_12 01:44:01
******** [step = 50] loss: 0.989, acc: 0.775
******** [step = 100] loss: 0.987, acc: 0.775
******** [step = 150] loss: 0.995, acc: 0.774
******** [step = 200] loss: 0.994, acc: 0.774
******** [step = 250] loss: 0.994, acc: 0.774
******** [step = 300] loss: 0.997, acc: 0.774
******** [step = 350] loss: 1.003, acc: 0.773
******** [step = 400] loss: 1.008, acc: 0.772
******** [step = 450] loss: 1.016, acc: 0.771
******** [step = 500] loss: 1.022, acc: 0.770
******** [step = 550] loss: 1.026, acc: 0.770
******** [step = 600] loss: 1.030, acc: 0.769
******** [step = 650] loss: 1.035, acc: 0.769
******** [step = 700] loss: 1.039, acc: 0.768
******** [step = 750] loss: 1.043, acc: 0.768
******** [step = 800] loss: 1.046, acc: 0.768
******** [step = 850] loss: 1.049, acc: 0.767
EPOCH = 59 loss: 1.049, acc: 0.767, val_loss: 1.415, val_acc: 0.745

================================================================================2025-08_12 01:46:02
******** [step = 50] loss: 0.973, acc: 0.780
******** [step = 100] loss: 0.974, acc: 0.779
******** [step = 150] loss: 0.980, acc: 0.778
******** [step = 200] loss: 0.987, acc: 0.777
******** [step = 250] loss: 0.992, acc: 0.776
******** [step = 300] loss: 0.999, acc: 0.775
******** [step = 350] loss: 1.004, acc: 0.774
******** [step = 400] loss: 1.010, acc: 0.773
******** [step = 450] loss: 1.014, acc: 0.772
******** [step = 500] loss: 1.019, acc: 0.772
******** [step = 550] loss: 1.022, acc: 0.771
******** [step = 600] loss: 1.024, acc: 0.771
******** [step = 650] loss: 1.027, acc: 0.771
******** [step = 700] loss: 1.033, acc: 0.770
******** [step = 750] loss: 1.037, acc: 0.769
******** [step = 800] loss: 1.039, acc: 0.769
******** [step = 850] loss: 1.044, acc: 0.769
EPOCH = 60 loss: 1.044, acc: 0.769, val_loss: 1.407, val_acc: 0.745

================================================================================2025-08_12 01:48:04
******** [step = 50] loss: 0.960, acc: 0.779
******** [step = 100] loss: 0.963, acc: 0.778
******** [step = 150] loss: 0.966, acc: 0.779
******** [step = 200] loss: 0.972, acc: 0.778
******** [step = 250] loss: 0.982, acc: 0.776
******** [step = 300] loss: 0.989, acc: 0.775
******** [step = 350] loss: 0.997, acc: 0.774
******** [step = 400] loss: 1.000, acc: 0.774
******** [step = 450] loss: 1.005, acc: 0.773
******** [step = 500] loss: 1.009, acc: 0.773
******** [step = 550] loss: 1.014, acc: 0.772
******** [step = 600] loss: 1.019, acc: 0.771
******** [step = 650] loss: 1.024, acc: 0.771
******** [step = 700] loss: 1.027, acc: 0.771
******** [step = 750] loss: 1.032, acc: 0.770
******** [step = 800] loss: 1.037, acc: 0.770
******** [step = 850] loss: 1.037, acc: 0.770
EPOCH = 61 loss: 1.037, acc: 0.770, val_loss: 1.408, val_acc: 0.745

================================================================================2025-08_12 01:50:06
******** [step = 50] loss: 0.964, acc: 0.778
******** [step = 100] loss: 0.969, acc: 0.779
******** [step = 150] loss: 0.969, acc: 0.779
******** [step = 200] loss: 0.978, acc: 0.777
******** [step = 250] loss: 0.981, acc: 0.777
******** [step = 300] loss: 0.987, acc: 0.776
******** [step = 350] loss: 0.991, acc: 0.776
******** [step = 400] loss: 0.995, acc: 0.775
******** [step = 450] loss: 1.001, acc: 0.775
******** [step = 500] loss: 1.005, acc: 0.774
******** [step = 550] loss: 1.009, acc: 0.774
******** [step = 600] loss: 1.014, acc: 0.773
******** [step = 650] loss: 1.018, acc: 0.773
******** [step = 700] loss: 1.021, acc: 0.772
******** [step = 750] loss: 1.025, acc: 0.772
******** [step = 800] loss: 1.028, acc: 0.772
******** [step = 850] loss: 1.031, acc: 0.771
EPOCH = 62 loss: 1.031, acc: 0.771, val_loss: 1.399, val_acc: 0.747

================================================================================2025-08_12 01:52:08
******** [step = 50] loss: 0.948, acc: 0.783
******** [step = 100] loss: 0.953, acc: 0.782
******** [step = 150] loss: 0.956, acc: 0.781
******** [step = 200] loss: 0.963, acc: 0.780
******** [step = 250] loss: 0.971, acc: 0.779
******** [step = 300] loss: 0.978, acc: 0.778
******** [step = 350] loss: 0.983, acc: 0.777
******** [step = 400] loss: 0.987, acc: 0.777
******** [step = 450] loss: 0.992, acc: 0.776
******** [step = 500] loss: 0.996, acc: 0.775
******** [step = 550] loss: 1.000, acc: 0.775
******** [step = 600] loss: 1.004, acc: 0.775
******** [step = 650] loss: 1.009, acc: 0.774
******** [step = 700] loss: 1.012, acc: 0.774
******** [step = 750] loss: 1.016, acc: 0.773
******** [step = 800] loss: 1.020, acc: 0.773
******** [step = 850] loss: 1.023, acc: 0.772
EPOCH = 63 loss: 1.023, acc: 0.772, val_loss: 1.397, val_acc: 0.747

================================================================================2025-08_12 01:54:10
******** [step = 50] loss: 0.944, acc: 0.783
******** [step = 100] loss: 0.952, acc: 0.781
******** [step = 150] loss: 0.953, acc: 0.781
******** [step = 200] loss: 0.957, acc: 0.781
******** [step = 250] loss: 0.965, acc: 0.780
******** [step = 300] loss: 0.970, acc: 0.780
******** [step = 350] loss: 0.977, acc: 0.778
******** [step = 400] loss: 0.982, acc: 0.778
******** [step = 450] loss: 0.987, acc: 0.777
******** [step = 500] loss: 0.990, acc: 0.777
******** [step = 550] loss: 0.996, acc: 0.776
******** [step = 600] loss: 1.001, acc: 0.776
******** [step = 650] loss: 1.005, acc: 0.775
******** [step = 700] loss: 1.009, acc: 0.775
******** [step = 750] loss: 1.013, acc: 0.774
******** [step = 800] loss: 1.015, acc: 0.774
******** [step = 850] loss: 1.019, acc: 0.773
EPOCH = 64 loss: 1.019, acc: 0.773, val_loss: 1.392, val_acc: 0.748

================================================================================2025-08_12 01:56:12
******** [step = 50] loss: 0.940, acc: 0.784
******** [step = 100] loss: 0.938, acc: 0.785
******** [step = 150] loss: 0.950, acc: 0.783
******** [step = 200] loss: 0.956, acc: 0.782
******** [step = 250] loss: 0.957, acc: 0.782
******** [step = 300] loss: 0.963, acc: 0.781
******** [step = 350] loss: 0.971, acc: 0.780
******** [step = 400] loss: 0.974, acc: 0.779
******** [step = 450] loss: 0.977, acc: 0.779
******** [step = 500] loss: 0.983, acc: 0.778
******** [step = 550] loss: 0.988, acc: 0.777
******** [step = 600] loss: 0.992, acc: 0.777
******** [step = 650] loss: 0.995, acc: 0.776
******** [step = 700] loss: 1.000, acc: 0.776
******** [step = 750] loss: 1.005, acc: 0.775
******** [step = 800] loss: 1.009, acc: 0.775
******** [step = 850] loss: 1.013, acc: 0.774
EPOCH = 65 loss: 1.013, acc: 0.774, val_loss: 1.386, val_acc: 0.749

================================================================================2025-08_12 01:58:14
******** [step = 50] loss: 0.942, acc: 0.783
******** [step = 100] loss: 0.946, acc: 0.783
******** [step = 150] loss: 0.948, acc: 0.783
******** [step = 200] loss: 0.950, acc: 0.782
******** [step = 250] loss: 0.956, acc: 0.781
******** [step = 300] loss: 0.959, acc: 0.781
******** [step = 350] loss: 0.964, acc: 0.780
******** [step = 400] loss: 0.968, acc: 0.780
******** [step = 450] loss: 0.973, acc: 0.779
******** [step = 500] loss: 0.978, acc: 0.778
******** [step = 550] loss: 0.983, acc: 0.778
******** [step = 600] loss: 0.987, acc: 0.778
******** [step = 650] loss: 0.993, acc: 0.777
******** [step = 700] loss: 0.995, acc: 0.777
******** [step = 750] loss: 0.999, acc: 0.776
******** [step = 800] loss: 1.004, acc: 0.775
******** [step = 850] loss: 1.006, acc: 0.775
EPOCH = 66 loss: 1.006, acc: 0.775, val_loss: 1.383, val_acc: 0.749

================================================================================2025-08_12 02:00:15
******** [step = 50] loss: 0.913, acc: 0.787
******** [step = 100] loss: 0.920, acc: 0.787
******** [step = 150] loss: 0.933, acc: 0.785
******** [step = 200] loss: 0.937, acc: 0.785
******** [step = 250] loss: 0.947, acc: 0.783
******** [step = 300] loss: 0.953, acc: 0.782
******** [step = 350] loss: 0.958, acc: 0.782
******** [step = 400] loss: 0.966, acc: 0.781
******** [step = 450] loss: 0.969, acc: 0.780
******** [step = 500] loss: 0.974, acc: 0.780
******** [step = 550] loss: 0.979, acc: 0.779
******** [step = 600] loss: 0.983, acc: 0.779
******** [step = 650] loss: 0.987, acc: 0.778
******** [step = 700] loss: 0.992, acc: 0.778
******** [step = 750] loss: 0.996, acc: 0.777
******** [step = 800] loss: 0.999, acc: 0.777
******** [step = 850] loss: 1.002, acc: 0.777
EPOCH = 67 loss: 1.002, acc: 0.777, val_loss: 1.386, val_acc: 0.750

================================================================================2025-08_12 02:02:18
******** [step = 50] loss: 0.913, acc: 0.790
******** [step = 100] loss: 0.920, acc: 0.788
******** [step = 150] loss: 0.932, acc: 0.786
******** [step = 200] loss: 0.942, acc: 0.784
******** [step = 250] loss: 0.945, acc: 0.784
******** [step = 300] loss: 0.950, acc: 0.783
******** [step = 350] loss: 0.954, acc: 0.783
******** [step = 400] loss: 0.959, acc: 0.782
******** [step = 450] loss: 0.965, acc: 0.781
******** [step = 500] loss: 0.970, acc: 0.780
******** [step = 550] loss: 0.972, acc: 0.780
******** [step = 600] loss: 0.977, acc: 0.780
******** [step = 650] loss: 0.981, acc: 0.779
******** [step = 700] loss: 0.985, acc: 0.779
******** [step = 750] loss: 0.990, acc: 0.778
******** [step = 800] loss: 0.994, acc: 0.778
******** [step = 850] loss: 0.999, acc: 0.777
EPOCH = 68 loss: 0.999, acc: 0.777, val_loss: 1.375, val_acc: 0.751

================================================================================2025-08_12 02:04:20
******** [step = 50] loss: 0.933, acc: 0.788
******** [step = 100] loss: 0.922, acc: 0.787
******** [step = 150] loss: 0.924, acc: 0.787
******** [step = 200] loss: 0.926, acc: 0.787
******** [step = 250] loss: 0.934, acc: 0.786
******** [step = 300] loss: 0.940, acc: 0.785
******** [step = 350] loss: 0.945, acc: 0.784
******** [step = 400] loss: 0.951, acc: 0.783
******** [step = 450] loss: 0.958, acc: 0.782
******** [step = 500] loss: 0.963, acc: 0.782
******** [step = 550] loss: 0.968, acc: 0.781
******** [step = 600] loss: 0.971, acc: 0.781
******** [step = 650] loss: 0.976, acc: 0.780
******** [step = 700] loss: 0.981, acc: 0.780
******** [step = 750] loss: 0.986, acc: 0.779
******** [step = 800] loss: 0.989, acc: 0.779
******** [step = 850] loss: 0.992, acc: 0.778
EPOCH = 69 loss: 0.992, acc: 0.778, val_loss: 1.379, val_acc: 0.751

================================================================================2025-08_12 02:06:22
******** [step = 50] loss: 0.924, acc: 0.788
******** [step = 100] loss: 0.921, acc: 0.790
******** [step = 150] loss: 0.927, acc: 0.788
******** [step = 200] loss: 0.932, acc: 0.787
******** [step = 250] loss: 0.936, acc: 0.787
******** [step = 300] loss: 0.939, acc: 0.786
******** [step = 350] loss: 0.946, acc: 0.784
******** [step = 400] loss: 0.949, acc: 0.784
******** [step = 450] loss: 0.952, acc: 0.784
******** [step = 500] loss: 0.957, acc: 0.783
******** [step = 550] loss: 0.962, acc: 0.782
******** [step = 600] loss: 0.965, acc: 0.782
******** [step = 650] loss: 0.969, acc: 0.782
******** [step = 700] loss: 0.973, acc: 0.781
******** [step = 750] loss: 0.977, acc: 0.781
******** [step = 800] loss: 0.981, acc: 0.781
******** [step = 850] loss: 0.987, acc: 0.780
EPOCH = 70 loss: 0.987, acc: 0.780, val_loss: 1.373, val_acc: 0.752

================================================================================2025-08_12 02:08:23
******** [step = 50] loss: 0.925, acc: 0.787
******** [step = 100] loss: 0.915, acc: 0.788
******** [step = 150] loss: 0.914, acc: 0.789
******** [step = 200] loss: 0.922, acc: 0.788
******** [step = 250] loss: 0.924, acc: 0.788
******** [step = 300] loss: 0.929, acc: 0.787
******** [step = 350] loss: 0.934, acc: 0.786
******** [step = 400] loss: 0.940, acc: 0.785
******** [step = 450] loss: 0.945, acc: 0.784
******** [step = 500] loss: 0.949, acc: 0.784
******** [step = 550] loss: 0.956, acc: 0.783
******** [step = 600] loss: 0.961, acc: 0.782
******** [step = 650] loss: 0.965, acc: 0.782
******** [step = 700] loss: 0.970, acc: 0.781
******** [step = 750] loss: 0.974, acc: 0.781
******** [step = 800] loss: 0.979, acc: 0.780
******** [step = 850] loss: 0.982, acc: 0.780
EPOCH = 71 loss: 0.982, acc: 0.780, val_loss: 1.371, val_acc: 0.751

================================================================================2025-08_12 02:10:26
******** [step = 50] loss: 0.909, acc: 0.792
******** [step = 100] loss: 0.912, acc: 0.791
******** [step = 150] loss: 0.915, acc: 0.789
******** [step = 200] loss: 0.919, acc: 0.789
******** [step = 250] loss: 0.925, acc: 0.788
******** [step = 300] loss: 0.929, acc: 0.788
******** [step = 350] loss: 0.935, acc: 0.787
******** [step = 400] loss: 0.941, acc: 0.786
******** [step = 450] loss: 0.947, acc: 0.785
******** [step = 500] loss: 0.951, acc: 0.785
******** [step = 550] loss: 0.955, acc: 0.784
******** [step = 600] loss: 0.957, acc: 0.784
******** [step = 650] loss: 0.962, acc: 0.783
******** [step = 700] loss: 0.967, acc: 0.783
******** [step = 750] loss: 0.970, acc: 0.782
******** [step = 800] loss: 0.974, acc: 0.782
******** [step = 850] loss: 0.977, acc: 0.781
EPOCH = 72 loss: 0.977, acc: 0.781, val_loss: 1.374, val_acc: 0.752

================================================================================2025-08_12 02:12:28
******** [step = 50] loss: 0.896, acc: 0.791
******** [step = 100] loss: 0.907, acc: 0.790
******** [step = 150] loss: 0.912, acc: 0.789
******** [step = 200] loss: 0.917, acc: 0.789
******** [step = 250] loss: 0.920, acc: 0.788
******** [step = 300] loss: 0.930, acc: 0.787
******** [step = 350] loss: 0.933, acc: 0.786
******** [step = 400] loss: 0.937, acc: 0.786
******** [step = 450] loss: 0.940, acc: 0.786
******** [step = 500] loss: 0.944, acc: 0.785
******** [step = 550] loss: 0.948, acc: 0.785
******** [step = 600] loss: 0.952, acc: 0.784
******** [step = 650] loss: 0.957, acc: 0.784
******** [step = 700] loss: 0.960, acc: 0.783
******** [step = 750] loss: 0.965, acc: 0.783
******** [step = 800] loss: 0.968, acc: 0.782
******** [step = 850] loss: 0.972, acc: 0.782
EPOCH = 73 loss: 0.972, acc: 0.782, val_loss: 1.367, val_acc: 0.752

================================================================================2025-08_12 02:14:29
******** [step = 50] loss: 0.903, acc: 0.791
******** [step = 100] loss: 0.898, acc: 0.792
******** [step = 150] loss: 0.900, acc: 0.792
******** [step = 200] loss: 0.907, acc: 0.791
******** [step = 250] loss: 0.915, acc: 0.790
******** [step = 300] loss: 0.921, acc: 0.789
******** [step = 350] loss: 0.929, acc: 0.788
******** [step = 400] loss: 0.933, acc: 0.787
******** [step = 450] loss: 0.936, acc: 0.787
******** [step = 500] loss: 0.940, acc: 0.786
******** [step = 550] loss: 0.945, acc: 0.786
******** [step = 600] loss: 0.950, acc: 0.785
******** [step = 650] loss: 0.954, acc: 0.785
******** [step = 700] loss: 0.959, acc: 0.784
******** [step = 750] loss: 0.964, acc: 0.783
******** [step = 800] loss: 0.967, acc: 0.783
******** [step = 850] loss: 0.969, acc: 0.783
EPOCH = 74 loss: 0.969, acc: 0.783, val_loss: 1.367, val_acc: 0.754

================================================================================2025-08_12 02:16:31
******** [step = 50] loss: 0.917, acc: 0.789
******** [step = 100] loss: 0.904, acc: 0.791
******** [step = 150] loss: 0.905, acc: 0.792
******** [step = 200] loss: 0.910, acc: 0.791
******** [step = 250] loss: 0.914, acc: 0.791
******** [step = 300] loss: 0.919, acc: 0.790
******** [step = 350] loss: 0.922, acc: 0.789
******** [step = 400] loss: 0.926, acc: 0.788
******** [step = 450] loss: 0.932, acc: 0.788
******** [step = 500] loss: 0.938, acc: 0.787
******** [step = 550] loss: 0.943, acc: 0.786
******** [step = 600] loss: 0.947, acc: 0.786
******** [step = 650] loss: 0.950, acc: 0.785
******** [step = 700] loss: 0.953, acc: 0.785
******** [step = 750] loss: 0.957, acc: 0.785
******** [step = 800] loss: 0.960, acc: 0.784
******** [step = 850] loss: 0.965, acc: 0.784
EPOCH = 75 loss: 0.965, acc: 0.784, val_loss: 1.365, val_acc: 0.753

================================================================================2025-08_12 02:18:33
******** [step = 50] loss: 0.890, acc: 0.795
******** [step = 100] loss: 0.896, acc: 0.794
******** [step = 150] loss: 0.900, acc: 0.793
******** [step = 200] loss: 0.901, acc: 0.793
******** [step = 250] loss: 0.907, acc: 0.792
******** [step = 300] loss: 0.912, acc: 0.792
******** [step = 350] loss: 0.917, acc: 0.791
******** [step = 400] loss: 0.922, acc: 0.790
******** [step = 450] loss: 0.926, acc: 0.790
******** [step = 500] loss: 0.931, acc: 0.789
******** [step = 550] loss: 0.935, acc: 0.788
******** [step = 600] loss: 0.938, acc: 0.788
******** [step = 650] loss: 0.943, acc: 0.787
******** [step = 700] loss: 0.947, acc: 0.787
******** [step = 750] loss: 0.951, acc: 0.786
******** [step = 800] loss: 0.955, acc: 0.786
******** [step = 850] loss: 0.958, acc: 0.786
EPOCH = 76 loss: 0.958, acc: 0.786, val_loss: 1.360, val_acc: 0.755

================================================================================2025-08_12 02:20:35
******** [step = 50] loss: 0.892, acc: 0.795
******** [step = 100] loss: 0.894, acc: 0.794
******** [step = 150] loss: 0.893, acc: 0.793
******** [step = 200] loss: 0.897, acc: 0.793
******** [step = 250] loss: 0.900, acc: 0.794
******** [step = 300] loss: 0.908, acc: 0.792
******** [step = 350] loss: 0.912, acc: 0.792
******** [step = 400] loss: 0.918, acc: 0.791
******** [step = 450] loss: 0.924, acc: 0.790
******** [step = 500] loss: 0.929, acc: 0.789
******** [step = 550] loss: 0.935, acc: 0.788
******** [step = 600] loss: 0.938, acc: 0.788
******** [step = 650] loss: 0.942, acc: 0.787
******** [step = 700] loss: 0.946, acc: 0.787
******** [step = 750] loss: 0.949, acc: 0.786
******** [step = 800] loss: 0.953, acc: 0.786
******** [step = 850] loss: 0.955, acc: 0.786
EPOCH = 77 loss: 0.955, acc: 0.786, val_loss: 1.353, val_acc: 0.756

================================================================================2025-08_12 02:22:38
******** [step = 50] loss: 0.874, acc: 0.798
******** [step = 100] loss: 0.877, acc: 0.796
******** [step = 150] loss: 0.888, acc: 0.794
******** [step = 200] loss: 0.894, acc: 0.793
******** [step = 250] loss: 0.896, acc: 0.792
******** [step = 300] loss: 0.902, acc: 0.792
******** [step = 350] loss: 0.905, acc: 0.792
******** [step = 400] loss: 0.909, acc: 0.791
******** [step = 450] loss: 0.913, acc: 0.791
******** [step = 500] loss: 0.917, acc: 0.790
******** [step = 550] loss: 0.922, acc: 0.790
******** [step = 600] loss: 0.926, acc: 0.789
******** [step = 650] loss: 0.931, acc: 0.789
******** [step = 700] loss: 0.936, acc: 0.788
******** [step = 750] loss: 0.941, acc: 0.788
******** [step = 800] loss: 0.946, acc: 0.787
******** [step = 850] loss: 0.951, acc: 0.787
EPOCH = 78 loss: 0.951, acc: 0.787, val_loss: 1.353, val_acc: 0.757

================================================================================2025-08_12 02:24:40
******** [step = 50] loss: 0.881, acc: 0.797
******** [step = 100] loss: 0.879, acc: 0.798
******** [step = 150] loss: 0.882, acc: 0.797
******** [step = 200] loss: 0.889, acc: 0.796
******** [step = 250] loss: 0.894, acc: 0.795
******** [step = 300] loss: 0.898, acc: 0.794
******** [step = 350] loss: 0.902, acc: 0.794
******** [step = 400] loss: 0.906, acc: 0.793
******** [step = 450] loss: 0.911, acc: 0.792
******** [step = 500] loss: 0.917, acc: 0.791
******** [step = 550] loss: 0.921, acc: 0.791
******** [step = 600] loss: 0.926, acc: 0.790
******** [step = 650] loss: 0.930, acc: 0.790
******** [step = 700] loss: 0.935, acc: 0.789
******** [step = 750] loss: 0.938, acc: 0.789
******** [step = 800] loss: 0.943, acc: 0.788
******** [step = 850] loss: 0.948, acc: 0.788
EPOCH = 79 loss: 0.948, acc: 0.788, val_loss: 1.351, val_acc: 0.757

================================================================================2025-08_12 02:26:44
******** [step = 50] loss: 0.870, acc: 0.796
******** [step = 100] loss: 0.873, acc: 0.797
******** [step = 150] loss: 0.875, acc: 0.797
******** [step = 200] loss: 0.882, acc: 0.796
******** [step = 250] loss: 0.890, acc: 0.795
******** [step = 300] loss: 0.895, acc: 0.794
******** [step = 350] loss: 0.900, acc: 0.794
******** [step = 400] loss: 0.902, acc: 0.793
******** [step = 450] loss: 0.907, acc: 0.793
******** [step = 500] loss: 0.911, acc: 0.792
******** [step = 550] loss: 0.916, acc: 0.791
******** [step = 600] loss: 0.922, acc: 0.791
******** [step = 650] loss: 0.926, acc: 0.791
******** [step = 700] loss: 0.930, acc: 0.790
******** [step = 750] loss: 0.934, acc: 0.790
******** [step = 800] loss: 0.937, acc: 0.789
******** [step = 850] loss: 0.940, acc: 0.789
EPOCH = 80 loss: 0.940, acc: 0.789, val_loss: 1.350, val_acc: 0.757

================================================================================2025-08_12 02:28:46
finishing training...
Training complete in 163m 20s
    epoch  ...   val_acc
0     1.0  ...  0.392960
1     2.0  ...  0.433544
2     3.0  ...  0.453770
3     4.0  ...  0.471379
4     5.0  ...  0.496261
..    ...  ...       ...
75   76.0  ...  0.755172
76   77.0  ...  0.756272
77   78.0  ...  0.756542
78   79.0  ...  0.757148
79   80.0  ...  0.756845

[80 rows x 5 columns]
== Done ==
Tue Aug 12 02:29:13 AM EDT 2025
---------------------------------------
Begin Slurm Epilog: Aug-12-2025 02:29:13
Job ID:        6939685
User ID:       xchen920
Account:       gts-apm7
Job name:      channel_trans
Resources:     cpu=4,gres/gpu:v100=1,mem=16G,node=1
Rsrc Used:     cput=11:08:08,vmem=0,walltime=02:47:02,mem=36248K,energy_used=0
Partition:     gpu-v100
QOS:           inferno
Nodes:         atl1-1-02-011-33-0
---------------------------------------
